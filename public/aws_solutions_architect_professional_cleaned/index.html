<!DOCTYPE html>
<html lang="en-us" dir="ltr" itemscope itemtype="http://schema.org/Article" data-r-output-format="html">
  <head><script src="/nirpendra83/aws-doc.git/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=nirpendra83/aws-doc.git/livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta name="viewport" content="height=device-height, width=device-width, initial-scale=1.0, minimum-scale=1.0">
    <meta name="generator" content="Hugo 0.148.2">
    <meta name="generator" content="Relearn 8.0.0+9803d5122ebb3276acea823f476e9eb44f607862">
    <meta name="description" content="AWS Certiﬁed Solutions Architect - Professional Understanding the Requirements AWS Certified Solutions Architect - Professional is intended for individuals with two or more years of hands-on experience designing and deploying cloud architecture on AWS. Questions are scenario oriented.
2 Choice for Instructor 1.Cover Theory and Basic Demos – Course Length Maintained 2.Cover Practically – Course Length will be Longer
Our Choice This course follows practical based approach. It will be lengthy but worth it. Video Course - Resources You can find the PPTs associated with the entire course available in the first section.">
    <meta name="author" content="">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Getting Started with AWS :: AWS Solution Architect">
    <meta name="twitter:description" content="AWS Certiﬁed Solutions Architect - Professional Understanding the Requirements AWS Certified Solutions Architect - Professional is intended for individuals with two or more years of hands-on experience designing and deploying cloud architecture on AWS. Questions are scenario oriented.
2 Choice for Instructor 1.Cover Theory and Basic Demos – Course Length Maintained 2.Cover Practically – Course Length will be Longer
Our Choice This course follows practical based approach. It will be lengthy but worth it. Video Course - Resources You can find the PPTs associated with the entire course available in the first section.">
    <meta property="og:url" content="http://localhost:1313/nirpendra83/aws-doc.git/aws_solutions_architect_professional_cleaned/index.html">
    <meta property="og:site_name" content="AWS Solution Architect">
    <meta property="og:title" content="Getting Started with AWS :: AWS Solution Architect">
    <meta property="og:description" content="AWS Certiﬁed Solutions Architect - Professional Understanding the Requirements AWS Certified Solutions Architect - Professional is intended for individuals with two or more years of hands-on experience designing and deploying cloud architecture on AWS. Questions are scenario oriented.
2 Choice for Instructor 1.Cover Theory and Basic Demos – Course Length Maintained 2.Cover Practically – Course Length will be Longer
Our Choice This course follows practical based approach. It will be lengthy but worth it. Video Course - Resources You can find the PPTs associated with the entire course available in the first section.">
    <meta property="og:locale" content="en_us">
    <meta property="og:type" content="article">
    <meta property="article:section" content="AWS Certified Solutions Architect - Professional">
    <meta itemprop="name" content="Getting Started with AWS :: AWS Solution Architect">
    <meta itemprop="description" content="AWS Certiﬁed Solutions Architect - Professional Understanding the Requirements AWS Certified Solutions Architect - Professional is intended for individuals with two or more years of hands-on experience designing and deploying cloud architecture on AWS. Questions are scenario oriented.
2 Choice for Instructor 1.Cover Theory and Basic Demos – Course Length Maintained 2.Cover Practically – Course Length will be Longer
Our Choice This course follows practical based approach. It will be lengthy but worth it. Video Course - Resources You can find the PPTs associated with the entire course available in the first section.">
    <meta itemprop="wordCount" content="48466">
    <title>Getting Started with AWS :: AWS Solution Architect</title>
    <link href="../nirpendra83/aws-doc.git/css/auto-complete/auto-complete.min.css?1757405171" rel="stylesheet">
    <script src="../nirpendra83/aws-doc.git/js/auto-complete/auto-complete.min.js?1757405171" defer></script>
    <script src="../nirpendra83/aws-doc.git/js/search-lunr.js?1757405171" defer></script>
    <script src="../nirpendra83/aws-doc.git/js/search.js?1757405171" defer></script>
    <script>
      window.relearn = window.relearn || {};
      window.relearn.index_js_url="../searchindex.en.js?1757405171";
    </script>
    <script src="../nirpendra83/aws-doc.git/js/lunr/lunr.min.js?1757405171" defer></script>
    <script src="../nirpendra83/aws-doc.git/js/lunr/lunr.stemmer.support.min.js?1757405171" defer></script>
    <script src="../nirpendra83/aws-doc.git/js/lunr/lunr.multi.min.js?1757405171" defer></script>
    <script src="../nirpendra83/aws-doc.git/js/lunr/lunr.en.min.js?1757405171" defer></script>
    <script>
      window.relearn = window.relearn || {};
      window.relearn.contentLangs=['en'];
    </script>
    <link href="../nirpendra83/aws-doc.git/fonts/fontawesome/css/fontawesome-all.min.css?1757405171" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="../nirpendra83/aws-doc.git/fonts/fontawesome/css/fontawesome-all.min.css?1757405171" rel="stylesheet"></noscript>
    <link href="../nirpendra83/aws-doc.git/css/perfect-scrollbar/perfect-scrollbar.min.css?1757405171" rel="stylesheet">
    <link href="../css/theme.css?1757405171" rel="stylesheet">
    <link href="../css/format-html.css?1757405171" rel="stylesheet" id="R-format-style">
    <script>
      window.relearn = window.relearn || {};
      // configuration
      window.relearn.min = ``;
      window.relearn.path='\/aws_solutions_architect_professional_cleaned\/index.html';
      window.relearn.relBasePath='..';
      window.relearn.relBaseUri='..';
      window.relearn.absBaseUri='http:\/\/localhost:1313\/nirpendra83\/aws-doc.git';
      window.relearn.disableAnchorCopy=false;
      window.relearn.disableAnchorScrolling=false;
      window.relearn.disableInlineCopyToClipboard=false;
      window.relearn.enableBlockCodeWrap=true;
      // legal
      window.relearn.getItem = (s,n) => {return s.getItem(n)};
      window.relearn.setItem = (s,n,v) => {return s.setItem(n,v)};
      window.relearn.removeItem = (s,n) => {return s.removeItem(n)};
      // translations
      window.T_Copy_to_clipboard = `Copy to clipboard`;
      window.T_Copied_to_clipboard = `Copied to clipboard!`;
      window.T_Copy_link_to_clipboard = `Copy link to clipboard`;
      window.T_Link_copied_to_clipboard = `Copied link to clipboard!`;
      window.T_Reset_view = `Reset view`;
      window.T_View_reset = `View reset!`;
      window.T_No_results_found = `No results found for "{0}"`;
      window.T_N_results_found = `{1} results found for "{0}"`;
      // variant stuff
      window.relearn.themevariants = [ 'auto' ];
      window.relearn.customvariantname = "my-custom-variant";
      window.relearn.changeVariant = function(variant) {
        var oldVariant = document.documentElement.dataset.rThemeVariant;
        window.relearn.setItem(window.localStorage, window.relearn.absBaseUri + "/variant", variant);
        document.documentElement.dataset.rThemeVariant = variant;
        if (oldVariant != variant) {
          document.dispatchEvent( new CustomEvent('themeVariantLoaded', { detail: { variant, oldVariant } }) );
          window.relearn.markVariant();
        }
      }
      window.relearn.markVariant = function() {
        var variant = window.relearn.getItem(window.localStorage, window.relearn.absBaseUri + "/variant");
        document.querySelectorAll(".R-variantswitcher select").forEach((select) => {select.value = variant;});
      }
      window.relearn.initVariant = function() {
        var variant = window.relearn.getItem(window.localStorage, window.relearn.absBaseUri + "/variant") ?? "";
        if( variant == window.relearn.customvariantname ){
        }else if( !variant || !window.relearn.themevariants.includes(variant) ){
          variant = window.relearn.themevariants[0];
          window.relearn.setItem(window.localStorage, window.relearn.absBaseUri + "/variant", variant);
        }
        document.documentElement.dataset.rThemeVariant = variant;
      }
      window.relearn.initVariant();
      window.relearn.markVariant();
    </script>
  </head>
  <body class="mobile-support html" data-url="../aws_solutions_architect_professional_cleaned/index.html">
    <div id="R-body" class="default-animation">
      <div id="R-body-overlay"></div>
      <nav id="R-topbar">
        <div class="topbar-wrapper">
          <div class="topbar-sidebar-divider"></div>
          <div class="topbar-area topbar-area-start" data-area="start">
            <div class="topbar-button topbar-button-sidebar" data-content-empty="disable" data-width-s="show" data-width-m="hide" data-width-l="hide"><button class="topbar-control" onclick="toggleNav()" type="button" title="Menu (CTRL&#43;ALT&#43;n)"><i class="fa-fw fas fa-bars"></i></button>
            </div>
            <div class="topbar-button topbar-button-toc" data-content-empty="hide" data-width-s="show" data-width-m="show" data-width-l="show"><button class="topbar-control" onclick="toggleTopbarFlyout(this)" type="button" title="Table of Contents (CTRL&#43;ALT&#43;t)"><i class="fa-fw fas fa-list-alt"></i></button>
              <div class="topbar-content">
                <div class="topbar-content-wrapper">
<nav class="TableOfContents">
  <ul>
    <li><a href="#challenges-and-structure">EKS
m5.large
t2.micro
c4.xlarge
Node Group
IAM Role for NodeGroup
An IAM Role needs to be associated with NodeGroup to ensure EC2 instance can perform
following operations:
Fetch Images from ECR,  Manage Network Interfaces,  and others.  <br>
Node Group
IAM
knowledge portal
A WS Fargate
Serverless Compute
Basic Approach
In traditional approach, there is a need to create set of EC2 instances where containers can run.
Challenges:   Define and Deploy EC2, Security of EC2, Manage EC2
Container Orchestrator
Container 1
Container 2
knowledge portal
Serverless Approach
In the serverless approach, we do not have to worry about provisioning and managing EC2
A WS Fargate  is a serverless, pay-as-you-go compute engine that lets you focus on building
applications without managing servers
Container Orchestrator
knowledge portal
AWS Fargate
Migration Strategies
Challenges and Structure</a></li>
    <li><a href="#supportd-platforms-vsphere-and-hyper--v">A WS SMS
Server Migration Service
Getting Started
knowledge portal A WS Server Migration Service (SMS) is an agentless service which makes it easier and faster
for you to migrate thousands of on-premises workloads to A WS.
Supportd Platforms: vSphere and Hyper- V</a></li>
    <li><a href="#easily-use-the-cloud-storage">Storage Gateway
Hybrid Storage
Introduction
knowledge portal A WS Storage Gateway is a hybrid storage service that allows the on-premise application to
easily use the cloud storage</a></li>
    <li><a href="#it-allows-us-to-easily-integrate-powerful-visual-analysis-into-our-application">Where does DevOps
Team sit?
Building A - 3rd Floor User
knowledge portal
A WS Rekognition
Deep Learning
Overview of A WS Rekognition
knowledge portal
A WS A WS Rekognition  is a deep learning based virtual analysis service.
It allows us to easily integrate powerful visual analysis into our application</a></li>
  </ul>
</nav>
                </div>
              </div>
            </div>
          </div>
          <ol class="topbar-breadcrumbs breadcrumbs highlightable" itemscope itemtype="http://schema.org/BreadcrumbList"><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><a itemprop="item" href="../index.html"><span itemprop="name">AWS Certified Solutions Architect - Professional</span></a><meta itemprop="position" content="1">&nbsp;>&nbsp;</li><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><span itemprop="name">Getting Started with AWS</span><meta itemprop="position" content="2"></li>
          </ol>
          <div class="topbar-area topbar-area-end" data-area="end">
            <div class="topbar-button topbar-button-prev" data-content-empty="disable" data-width-s="show" data-width-m="show" data-width-l="show"><a class="topbar-control" href="../index.html" title="AWS Certified Solutions Architect - Professional (🡐)"><i class="fa-fw fas fa-chevron-left"></i></a>
            </div>
            <div class="topbar-button topbar-button-next" data-content-empty="disable" data-width-s="show" data-width-m="show" data-width-l="show"><a class="topbar-control" href="../getting-started-with-the-course/index.html" title="Getting Started with AWS (🡒)"><i class="fa-fw fas fa-chevron-right"></i></a>
            </div>
            <div class="topbar-button topbar-button-more" data-content-empty="hide" data-width-s="show" data-width-m="show" data-width-l="show"><button class="topbar-control" onclick="toggleTopbarFlyout(this)" type="button" title="More"><i class="fa-fw fas fa-ellipsis-v"></i></button>
              <div class="topbar-content">
                <div class="topbar-content-wrapper">
                  <div class="topbar-area topbar-area-more" data-area="more">
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </nav>
      <div id="R-main-overlay"></div>
      <main id="R-body-inner" class="highlightable page" tabindex="-1">
        <div class="flex-block-wrapper">
<article class="default">
  <header class="headline">
  </header>

<h1 id="getting-started-with-aws">Getting Started with AWS</h1>

<pre><code>   AWS Certiﬁed Solutions Architect - Professional 

                  Understanding the Requirements 
</code></pre>
<p>AWS Certified Solutions Architect - Professional is intended for individuals with
two or more years of hands-on experience  designing and deploying cloud
architecture on AWS.
Questions are scenario oriented.</p>
<pre><code>                       2 Choice for Instructor 
</code></pre>
<p>1.Cover Theory and Basic Demos &ndash; Course Length Maintained
2.Cover Practically &ndash; Course Length will be Longer</p>
<pre><code>                                Our Choice 
</code></pre>
<p>This course follows practical based approach.
It will be lengthy but worth it.
Video Course - Resources
You can find the PPTs associated with the entire course available in the first
section.</p>
<pre><code>                     Our Community (Optional) 
</code></pre>
<p>We also have a Discord community that allows all the individuals who are
preparing for the same certification to connect with each other for discussions as
well as technical support.</p>
<pre><code>                            F AQ for this course! 
</code></pre>
<ol>
<li>
<p>Will things be taught from basics in this course?
Base AWS practical knowledge is prerequisite to this course and certification.
We recommend at-least AWS Solutions Architect - Associate knowledge.
2.Will this help me prepare for certification ?
Definitely, it will help you more then the certification aspect, the real world
scenarios.</p>
<pre><code>                                    About Me 
</code></pre>
</li>
</ol>
<p>●DevSecOps Engineer  - Defensive Security.
●Teaching is one of my passions.
●I have total of 16 courses, and around 400,000+ students now.
Something about me :-
●AWS Certified [SA Pro, Advanced Networking, Security Specialty …]
●RedHat Certified Architect (RHCA) + 13 more Certifications
●Part time Security Consultant</p>
<p>Join us in our Adventure
Be Awesome  .in/ cha t
.in/link edin</p>
<pre><code>                               AWS Multi-Account Strategy 
                                Legacy Approach 
</code></pre>
<p>In the legacy approach , organisations used a single AWS account for all of their
environments.
The separation of environments were based on AWS Regions.
Development Region
(us-east-1) Staging Region
(us-east-2) Production Region
(us-west-1)</p>
<pre><code>                         Issues with Legacy Approach 
</code></pre>
<p>Security Risks: If credentials are compromised, an attacker could potentially
access all environments.
Resource and Service Limits:  Many AWS service limits are per-account, not
per-region. Dev or staging could accidentally exhaust resources needed by
production.
Compliance and Auditing:  Regulatory requirements often require strong
isolation. Auditors prefer account-level isolation.
Multi-Account Architecture
Multi-AWS account architecture  is a cloud management strategy in which an
organization utilises multiple AWS accounts  to run and manage its workloads.
Each environment can be isolated in a separate AWS account.
Development AWS Account Staging AWS Account Production AWS Account
AWS Account 1 AWS Account 2 AWS Account 3
Challenges with Multi-Account Architecture
Centralized Logging and Monitoring:  Each AWS account generates its own
CloudTrail, CloudWatch, and other logs. You need to build architectures to
consolidate logs from multiple accounts centrally.
User Management: Many users will require access to all AWS accounts for day
to day operations. You need to build an identity solution for easier management
of identities across accounts.
Billing:  You need consolidated billing to get an updated picture of costs across all
AWS accounts.
Centralized Account Architectures
In this approach, additional AWS accounts are created for specific purposes.
Example: Logging Account, Billing Account, Networking account.
Development AWS Account Staging AWS Account Production AWS Account
AWS Account 1 AWS Account 2 AWS Account 3 Push Logs Push Logs
Push Logs
Logging
AWS
Account</p>
<pre><code>        Multi-Account Architectures can be Complex 

                           Keys Points to Remember 
</code></pre>
<p>For multi-AWS account architectures, you must be familiar with cross-account
AWS service-specific configurations  and services that enable organizations to
maintain centralized access .
Services / Configurations Descriptions
AWS Organizations Centralized account management, policy enforcement, consolidated
billing
IAM Identity Center Centralized user authentication and access management
AWS Security Hub Centralized security posture management
Cross-Account
Configurations CloudTrail, Config, GuardDuty, CloudWatch
Identity Account Architecture
Understanding the Challenge
If an organization uses multiple sets of AWS accounts, having separate
usernames and passwords for each AWS account for users is a challenge.
AWS Account 1
AWS Account 2
AWS Account 3
AWS Account 1 developer-user secretPassword MFA-1
AWS Account 2 developer-user strongPassword MFA-2
AWS Account 3 developer-user tmpPassword MFA-3 Login with Credentials
Identity Account Architecture
In Identity Account architecture, the IAM users are created and managed in
central AWS Account .
From this central AWS account, they can login to any other AWS accounts.
Identity Account
Identity Account
AWS Account 1
AWS Account 2
AWS Account 3 Login
Reference Screenshot</p>
<pre><code>                         The Practical Architecture 
</code></pre>
<p>AWS Account B
AWS Account C Assume Role
Assume Role Identity Account
Identity Account cross-account-iam-role
cross-account-iam-role</p>
<pre><code>                                 Advantages and Disadvantages 
</code></pre>
<p>Advantages:
●Simple setup with no extra costs. Fast to configure.
Disadvantages:
●Hard to manage when number of roles and AWS accounts increases.
●AWS console access is required for Switch Role operations.
Practical W orkflow Steps
1.Create a user in Account A (Identity Account)
2.Create a Cross-Account IAM Role in the destination account with
appropriate trust and policies.
3.Allow User to switch to CrossAccountRole.
Reference Screenshot - STS Assume Role Policy</p>
<pre><code>                                               Point to Note 
</code></pre>
<p>You cannot switch to a role when you sign in as the AWS account root user.</p>
<pre><code>                                       IAM Policies 
                              Setting the Base 
</code></pre>
<p>IAM Policy defines permissions  that a specific entity has in AWS.</p>
<pre><code>                              IAM Policy T ypes 
</code></pre>
<p>IAM Policy Types Description
Identity-based policies Attach managed and inline policies to IAM identities (users, groups to
which users belong, or roles).
Resource-based policies Attach inline policies to resources like S3, SQS and so on.
Permissions boundaries Defines the maximum permissions that the identity-based policies can
grant to an entity, but does not grant permissions.
Organizations SCPs Define the maximum permissions for account members of an
organization or organizational unit (OU)
Access control lists
(ACLs) control which principals in other accounts can access the resource to
which the ACL is attached.
Session policies Session policies limit permissions for a created session, but do not
grant permissions
Identity Based Policy
Identity-based policies are JSON permissions  policy documents that control
what actions an identity (users, groups of users, and roles) can perform, on
which resources, and under what conditions</p>
<pre><code>                         Resource-based policies 
</code></pre>
<p>Resource-based policies are JSON policy documents that you attach to a
resource such as an Amazon S3 bucket, KMS Keys etc.
You can specify who has access to the resource and what actions they can
perform on it.</p>
<pre><code>                          Permission Boundaries 
</code></pre>
<p>A permissions boundary is an advanced feature in which you set the maximum
permissions  that an identity-based policy can grant to an IAM entity</p>
<pre><code>                        Service Control Policies 
</code></pre>
<p>SCPs are JSON policies that specify the maximum permissions that can be
allowed at an account level (Organization or Organizational Unit)</p>
<pre><code>                        Access Control Lists 
</code></pre>
<p>Access control lists (ACLs) are service policies that allow you to control which
principals in another account  can access a resource.</p>
<pre><code>                                      AWS Organizations 
                                  Setting the Base 
</code></pre>
<p>AWS offers centralised policy-based management , as well as the feature of
consolidated billing  for multiple AWS accounts through AWS Organisations.
Development AWS Account Production AWS Account
Member Account 1 Member Account 2 AWS Organization Management Account</p>
<pre><code>                               Management Account 
</code></pre>
<p>A management account  is the AWS account you use to create your organization.
The management account is the ultimate owner of the organization and has final
control over security policies. It also acts as a payer account, responsible for
paying all charges accrued by the accounts within its organization.</p>
<pre><code>                  Creation of New A WS Accounts 
</code></pre>
<p>Through the Management Account, organizations can easily create new sets of
AWS accounts or invite existing accounts.
Management Account AWS Account 1
AWS Account 2
AWS Account 3 Create new
accounts
Member Accounts
T wo Important Features
There are two important features of AWS Organizations - Policies  and
Consolidated Billing .
AWS Organizations
Policies  Consolidated Billing
1 - Consolidated Billing
Consolidated billing  is a feature of AWS Organizations that allows you to
combine the billing for multiple AWS accounts into a single bill , thereby
simplifying the payment process.
Management Account AWS Account 1
AWS Account 2
AWS Account 3</p>
<pre><code>  Benefits of Consolidated Billing - V olume Discounts 
</code></pre>
<p>AWS provides volume pricing discounts  on numerous service usage.
With consolidated billing, all charges are combined into a single bill, allowing
volume discounts to be applied even if services are used across multiple AWS
accounts.
S3 Standard Storage Pricing
First 50 TB / month $0.023 per GB
Next 450 TB / Month $0.022 per GB
Over 500 TB / Month $0.021 per GB
2 - Policies
Policies  in AWS Organizations enable you to apply additional types of
management  to the AWS accounts within your organization.
AWS Organization Policies
Service Control Policies
Tag Policies
Backup Policies
Resource Control Policies
AI services opt-out policies
Security Hub policies
Policies Description
Service Control Policies Offer central control over the maximum available permissions for IAM users and IAM
roles in an organization.
Tag Policies Help enforce consistent tagging across resources in your organization.
Backup Policies Allow you to centrally manage and apply backup plans to the AWS resources across an
organization&rsquo;s accounts.
Resource Control Policies Offer central control over the maximum available permissions for resources in an
organization.
AI services opt-out policies Allow you to control data collection for AWS AI services for all the accounts in an
organization.
Security Hub policies Allow you to address security coverage gaps that align with your organization&rsquo;s security
requirements and centrally applying them across an organization.
Chat applications policies Allow you to control access to an organization&rsquo;s accounts from chat applications such as
Slack and Microsoft Teams.
Declarative policies for EC2 Allow you to centrally declare and enforce desired configurations for EC2 at scale across
an organization.
Example - Service Controlled Policies
Service control policies (SCPs) are a type of organizational policy that you can
use to manage permissions within your AWS organization accounts.
AWS Account A
AWS Account B Deny ALL S3 Deny Disable
CloudTrail
AWS Organization
Point to Note - SCPs
SCPs don&rsquo;t affect users or roles in the management account .
They affect only the member accounts in your organization.
SCPs do not grant permissions to the IAM users and IAM roles in your
organization. No permissions are granted by an SCP.</p>
<pre><code>                              Example - T ag  Policies 
</code></pre>
<p>Tag policies  allow you to standardize the tags attached to the AWS resources
across AWS organization&rsquo;s accounts.
Tag Policy
The tag with key of TeamName must have
value of either of the following:
[Payments, Security, Database] AWS Account 1
AWS Account 2
AWS Account 3 AWS Organization Enforce
Reference Screenshot - T ag Policies</p>
<pre><code>                Organizational Units (OUs) in AWS Organizations 
                                               Setting the Base 
</code></pre>
<p>Large organizations may manage hundreds of AWS accounts.
Applying policies to accounts — such as those used for development — can be complex
and difficult to manage if not grouped together.
Example:  Attach “DenyS3” SCP to all Development Accounts.
Account-1
Account-2 Account-4
Account-3 Account-5
Account-6 Account-7
Account-8
Account-9</p>
<pre><code>                                  Introducing Organizational Units 
</code></pre>
<p>An Organizational Unit  (OU) allows customers to to group AWS accounts .
You can apply policies at OU level.
Team A AWS Account Team B AWS Account
Log Archive Account Networking Account Development OU
Production OU
Deny Disable
CloudTrail Deny Delete S3
Point to Note
You can create multiple OUs within a single organization, and you can create
OUs within other OUs.</p>
<pre><code>                       Strategies for using SCPs 

                  Understanding the Basics 
</code></pre>
<p>There are two strategies that you can use to configure SCPs in your account.
SCP Strategies
Deny List   Allow List
Strategy 1 - Deny List
In deny list , actions are allowed by default, and you specify what services and
actions are prohibited
To support this, AWS Organizations attaches an AWS managed SCP named
FullAWSAccess  to every root and OU when it&rsquo;s created.</p>
<pre><code>                     Benefits of Deny List Strategy 
</code></pre>
<p>Using a deny list strategy, account administrators can delegate all services and
actions until you create and attach an SCP that denies a specific service or set
of actions.
Deny statements require less maintenance, because you don&rsquo;t need to update
them when AWS adds new services.
Deny statements usually use less space, thus making it easier to stay within the
maximum size for SCPs</p>
<pre><code>               Sample Deny List Based Policy 

                       Strategy 2 - Allow List 
</code></pre>
<p>To use SCPs as an allow list, you must replace the AWS managed
FullAWSAccess SCP with an SCP that explicitly permits only those services and
actions that you want to allow.
By removing the default FullAWSAccess SCP, all actions for all services are now
implicitly denied.
Your custom SCP then overrides the implicit Deny with an explicit Allow for only
those actions that you want to permit</p>
<pre><code>               Sample Allow List Based Policy 

                            Points to Note 
</code></pre>
<p>Every root, OU, and account must have at least one SCP attached.
If you want to replace the default FullAWSAccess policy with an SCP that limits
the permissions that can be delegated, you must attach the replacement SCP
before you can remove the default SCP.</p>
<pre><code>                     IAM Policy Evaluation Logic 
                  Understanding the Challenge 
</code></pre>
<p>AWS has so many types of IAM Policies available.
IAM Policies: Identity-Based, Resource-Based, SCPs, Sessions Policies, ACLs
Question: When there are contradictory policies, what will be the final decision?</p>
<pre><code>                         Basics of Default Deny 
</code></pre>
<p>By default, all requests are implicitly denied  with the exception of the AWS
account root user, which has full access.
If user does not have any IAM Policy, it means that all his requests will be
denied by default.
Stop EC2
Sorry, but access denied Bob
Overriding Default Deny - Identity Level
An explicit allow  in an identity-based or resource-based policy overrides this
default deny.
IAM Policy
Allow Bob for S3*
Bob
Overriding Default Deny - Resource Level
An explicit allow in a resource-based policy  overrides this default deny.
Bob
Resource Policy
Allow Bob for S3*
Allow and Deny Policy
User has both Allow and Deny policies.
Bob
IAM Policy
Allow Bob for S3*
Deny Bob for S3*</p>
<pre><code>                              Short Answer 
</code></pre>
<p>Any Explicit  Deny = Final Deny
Explicit Deny = 0
Anything multiplied by 0 is 0</p>
<pre><code>                 Deny at a Resource Policy Level 
</code></pre>
<p>An explicit Deny always has higher precedence than explicit allow.
IAM Policy
Allow Bob for S3*
Resource Policy
Deny Bob for S3*
Bob
Explicit Deny is Final Deny - Second
An explicit Deny has higher precedence than explicit allow.
IAM Policy
Deny Bob for S3*
Resource Policy
Allow Bob for S3*
Bob
Evaluating identity-based policies with resource-based policies
When an IAM entity (user or role) requests access to a resource within the same
account, AWS evaluates all the permissions granted by the identity-based and
resource-based policies.
The resulting permissions are the total permissions of the two types.</p>
<p>Evaluating identity-based policies with permissions boundaries
When AWS evaluates the identity-based policies and permissions boundary for a
user, the resulting permissions are the intersection  of the two categories.</p>
<pre><code>Evaluating identity-based policies with Organizations SCPs 
</code></pre>
<p>When a user belongs to an account that is a member of an organization, the
resulting permissions are the intersection of the user&rsquo;s policies and the SCP.
This means that an action must be allowed by both the identity-based policy and
the SCP</p>
<pre><code>           Policy Evaluation - Identity and Resource Policies 

    A WS Secure T oken Service (STS) 
    Credentials Management 
                                      How IAM Role 
</code></pre>
<p>knowledge portal</p>
<pre><code> IAM Role 
</code></pre>
<p>S3 ReadOnly
EC2 ReadOnly AWS Access Keys
or
IAM Role</p>
<p>Overview of STS
knowledge portal ● The A WS  STS is a web service that enables you to request temporary ,
limited-privilege credentials for A WS Identity and Access Management (IAM) users
or for users that you authenticate (federated users).
● T emporary security credentials are short term and expire after a certain duration.
● Since they have a limited lifetime, the key rotation is no longer explicitly needed.</p>
<p>Overview Architecture of STS
knowledge portal
Temporary Security Credentials
Temporary Security Credentials    IAM Users
Federated Users
STS Architecture - Cross-A WS Account Access
knowledge portal
IAM User
Administrator Role AWS Account 2
AWS Account 3
Read Only Role
IAM Role
AWS Account 1
Service Role &amp; Pass Role
Back to IAM
Overview of Service Roles</p>
<p>A service role is a role that an A WS service assumes to perform actions on your behalf.
Service Role
CloudFormation
S3ReadOnlyAccess
EC2FullAccess S3
EC2
knowledge portal                                    Overview of PassRole</p>
<p>Pass Role allows the service to assume the role and perform actions on your behalf.
T o pass a role (and its permissions) to an A WS service, a user must have permissions to pass
the role to the service.
Use X Service Role
CloudFormation IAM User You don’t have
permission
knowledge portal                                  Sample PassRole Policy</p>
<p>knowledge portal                                          Important Pointer</p>
<p>Once the Role is associated with CloudFormation, other users that have permissions to
operate on this stack will be able to use this role, even if they don&rsquo;t have permission to pass it.
Ensure that this role grants least privilege.
Service Role
CloudFormation
Associated DeleteStack
Operation X Alice
Bob
Attribute-based access control</p>
<pre><code>                           Basics of RBAC 
</code></pre>
<p>Role-based access control (RBAC) restricts access based on a person&rsquo;s role
within an organization
In IAM, you implement RBAC by creating different policies for different job
functions
DevOps Policy
Security Policy
Prod Account</p>
<pre><code>                   Understanding the Challenge 
</code></pre>
<p>DevOps Team AdminAccess DevOps Policy Red Environment
Green Environment DevOps Team has access to Red and Green Environment</p>
<pre><code>            Possible Approach of Separation 
</code></pre>
<p>Red DevOps Policy Red Environment
Green Environment Red    Env DevOps only has access to Red Environment
Green Env DevOps only has access to Green Environment
Green DevOps Policy
Red Env DevOps
Green Env DevOps</p>
<pre><code>                        Basics of Attributes 
</code></pre>
<p>Attributes are key-value pairs.
In AWS, these attributes are called tags.
Team:     DevOps
Location:  India Env:      Prod
Project: Green
Scalable Permission Model based on Attributes
DevOps Member 2     Single IAM Policy Red Environment
Green Environment
DevOps Member 1
IAM Policy
Allow * Access To Env Based on User Attribute</p>
<pre><code>                Attributes for IAM User 
</code></pre>
<p>You can use IAM tag key-value pairs to add custom attributes  to an IAM user.</p>
<pre><code>                Attribute-Based Access Control 
</code></pre>
<p>Attribute-based access control  (ABAC) is an authorization strategy that defines
permissions based on attributes.</p>
<pre><code>                  Permissions Based on ABAC 
</code></pre>
<p>This example shows an IAM policy that allows a principal to start or stop an
Amazon EC2 instance when the instance&rsquo;s resource tag and the principal&rsquo;s tag
have the same value for the tag key Team
Key Value
Team Green</p>
<pre><code>                         Benefits of ABAC 
</code></pre>
<p>ABAC requires fewer policies. Because you don&rsquo;t have to create different
policies for different job functions, you create fewer policies. Those policies are
easier to manage.
Permissions can easily be granted and revoked based on user’s tags.
You can even use attributes of users from corporate directory  to allow / deny
permissions to AWS resources.</p>
<pre><code>                                    External ID 
                              Setting the Base 
</code></pre>
<p>Security Corp has a SAAS software offering that scans the AWS environment of
customers and provides regular security recommendations.
Security Corp Account
Client Account 1
Client Account 2
Scan
Scan
Sample Screenshot - Populated Dashboard</p>
<pre><code>                       How is Access Granted 
</code></pre>
<p>For Security Corp SAAS software to continuously scan client’s AWS accounts,
the following steps are required:
1.Client Account needs to create cross-account IAM role to allow Security
Corp account to access resources.
2.Security Corp assumes that role, scans the resources and provides findings
in the central dashboard.
Confused Deputy Problem
The confused deputy problem is a security issue where an entity that doesn&rsquo;t
have permission to perform an action can coerce a more-privileged entity to
perform the action.
Security Corp Account Client Account 1 Client 1 Role ARN
Attacker Account 1 Client 1 Role ARN</p>
<pre><code>                                 The W orkflow 
</code></pre>
<p>1.When you start using Security Corp&rsquo;s service, you provide the ARN of
Client1:ExampleRole to Security Corp.
2.Security Corp assumes this cross account role to gain access to your AWS
account.
3.Another customer also starts using Security Corp service, and this customer
also provides Client1:ExampleRole to Security Corp
4.Security Corp assumes this Client1:ExampleRole on behalf of Customer 2
and shares also security related findings with Customer 2.</p>
<p>Sample Screenshot - Client Adding IAM Role Details</p>
<pre><code>                   Introducing External ID 
</code></pre>
<p>External ID is used along with the Role ARN to be able to assume it.
This acts as an additional verification check and must match to assume role.
Security Corp Account Client Account 1 Client 1 Role ARN + 23853243</p>
<pre><code>                             Points to Note 
</code></pre>
<p>Security Corp must generate an unique ExternalId  value for each customer.
The ExternalId value must be unique among Security Corp&rsquo;s customers and
controlled by Security Corp, not its customers.</p>
<pre><code>                         IAM Policy with External ID 
</code></pre>
<p>Security Corp gives the external ID value of 12345 to you.
You must then add a Condition element to the role&rsquo;s trust policy that requires the
sts:ExternalId value to be 12345, like this:</p>
<p>Centralized Logging
Architectural Perspective
Centralized Logging
knowledge portal A comprehensive log management and analysis strategy is mission critical in an organization.
It enables the organizations to understand the relationship between operational, security ,
and change management events and maintain a comprehensive understanding of their
infrastructure.
Account A
Account BLogging Account
CloudTrail
Config
Challenges with Logging
knowledge portal In a Multi-Account based architecture, log monitoring at an individual account level is not
the best of the approaches.
Development Account
Staging Account
Production Account
CloudTrail CloudTrail CloudTrail Guard Duty Guard Duty Guard Duty EC2 EC2EC2    Splunk
Recommended Architecture for Logging
knowledge portal A comprehensive log management and analysis strategy is mission critical in an organization.
One of the recommended approaches is to use a Centralized Logging Account.
Account A
Account BCentral Logging Account
CloudTrail
Config   Splunk
Considerations while implementing Logging
knowledge portal
Define log retention requirements and lifecycle policies early on.
Incorporate tools and features to automate the lifecycle policies.
Automate the installation and configuration of log shipping agent.
Make sure the solution supports hybrid environment to support the needs.</p>
<p>A WS Services to Help!
knowledge portal W e can make use of A WS Managed service to build centralized logging solutions.
Services which can help here:
● A WS ElasticSearch Service
● A WS CloudW atch Logs
● Kinesis Firehose
● A WS S3
W ays to configure centralized logging for each A WS service (CloudT rail, VPCFlow) differs.</p>
<p>Considerations - S3 Bucket Policy for Cross-Account
Architectural Perspective
Challenges with S3 Bucket Policy
knowledge portal A wildcard based S3 bucket policy allowing CloudT rail service would mean that any A WS
account’s CloudT rail can put its data to your S3 bucket.</p>
<p>Bucket Policy with Conditional Statement
knowledge portal As a security best practice, add an aws:SourceArn  condition key to the Amazon S3 bucket
policy . This helps prevent unauthorized access to your S3 bucket.</p>
<pre><code>        Unified CloudW atch Agent 
  Metrics and Logs 
                            Default CloudW atch Metrics 
</code></pre>
<p>When we launch an EC2 instance in A WS, there are certain metrics that are captured by default.
Some of these include:
● CPU Utilization
● Network Related
● Disk Related
knowledge portal
Challenge 1 -More Metrics Are Needed
There are various important metrics that needs to be collected in addition to the default ones.
Some of these include:
● Memory Metrics
● Disk Usage Metrics
● Netstat related.
knowledge portal</p>
<p>Challenge 2 - Log Monitoring
knowledge portal A server can contain a lot of log files, from system logs to the application logs.
During debugging, it is important to have log files at hand.
This means in default case; you need to give access to the server to an individual who wants to
debug.
log line 01 - GET request
log line 02 - PUT request
log line 03 - DELETE
log line 04 - PATCH
log line 05 - POST
log line 06 - PUT  request file.log
Disadvantage of the Approach
knowledge portal Access must be given to the server to the developers.
If the server gets terminated, the logs are lost.
No way to set up an alarm on certain conditions or create complex filters.
log line 01 - GET request
log line 02 - PUT request
log line 03 - DELETE
log line 04 - PATCH
log line 05 - POST
log line 06 - PUT  request file.log
Better W ay
knowledge portal ● W e create a Central Log Server.
● W e push the log files from individual systems to Central Log Server.</p>
<p>Introducing Unified CloudW atch Agent
knowledge portal Unified CloudW atch Agent allows customers to capture both the internal system level
metrics as well as logs collection.
Amazon EC2 CloudWatch Unified Agent
Metrics
Logs
How- T o Steps
knowledge portal</p>
<ol>
<li>Create a IAM Role with CloudW atchAgentServer policy .</li>
<li>Create EC2 using IAM Role.</li>
<li>Install CloudW atch Agent.</li>
<li>Run CloudW atch Agent Configuration Wizard</li>
<li>Start Unified CloudW atch Agent.
A WS License Manager
Let’s understand Licensing
Getting Started
knowledge portal In Enterprises, managing software licenses sometimes becomes quite a hassle.
Organizations uses wide variety of software licenses:
● OS Level Licenses    :  Windows, RedHat
● Database Licenses :     Oracle DB, Microsoft SQL
● Application Licenses: SAP
● Other 3rd Party Licenses</li>
</ol>
<p>Challenges
knowledge portal
In Cloud, new servers can be launched in click of a button.
License Violation detected during audit can lead to heavy penalties.
Difficult to track licenses across multiple accounts.</p>
<p>Overview of A WS License Manager
knowledge portal
A WS License Manager is a service which allows us to manage license from wide variety of
software vendors across A WS and on-premise.
W e can enforce policies  for licenses based on various factors like CPU, sockets that will
control the number of EC2 instance which can be launched.</p>
<pre><code>    AWS 
</code></pre>
<p>Launch 2 EC2 from RedHat 9
Nope. We only have 1 EC2 license
A WS Service Catalog
Standardized Stack
Understanding the W orkflow
knowledge portal A WS Service Catalog enables organizations to create and manage catalogs of IT services
that are approved for use on A WS.
Development ENV
Production ENV
Service Catalog Products Launch
t2.micro
Database
S3 Bucket Policy
Bucket Policies
Granting Permission for S3 Resource
knowledge portal
There are two primary ways in which a permission to a S3 resource is granted.
Identity Policies
Bucket Policies S3 Bucket
Use-Case 1: IAM User Needs Access to S3 Bucket
knowledge portal
IAM User Named Bob needs Full Access to S3 Bucket.
S3 Full Access IAM Policy S3 Bucket</p>
<p>Wider Scope of S3 Bucket
knowledge portal
Files within the S3 bucket can have scope beyond the IAM entity .
Organization can host entire websites in S3 Bucket.
S3 Buckets can even be used to host central files for download.
S3 Bucket</p>
<p>S3 Bucket Policy
knowledge portal
A bucket policy is a resource-based A WS IAM policy associated with the S3 Bucket to control
access permissions for the bucket and the objects in it .
S3 Bucket S3 Bucket Policy Rules
Allow Access from Internet
Allow Access from only 10.77.3.20 IP
Only Allow Access from Specific VPC
Only allow HTTPS connections
Bucket Policy 1 - Public Access
knowledge portal
The following example policy grants the s3:GetObject permission to any public anonymous
users.</p>
<p>Bucket Policy 2 - Only HTTPS
knowledge portal Only the HTTPS requests should be allowed. All HTTP requests should be blocked.</p>
<p>Cross Account S3 Access
Bucket Policies
Cross Account S3 Access
knowledge portal There are many requirements where logs across all A WS accounts need to be stored in a central
account.
These logs can include, CloudT rail, CloudW atch, Application Logs, and others.
Account B
Account CCentral S3 Bucket
EC2
EC2
Account A
Creating Bucket Policy
knowledge portal The recommended approach is to add a Bucket Policy in the Central S3 bucket and allow the
Account B to push the logs.
Account B
Central S3 Bucket
EC2
Account A Bucket Policy
Allow Account B
to Push Logs to
Central S3 Bucket
Bucket Policy Example - Central S3 Account
knowledge portal
Account B ARN
Central S3 Bucket
Part 2- Permission on Account B Side
knowledge portal The resource in the Account B also needs to have permission to push the logs to Central
Account S3 Bucket.
Account B    EC2
IAM Policy
Allow Pushing
Data to Central
S3 Bucket
IAM Policy - Account B
knowledge portal Central S3 Bucket</p>
<p>Canned ACL
Setting Right Bucket Permissions
Understanding S3 Access ACL
knowledge portal
Every bucket and it’s objects have an ACL associated with them.
When a request is received, A WS S3 will check against the attached ACL to either allow or
block access to that specific object.
account-a.txt account-b.txt
The T ricky Part
knowledge portal
When we create a bucket or an object, A WS S3 by default will grant the resource owner full
control over the resource.
Central S3 Bucket
Owner Account A Owner Account B
Ideal Architecture
knowledge portal
In most of the architectures, 3rd Party Log Monitoring / SIEM solutions connect to the
Central S3 bucket to fetch all of the data.
Account B
Account CCentral S3 Bucket
EC2
EC2
Account A
3rd Party Solution
Canned ACL
knowledge portal A WS S3 supports set of pre-defined grants, known as Canned ACL’s.
Each canned ACL has predefined set of permission associated with them.
These canned ACL can be specified in the request using x-amz-acl  header.</p>
<pre><code>                         S3 - Cross Account Replication 

                    Understanding the Basics 
</code></pre>
<p>Replicating Data across different S3 Buckets in same account is a
straightforward process.
However for requirements were Source and Destination Bucket are in different
account, there are additional configurations that are needed.
Replication
Source Account Destination Account
End to End W orkFlow Steps
1.IAM Role in the Source Account is required with trust relationship with S3.
2.S3 Bucket Policy in Destination Account to Allow Replicate related
operations from Source Account.
3.Setting up Replication Rule with appropriate IAM Role.
Replication
Source Account Destination Account IAM Role
Bucket Policy</p>
<p>CloudFormation - StackSets
Need to learn the backend
Getting Started
knowledge portal CloudFormation StackSets basically allows us to deploy stacks across multiple A WS
account / A WS regions from single location.
Simple Use-Case:
● A WS Config is recommended to be enabled in all regions.
● Before we had to maintain stack across each region.
● This can now be solved easily using Stack Sets</p>
<p>Deployment Instruction
knowledge portal T wo IAM Roles required:
1 for the Administrator Account of StackSets
1 for the Destination A WS Accounts.
Role Name for Admin Account:  A WSCloudFormationStackSetAdministrationRole
Role Name for Dest Account:      A WSCloudFormationStackSetExecutionRole</p>
<p>Active Directory
Directory Service
knowledge portal
T raditional W ay</p>
<p>knowledge portal
Better W ay</p>
<p>Active Directory
knowledge portal Active Directory is one of the most popular directory service developed by Microsoft.
The server running the Active Directory service is called as the domain computer and
it can authenticate and authorize the users and computers which are associated to it.</p>
<p>A WS Directory Service
Directory on the Cloud
Challenges with Active Directory
knowledge portal For those who have set up an AD knows, this can be a challenging and time-consuming
process.
Some of the challenges involved can be:</p>
<ul>
<li>Provisioning the Infrastructure.</li>
<li>Installing the directory software</li>
<li>Getting replication setup between domain controllers for HA</li>
<li>Monitoring / Patching and many more.</li>
</ul>
<p>Directory Service in the Cloud
knowledge portal A WS Directory Service is a managed service based on the cloud that allows us to create
directories and let A WS experts handle and manage the other parts like high availability ,
monitoring, backups, recovery , and others.
There are three important components :</p>
<ul>
<li>Active Directory Service with Microsoft Active Directory</li>
<li>Simple AD</li>
<li>AD Connector</li>
</ul>
<p>Directory Service with Microsoft AD
knowledge portal A WS Directory Service for Microsoft Active Directory is powered by an actual Microsoft
Windows Server Active Directory (AD) in the A WS Cloud.
There are two types:</p>
<ul>
<li>Standard Edition   &ndash; For small and midsize ( up to 5000 users )</li>
<li>Enterprise Edition &ndash; For larger deployments.</li>
</ul>
<p>AD Connector
knowledge portal
● It is a proxy service that provides easy way to connect applications in cloud to your
existing on-premise Microsoft AD.
● When users log in to the applications, AD Connector forwards sign-in requests to your
on-premises Active Directory domain controllers for authentication.
Active Directory AD Connector Cloud Resources
Simple AD
knowledge portal
● Simple AD is a Microsoft Active Directory–compatible directory from A WS Directory
Service that is powered by Samba 4.
● Simple AD supports basic Active Directory features such as user accounts, group<br>
memberships, joining a Linux domain or Windows based EC2 instances, Kerberos-based<br>
SSO, and group policies. A WS provides monitoring, daily snapshots, and recovery as part of<br>
the service.
● Simple AD does not support trust relationships, DNS dynamic update, schema extensions,<br>
multi-factor authentication, communication over LDAPS, PowerShell AD cmdlets, or  FSMO<br>
role transfer.</p>
<p>Federation
Connecting Identities
@systems            Understanding the Challenge
Let’s assume there are 500 users within an organization. Y our organization are using
3 services :-
● A WS ( Infrastructure )
● Jenkins ( CI / CD )
● HR Activator  ( Payroll )
Y ou have been assigned role to give users access to all 3 services.
knowledge portal
knowledge portal               Storing Users Centrally</p>
<p>knowledge portal</p>
<p>@systems                     Central Users
There are various solutions available which can store users centrally :-
● Microsoft Active Directory
● RedHat Identity Management / freeIP A
knowledge portal
@systems   Basics of Federation - AWS Perspective
Federation allows external identities ( Federated Users ) to have secure access in your
A WS account without having to create any IAM users.
These external identities can come from :-
●       Corporate Identity Provider ( AD, IP A )
●       W eb Identity Provider  ( Facebook, Google, Amazon, Cognito or OpenID )
knowledge portal
@systems                Basic Workflow
knowledge portal</p>
<p>@systems          Understanding Identity Broker
Identity Broker :-
It is an intermediate service which connects multiple providers.
knowledge portal
Identity Broker
knowledge portal                    <br>
User Sign In Authenticate User
Auth Response
Sign In with Auth
Response Token
Calls the STS service
A.R
User Sign In Authenticate User
Auth Response
Sign In with Auth
Response Token
Calls the STS service
A.R        AWS
User Sign In Authenticate User
Auth Response
Sign In with Auth
Response Token
Calls the STS service
A.R        AWS  ADFS
@systems                     Steps to Remember
●  User logs in with username &amp; Password.
●  This credentials are given to the Identity Broker.
●   Identity Broker validates it against the AD.
●   If credentials are valid, Broker will contact the STS token service.
●   STS will share the following 4 things :-
Access Key + Secret Key + T oken + Duration
● User can now use to login to A WS Console or CLI.
knowledge portal
@systems           Notations to Remember
Identities  :   Users
Identity Broker  :
● It is a middlware that takes the users from point A &amp; help connect them to
point B.
Identity Store :-<br>
● Place where users are present. Eg : AD, IP A, Facebook etc.
knowledge portal
SAML
Single Sign On
Introduction to SAML
knowledge portal
● SAML stands for Security Assertion Markup Language.
● It is a secure XML based communication mechanism for communicating identities across
organizations.
● SAML eliminates the need to maintain multiple authentication credentials, such as
passwords in multiple locations.</p>
<p>knowledge portal                                               Classic W ay</p>
<pre><code>                                Challenges with classic way 
</code></pre>
<p>knowledge portal
● The administrator does not have direct visibility with the underlying database of the
SAAS provider.
● If there are multiple SAAS providers, it is difficult to keep track of which user has access to
which SAAS application.
● When the user leaves the organization, he needs to be removed from all the entities
(Jenkins, A WS, HR app)
Different Views
knowledge portal Administrator’s View                User’s View
Have to login to different
providers to manage and control
the permissions of an individual
user across the organization.
User forgetting username and
passwords, MFA :( I have to remember passwords of all
the applications in the organization.
It might be possible that even userID
across apps is different, so have to
remember that as well.        SAAS Provider’s View
Have to maintain the user and
password database of
customers.
This is a big security liability.
knowledge portal
SAML
Identity Provider
Service Provider
knowledge portal                                               The SAML W ay
IdP        SP
user / pass Sends response
POST to sign in
page with token
Redirect to Management Console
Introduction to SAML
knowledge portal
● The flow gets initiated when user opens the IDP URL and enters the username and
password and selects the appropriate application.
● IdP will validate the credentials and associated permissions and then user receives SAML
assertion from the IdP as part of response.
● User does a POST of that SAML assertion to the SAAS sign in page and SP will validate
those assertion.
● On validation, SP will construct relevant temporary credentials, and constructs sign in
URL for the console and sends to the user.</p>
<pre><code>                                IAM Identity Center 

                   Understanding the Basics 
</code></pre>
<p>IAM Identity Center (successor to AWS Single Sign-On) allows centralized
access to multiple AWS accounts and applications and provide users with single
sign-on access to all their assigned accounts and applications from one place.
IAM Identity Center
Basic Steps
Login to Access Portal Connect with AWS Accounts / Apps available
Understanding the W orkflow
Identity Store
IAM Identity Center
SSO
Fetch User Identities
SSO with A WS CLI
AWS CLI integrates with the SSO.
SSO users can authenticate via CLI, and they will be able to perform the CLI
operations without having to add keys in their ~/.aws/credentials file.</p>
<pre><code>                Benefits of IAM Identity Center 
</code></pre>
<p>Your users can use their directory credentials for single sign-on access to
multiple AWS accounts.
Enable single sign-on access to your AWS applications
Enable single sign-on access to Amazon EC2 Windows instances
Enable single sign-on access to cloud-based applications that support SAML</p>
<pre><code>  IAM Identity Center - Concepts &amp; Considerations 

            Prerequisite for Identity Center 
</code></pre>
<p>Your AWS account must be managed by AWS Organizations.
If you&rsquo;ve already set up AWS Organizations, make sure that all features are
enabled
When you enable IAM Identity Center, you will choose whether to have AWS
create an organization for you.</p>
<pre><code>                             Identity Source 
</code></pre>
<p>If you&rsquo;re already managing users and groups in Active Directory or an external
IdP, it is recommended that you consider connecting this identity source when
you enable IAM Identity Center and choose your identity source.
You can also create users and groups directly in IAM Identity Center.</p>
<pre><code>                            Permission Sets 
</code></pre>
<p>Permission sets define the level of access  that users in IAM Identity Center have
to their assigned AWS accounts
Account - Dev
Account - Stage
Account - Prod
Alice
BobPermission Sets
User Access Account
Alice ReadOnly Dev &amp; Stage
Bob Admin ALL
How it W orks
IAM Role - ReadOnly IAM Role - ReadOnly
Permission Set - ReadOnly
IAM Identity Center Create
Alice Assume Role
Points to Note - IAM Identity Center</p>
<pre><code>                   SAML Implementation 
</code></pre>
<p>IAM Identity Center supports identity federation with SAML (Security Assertion
Markup Language) 2.0.
This allows IAM Identity Center to authenticate identities from external identity
providers (IdPs</p>
<pre><code>                    Attributes in IAM 
</code></pre>
<p>You can use IAM tag key-value pairs to add custom attributes  to an IAM user.</p>
<pre><code>                Attribute-Based Access Control 
</code></pre>
<p>Attribute-based access control (ABAC) is an authorization strategy that defines
permissions based on attributes.
Permission
Allow * If User Attribute has Department of
Security IAM Role
Assume Role
How to Set Attributes?
Depending on the Identity Source, the way we set Attribute also changes.
In IAM Identity Center, we can easily set user attributes from Profile.</p>
<pre><code>                  Permissions Based on ABAC 
</code></pre>
<p>Depending on the Identity Source, the way we set Attribute also changes.
In IAM Identity Center, we can easily set user attributes from Profile.
Attribute Key Values
Department DevOps
Importance of Session T ags
Session tags  are key-value pair attributes that you pass when you assume an
IAM role or federate a user in AWS STS.
Attributes are passed as session tags. They are passed as comma-separated
key:value pairs
Federate
department: security
manager: Bob
IAM User IAM Role
Amazon Cognito
Federation
Basics of Cognito
knowledge portal Amazon Cognito provides authentication, authorization, and user management service for
your web and mobile apps.</p>
<p>Sample Use-Case
knowledge portal
Alice is a mobile developer in a start-up organization. They have begun with mobile wallet
system, and there are specific requirements as follows:
● Users should be able to sign-up with new credentials.
● User should be able to sign-in with social platforms like FB, T witter, Google.
● There should be a post sign-up process (one-time password) for verification.
● Multi-Factor authentication should be present.
● Account recovery feature should be  present.
In-Short: Build a Complete Authentication &amp; Authorization System</p>
<p>Amazon Cognito
knowledge portal At a high level, there are two major features under Amazon Cognito
i) User Pools
ii) Identity Pools
Cognito user pool takes care of the entire authentication, authorization process .
Identity pool provides the functionality of federation for users in user pools.</p>
<p>Identity Pool
knowledge portal Cognito Identity pools also referred to as A WS Cognito Federated Identities allows developers
to authorize the users of the application to use various A WS services.
Use-Case:
W e have a quiz based mobile application. At the end of quiz, user’s results should be stored in
the DynamoDB table.
If we hard-code the access/secret keys, chances of reverse engineering are high.</p>
<p>Cognito Identity Pool W orking - NO
knowledge portal</p>
<p>User Pool vs Identity Pool - NO
knowledge portal The Cognito Identity pool then takes these identities and federates them and then can give
secure access to the A WS services regardless of where the user comes from.</p>
<p>A WS Resource Access Manager
Let’s Share Resources
knowledge portal Overview of Resource Access Manager
A WS Resource Access Manager (A WS RAM) helps you securely share the A WS resources that
you create in one A WS account with other A WS accounts.
AWS Account 1  AWS Account 2</p>
<p>VPC Sharing in A WS
Let’s Share Subnets
Understanding the Basics
VPC sharing allows multiple A WS accounts to create their application resources, such as EC2
instances, RDS, and others into shared, centrally-managed virtual private clouds (VPCs).
In this model, the account that owns the VPC (owner) shares one or more subnets with other
accounts (participants) that belong to the same organization from A WS Organizations.</p>
<p>AWS Account 1  AWS Account 2
Share Subnet
Important Note
VPC owners are responsible for creating, managing, and deleting the resources associated with a
shared VPC. These include subnets, route tables, network ACLs and others.
VPC owners cannot modify or delete resources created by participants, such as EC2 instances
and security groups
Default subnets cannot be shared.</p>
<p>knowledge portal
Billing Considerations
In a shared VPC, each participant pays for their application resources including EC2 instances,
RDS, Lambda functions and other resources.
Participants also pay for data transfer charges associated with inter-A vailability Zone data
transfer, data transfer over VPC peering connections.
VPC owners pay hourly charges across NA T gateways, virtual private gateways, transit gateways,
and other VPC specific central resources.</p>
<p>knowledge portal
T raffic Mirroring
Capture Network T raffic
Understanding the Challenge
Many organizations use various kind of wire data collection tools like Splunk stream to capture
specific type network traffic to analyze for security threats.
This used to impact the overall system performance.</p>
<p>knowledge portal</p>
<p>Basics of Feature
T raffic Mirroring is an Amazon VPC feature that you can use to copy network traffic from an
elastic network interface.
Y ou can then send the traffic to out-of-band security and monitoring appliances for:</p>
<p>knowledge portal
Monitoring Instance Mirror NW Traffic
Mirror NW Traffic
Set of EC2 Instances
Relax and Have a Meme Before Proceeding
knowledge portal</p>
<pre><code>                                  VPC Endpoints 
                   Understanding the Challenge 
</code></pre>
<p>For EC2 instances to be able to connect to other AWS services, the traffic had to
flow via the Internet.
AWS Services
Internet
Challenge with Private W orkloads
For sensitive workloads that DO NOT Internet connectivity , it becomes a big
challenge.
Internet<br>
Gateway Public Subnet
EC2
Isolated Private Subnet
EC2
No Internet Route
AWS Services</p>
<pre><code>          Main Challenge &amp; Customer Demand 
</code></pre>
<p>If ALL the resources are hosted in AWS, why do they need Internet for
communication between each other?
Customer needs a way in which the communication between AWS services can
happen privately through AWS Network.
This can lead to better security, lower latency and lower cost.
Downsides of Public Internet
1.Data Transfer Cost of AWS
2.Higher Latency
3.Can bottleneck your Internet Gateway.
4.Security
Introducing VPC Endpoints
VPC Endpoints allows us to connect VPC to another AWS services OR other
supported services over AWS private network .
EC2VPC Endpoint
Isolated Private Subnet
AWS Services
T ypes of VPC Endpoints
There are three primary types of VPC Endpoints that are available
VPC Endpoints
Gateway Endpoints Interface Endpoints Gateway Load balancer Endpoints
Gateway VPC Endpoints
T ypes of VPC Endpoints
There are three primary types of VPC Endpoints that are available
VPC Endpoints
Gateway Endpoints Interface Endpoints Gateway Load balancer Endpoints
Gateway Endpoints Architecture
A gateway endpoint targets specific IP routes  in VPC route table, in the form of a
prefix-list , used for traffic destined to DynamoDB or S3.
Destination Target
172.31.0.0/16 local
pl-1a2b3c4d vpce-11bb22cc
Route Table
Supported Services
Gateway VPC Endpoints supports only S3 and DynamoDB Service.</p>
<pre><code>  Gateway VPC Endpoints - Practical Architecture 
                            Aim of this Video 
</code></pre>
<p>EC2 instance in private subnet should be able to connect to S3 service using
Gateway VPC Endpoints.
Destination Target
172.31.0.0/16 local
pl-1a2b3c4d vpce-11bb22cc
Route Table
Step 1 - Private Subnet in VPC
All the subnets in Default VPC are Public by default (Has Internet Gateway route)
We will convert one subnet to Private by associating a different route table to it
which does not have Internet Gateway association.</p>
<pre><code>                    Step 2 - Create IAM Role 
</code></pre>
<p>For EC2 instance to communicate to S3 Bucket, we have to create an IAM Role
with appropriate S3 Policy.</p>
<pre><code>                 Step 3 - Launch EC2 Instance 
</code></pre>
<p>1.We will launch EC2 instance in Private Subnet.
2.We will launch EC2 instance in Public Subnet.</p>
<pre><code>     Step 4 - Create S3 Buckets for T esting 
</code></pre>
<p>Create any random S3 bucket for testing.
If you already have any S3 bucket, you can ignore this step.</p>
<pre><code>                    Step 5 - T est Connectivity 
</code></pre>
<p>1.Connect to Public EC2 Instance.
2.From Public EC2, connect to the Private EC2 instance.
Results: No S3 connectivity should be present.
Step 6 - Create Gateway Endpoint
In this step, we will create a Gateway VPC Endpoint for S3 and associate it with
the Private Subnet.</p>
<pre><code>                 Step 7 - T est Connectivity 
</code></pre>
<p>1.Connect to Private EC2 instance using preferred way.
2.Verify if you are able to connect to S3 service.</p>
<pre><code>                 Gateway VPC Endpoint Policies 
                   Understanding the Challenge 
</code></pre>
<p>By default, Gateway VPC Endpoint will allow EC2 instances to connect to ALL
the destination resources (S3 Buckets) [provided permissions are present]
test-bucket
stage-bucket
sensitive-bucket
Default Policy of Gateway Endpoint
The access to ALL S3 buckets is allowed because of the Default Gateway
Endpoint Policy that gets associated.</p>
<pre><code>                  Customization on the Policy 
</code></pre>
<p>Based on requirements, we can customize the Gateway VPC Endpoint policy to
allow access to only certain S3 buckets.</p>
<pre><code>             Point to Remember - Policy Decision 
</code></pre>
<p>There are multiple places in which permission can be DENIED for a resource.
IAM Policy, VPC Endpoint Policy, S3 Bucket Policy.
ONE Deny = Total Deny of Request.</p>
<pre><code>                              Interface Endpoints 
                          Basic Architecture 
</code></pre>
<p>An interface endpoint is an ENI with a private IP address from the IP address
range of your subnet.
The ENI serves as an entry point for traffic destined to a supported AWS service
or a VPC endpoint service.
AWS Services
Private Subnet
Interface VPC Endpoint EC2</p>
<pre><code>                            Supported Services 
</code></pre>
<p>Unlike Gateway VPC Endpoints, the Interface Endpoints supports lots of
services.</p>
<pre><code>                   Security Group Integration 
</code></pre>
<p>Since the Interface Endpoints uses ENI, you can associate a security group to it.
This allows customers to restrict access to endpoint based on their
requirements.
SG Rules
Allow 443 from 172.31.20.50/32
Allow 443 from 172.31.0.5/32 Interface Endpoint ENI
On-Premise Support
Since Interface Endpoints creates an Elastic Network Interface inside the VPC,
the on-premise systems can connect to it via VPN and Direct Connect.</p>
<pre><code>                           VPC Endpoint Services 
                       Understanding the Basics 
</code></pre>
<p>Organizations widely use many 3rd party solutions like Data Dog, New Relic etc
to create dashboards related to systems / application performance.
To create such dashboards, organization has to send appropriate metrics to 3rd
party servers.</p>
<pre><code>                       Understanding the Challenge 
</code></pre>
<p>These system and applications metrics are generally sent via the Internet to 3rd
Party service provider servers.
Consumers Service Providers
Send Metrics Receive Metrics
Internet</p>
<pre><code>                  Better Solution - Internal Network 
</code></pre>
<p>If both Consumers and Service Providers are hosted in AWS, these metrics can
be sent via AWS Private Network instead of the Internet.
This can provide many advantages related to cost, latency, and security.
Consumers Service Providers
Send Data - Internal Network</p>
<pre><code>                Possible Approach - VPC Peering 
</code></pre>
<p>In this approach, the Consumer and Service Provider VPC can establish VPC
Peering and data can then be sent over Internal Network.
Consumers Service Providers
VPC Peering
10.77.0.0/16 172.31.0.0/16</p>
<pre><code>                VPC Peering is Not Practical 
</code></pre>
<p>A Service provider can have thousands of customers.
There will be CIDR overlapping issues.
Consumer 1
Service Providers
Send Data - Internal Network
10.77.0.0/16 172.31.0.0/16
Consumer 2
10.77.0.0/16</p>
<pre><code>                      Consumer Requirements 
</code></pre>
<p>Consumer and Service Provider VPC should be able to communicate with each
other through AWS Internal Network without worrying about CIDR overlaps</p>
<pre><code>                Introducing VPC Endpoint Services 
</code></pre>
<p>Using Interface Endpoints, AWS allows connecting to the Service Provider VPC
The traffic flows through AWS Private Network.</p>
<p>Load Balancing in A WS
Let’s Load Balance T raffic in A WS
Basics of Load Balancing
There are multiple software and hardware based load balancing solutions available.
Some of the popular ones include Nginx, HA Proxy and others.
knowledge portal</p>
<p>Challenges with Maintaining Load Balancing Solution
If you are using a load balancing solution, various responsibilities falls to customer.
Some of these include:</p>
<ol>
<li>
<p>High-A vailability of Load Balancers.</p>
</li>
<li>
<p>Security .</p>
</li>
<li>
<p>Performance.
knowledge portal
Basics of Elastic Load Balancing Service
A WS offers managed load balancing solutions for wide variety of use-cases.
These solutions are offered under the Elastic Load Balancing feature.
Tight integration with multiple A WS Services.</p>
<p>knowledge portal
Auto Scaling WAF ACM Integrations
Elastic Load Balancing
T ypes of Load Balancers
There are 4 primary type of Load Balancer offerings available.</p>
<p>knowledge portal    Load Balancer Types  Application Load Balancer
Network Load Balancer
Gateway Load Balancer
Classic Load Balancer
Application Load Balancers
An Application Load Balancer makes routing decisions at the application layer (HTTP/HTTPS)</p>
<p>knowledge portal
Application Load Balancer
/videos Server 1
/payment Server 2
example.com/videos
User /videos
Server 1
Server 2
Network Load Balancers
A Network Load Balancer makes routing decisions at the transport layer (TCP/UDP/SSL).
It can handle millions of requests per second.
Not all of the applications work on HTTP/HTTPS protocol.
Network Load Balancer Server 1
Server 2 Millions of Requests
Gateway Load Balancers
Gateway Load Balancers allow you to deploy , scale, and manage virtual appliances, such as firewalls,
intrusion detection and prevention systems, and deep packet inspection systems
knowledge portal  Gateway Load Balancer
Virtual Appliance     IPS
IPS
Classic Load Balancers
A Classic Load Balancer makes routing decisions at either the transport layer (TCP/SSL) or the
application layer (HTTP/HTTPS).
Previous Generation Load Balancer and not recommended.
knowledge portal
TCP HTTPS
Summary Slide
knowledge portal Load Balancer Important Notes
Application Load Balancer Use when you have websites/applications at L7 (HTTP/HTTPS)
Network Load Balancers TCP and UDP based applications.
Requirement to handle millions of requests per second.
Ultra high performance.
Gateway Load Balancer Use when you have virtual appliances:
IDS/IPS
Firewalls
OSI Model &amp; Load Balancers
Revising Networking
Basics of OSI Model
The Open Systems Interconnection (OSI) model describes seven layers that computer systems
use to communicate over a network. It</p>
<p>knowledge portal</p>
<p>knowledge portal                Load Balancer &amp; OSI Layers
Each load balancer operates at a specific layer.
Y ou will only be able to perform operations on requests based on Layer the ELB supports.</p>
</li>
</ol>
<p>Classic Load Balancers
First generation Load Balancers
knowledge portal   Understanding Classic Load Balancers
These are older generation of load balancers.
Provides basic set of features for HTTP , HTTPS, TCP and SSL protocols.
Classic ELB
knowledge portal       Limitation of Classic Load Balancers
● Does not support native HTTP/2 protocol.
● IP address as targets are not supported.
● Path based routing is not supported. (eg: /images should go to server 1 &amp; / php to server
02)
● Many Many more …..</p>
<p>Application Load Balancers
Next generation load balancers
knowledge portal                 Basics of HTTP Headers
HTTP headers let the client and the server pass additional information with an HTTP request
or response.</p>
<p>knowledge portal                  Understanding ALB
Application Load Balancer functions at Application layer and support both HTTP &amp; HTTPS
Routing Based On
HTTP Headers
Application Load Balancer
Path Based Routing
The request are routed based on the URI path.
Application Load Balancer Path Based Rules Destination
/videos Server 1 and 2
/payment Server 3 and 4
example.com/videos example.com/payments
Routing Using Host Headers
The request are routed based on the Host Header
Application Load Balancer Host Header Destination
example.com Server 1 and 2
.in Server 3 and 4
<a href="http://example.com" rel="external" target="_blank">http://example.com</a> http://.in
Listener &amp; T arget Groups
Next generation load balancers
knowledge portal                  Understanding Listeners
A listener is a process that checks for connection requests, using the protocol and port that you
configure.
Listener 1
Listener 2 Protocol Port
HTTP 80
Protocol Port
HTTPS 443ELBhttp://example.com
knowledge portal                         Listener Rules
Each listener has a rule based on which an action is taken based on a request.
Listener 1
ELBhttp://example.com Listener Rules
Check if User-Agent is Mozilla
Check if Host Header is demo.com
Check if path is /videos
knowledge portal                      Listener Rule Actions</p>
<pre><code>Listener 1 Listener Rules 
</code></pre>
<p>Check if User-Agent is Mozilla
Check if Host Header is demo.com
Check if path is /videos Rule Actions
Forward To
Redirect To
Return Fixed Response
If a request matches a specific rule, what action you want to perform on that request is
determined in the Rule Actions.</p>
<p>knowledge portal</p>
<p>knowledge portal            Understanding T arget Groups
T arget group is used to route requests to one or more registered targets.
These targets can be EC2 instances, Lambda Functions, and others.
Target Group 1   Target Group 2</p>
<p>knowledge portal                       Overall W orkflow
Listener 1
Listener 2 ELBhttp://example.com  Target Group 1
Target Group 2</p>
<p>Network Load Balancers
Next generation load balancers
knowledge portal                  Understanding NLB
Network Load Balancer works on the fourth layer of the OSI model.
It can handle millions of requests per second.</p>
<p>knowledge portal                     Basic W orking
NLB primarily selects a target using a flow hash algorithm  based on:
Protocol, Source IP address, Source port, Destination IP address, Destination port, and TCP
sequence number.</p>
<p>Each individual TCP connection is routed to a single target for the life of the connection.</p>
<p>Relax and Have a Meme Before Proceeding
knowledge portal</p>
<p>A vailability Zones and ELB  nodes
ELB Interfaces
A vailability Zones and ELB  nodes
When you enable an A vailability Zone for your load balancer, Elastic Load Balancing creates a
load balancer node in the A vailability Zone.
If you register targets in an A vailability Zone but do not enable the A vailability Zone, these
registered targets do not receive traffic.</p>
<p>AZ1
AZ2
ELB
Recommendations
With an Application Load Balancer, it is a requirement that you enable at least two or more
A vailability Zones. If one A vailability Zone becomes unavailable or has no healthy targets, the
load balancer can route traffic to the healthy targets in another A vailability Zone.</p>
<p>After you disable an A vailability Zone, the targets in that A vailability Zone remain registered
with the load balancer. However, even though they remain registered, the load balancer does
not route traffic to them.
knowledge portal
Cross Zone Load Balancing
Interesting Learning
Understanding the Challenge
If Cross Zone Load Balancing is disabled, each load balancer node distributes traffic only across
the registered targets in its A vailability Zone.</p>
<p>knowledge portal
50% 50%
Cross Zone Load Balancing Disabled
Each of the two targets in A vailability Zone A receives 25% of the traffic.
Each of the eight targets in A vailability Zone B receives 6.25% of the traffic.</p>
<p>knowledge portal</p>
<pre><code>         Cross Zone Load Balancing 
</code></pre>
<p>When cross-zone load balancing is enabled, each load balancer node distributes traffic across the
registered targets in all enabled A vailability Zones.</p>
<p>If cross-zone load balancing is enabled, each of the 10 targets receives 10% of the traffic.
knowledge portal</p>
<pre><code>              Important Pointers 
</code></pre>
<p>With Application Load Balancers, cross-zone load balancing is always enabled.
With Network Load Balancers and Gateway Load Balancers, cross-zone load balancing is
disabled by default. After you create the load balancer, you can enable or disable cross-zone load
balancing at any time.
knowledge portal
ELB Access Logs
Who is Visiting Us?
Overview of Access Logs
An access log is a list of all the requests for individual files that people have requested from a
W eb site
knowledge portal</p>
<p>ELB Access Logs
knowledge portal Elastic Load Balancing provides access logs that capture detailed information about
requests sent to your load balancer.
Users Access Logs
Target Group
S3
Important Pointers for Access Logs - Part 1
Access logging is an optional feature of Elastic Load Balancing that is disabled by default
Elastic Load Balancing logs requests on a best-effort basis. A WS recommend that you use access
logs to understand the nature of the requests, not as a complete accounting of all requests.
knowledge portal
Important Pointers for Access Logs - Part 2
The bucket and your load balancer must be in the same Region.
Bucket Policy should be designed so that A WS Account must be able to write to your bucket.
Elastic Load Balancing publishes a log file for each load balancer node every 5 minutes.
knowledge portal
Relax and Have a Meme Before Proceeding
knowledge portal</p>
<p>Dualstack IP Address T ype for ELBs
Enable IPv6 for ELBs
IP Address T ype Support
ELB Supports two address types:
i) IPv4
ii) Dualstack (includes both IPv4 and IPv6 addresses)
knowledge portal
192.168.0.1
2001:db8:3333:4444:5555:
6666:7777:8888. ALBUsers
Important Pointer
knowledge portal T o use IPv6 addresses, the virtual private cloud (VPC) where you launch your ELB must
have subnets with associated IPv6 CIDR blocks
IPv6 addresses can be associated only with internet-facing Application Load Balancers and
Network Load Balancers.
Internal Application Load Balancers, Classic Load Balancers, and Network Load
Balancers do not support IPv6 addresses.</p>
<pre><code>                   Sticky Sessions 
   Direct Users to the Same Server 
                     Understanding the Challenge 
</code></pre>
<p>Generally the Load Balancers will distribute the traffic from the users to the backend servers via
the round robin algorithm.
If subsequent requests are routed to different servers, your session state information is lost.
knowledge portal
Importance of Sticky Session
Sticky session refers to the feature of many commercial load balancing solution to route the
requests for a particular session to the same physical machine that serviced the first request for
that session.
knowledge portal</p>
<p>Sticky Session and A WS Load Balancers
By default, an Application Load Balancer routes each request independently to a
registered target based on the chosen load-balancing algorithm.
However, you can use the sticky session feature to enable the load balancer to bind a user&rsquo;s
session to a specific target</p>
<p>Overview of the W orkflow
Cookie
target=EC2-1  cookie GET index.html EC2-1
EC2-2
Advantages of Sticky Sessions
knowledge portal When sticky sessions are used, the servers do not need to exchange the sessions data which
can minimize the data transfers.
Sticky Sessions can also allow better utilization of your RAM Cache that leads to better
responsiveness</p>
<p>Disadvantage of Sticky Sessions
knowledge portal With sticky sessions, the overall balancing of traffic between servers can be affected.
A server can become overloaded if it accumulates too many sessions, or if specific sticky
sessions require a high number of resources.</p>
<pre><code>                                 Duration Based Stickiness 
</code></pre>
<p>When a load balancer first receives a request from a client, it routes the request to a target
(based on the chosen algorithm), and generates a cookie named A WSALB.
It encodes information about the selected target, and includes the cookie in the response
to the client
In subsequent requests, the client should include the A WSALB cookie. When the load
balancer receives a request from a client that contains the cookie, it detects it and routes
the request to the same target</p>
<p>knowledge portal
Application Based Stickiness
The target is expected to set a custom application cookie.
When the ALB  receives the custom application cookie from the target, it automatically
generates a new encrypted application cookie to capture stickiness information.
The load balancer generated application cookie does not copy the attributes of the custom
cookie set by the target. It has its own expiry of 7 days which is non-configurable</p>
<p>knowledge portal
IP Attachments to NLB</p>
<pre><code>                    Understanding the Basics 
</code></pre>
<p>Network Load Balancer automatically provides a static IP per Availability Zone
(subnet) that can be used by applications as the front-end IP of the load
balancer.
Network Load Balancer also allows you the option to assign an Elastic IP per
Availability Zone (subnet) thereby providing your own fixed IP.
After a Network Load Balancer is created, you can no longer modify its existing
subnets or NLB node Elastic IP addresses.
NLB-ALB Architecture
You can&rsquo;t assign a static IP address to an Application Load Balancer.
If you need a static IP address for your Application Load Balancer, it&rsquo;s a best
practice to register the Application Load Balancer behind a Network Load
Balancer.
Target Group
Network Load Balancer Application Load Balancer Client
Capturing Client IP Behind ELB</p>
<pre><code>                    Understanding the Challenge 
</code></pre>
<p>In a typical setup, the backend application does not receive the IP address of
client.
GET /login.php GET /login.php
192.168.0.10 172.31.10.5 Got GET request
for login.php from
172.31.10.5
Points to Note
Load Balancer Type Description
Classic Load Balancer For HTTP based listeners, Client IP is forwarded by default to the servers.
For TCP based listeners, Proxy Protocol needs to be enabled.
Application Load Balancer Client IP is passed with the request. Use X-Forwarded-For headers in application
to capture the client address.
Network Load Balancer Client IP preservation is enabled (and can&rsquo;t be disabled) for instance and IP type
target groups with UDP and TCP_UDP protocols.
You can enable or disable client IP preservation for TCP and TLS target groups
HTTPS Listener</p>
<pre><code>                    Understanding the Challenge 
</code></pre>
<p>In a typical setup, the end to end connection through ELB remains unencrypted.
GET /login.php GET /login.php
192.168.0.10 172.31.10.5
Basic Architecture
You can create an HTTPS listener, which uses encrypted connections (also
known as SSL offload).
This feature enables traffic encryption between your load balancer and the
clients that initiate SSL or TLS sessions.
GET /login.php
192.168.0.10 172.31.10.5 Encrypted
Certificate
Points to Note
To use an HTTPS listener, you must deploy at least one SSL/TLS server
certificate on your load balancer.
The load balancer uses a server certificate to terminate the front-end connection
and then decrypt requests from clients before sending them to the targets.</p>
<pre><code>                        End to End Encryption 
</code></pre>
<p>With ALB, you can terminate the connection at ALB level and Initiate new
encrypted connection to EC2.
If you need to pass encrypted traffic to targets without the load balancer
decrypting it, you can create a Network Load Balancer or Classic Load Balancer
with a TCP listener on port 443.
192.168.0.10 172.31.10.5 Encrypted Encrypted
Certificate
Certificate
326                  RDS Read Replicas</p>
<pre><code>                                    Use Case : Bank 
</code></pre>
<p>In bank, for different kind of work purpose, there are different people you might
have to approach. For example :
-Cash Collector
-Cheque Counter
-Enquiry Counter</p>
<pre><code>                                     Database W ay 
</code></pre>
<p>Using a single database for all kind of activity will increase the database load
and slow down the operations.
Database connect ()
Improved Architecture - Read Replica
Read Replica allows customers to offload read requests or analytics traffic from
the primary instance
Replication Primary DB
Read Replica All WRITE Operations
All READ Operations
RDS Read Replica
RDS Read Replica feature allows customers to implement “Database Read
Replica” functionality for RDS databases.
Primary Database
Read Replica Replication
Pointers to Note - 1
You can create one or more replicas of a given source DB Instance and serve
high-volume application read traffic.
Primary Database
Read Replica 1 Replication
Read Replica 2
Pointers to Note - 2
With Amazon RDS, you can create a read replica in a different AWS Region
from the source DB instance.
Replication
us-east-1 ap-south-1
333 Amazon RDS Multi AZ Deployments</p>
<pre><code>                     Understanding the Challenge 
</code></pre>
<p>If database is running in a specific availability zone and if the AZ is down or
unreachable then your entire application can be impacted.
Availability Zone 1
Clients connect ()
Multi-AZ Architecture
In this approach, Amazon creates a standby DB instance and synchronously
replicates data from the primary DB instance in a different availability zone.
Availability Zone 1
Clients
Availability Zone 2 Replication Primary
Standby
Failover Condition
If a planned or unplanned outage of your DB instance results from an
infrastructure defect, Amazon RDS automatically switches to a standby replica
in another Availability Zone if you have turned on Multi-AZ.
●Loss of availability in primary Availability Zone
●Loss of network connectivity to primary
●Compute unit failure on primary
●Storage failure on primary
Failover times are typically 60–120 seconds.</p>
<p>337        Multi AZ Deployment Types</p>
<pre><code>                   T ypes of Multi-AZ Deployments 
</code></pre>
<p>There are two primary deployment types available in Multi-AZ based approach.
Multi-AZ Instance Deployment        Multi-AZ Cluster Deployment
Approach 1 - Multi-AZ Instance Deployment
Referred to as RDS Multi-AZ with one standby
Availability Zone 1
Clients
Availability Zone 2 Replication Primary
Standby
Approach 1 - Multi-AZ Instance Deployment
Referred to as RDS Multi-AZ with one standby
Cannot perform any operation on standby replica (including read)</p>
<pre><code>        Approach 2 - Multi-AZ Cluster Deployment 
</code></pre>
<p>A Multi-AZ DB cluster has a writer DB instance and two reader DB instances in
three separate Availability Zones in the same AWS Region.</p>
<pre><code>                  Different Deployment T ypes 
</code></pre>
<p>Feature Single-AZ Multi-AZ with 1 Standby Multi-AZ with 2 readable
Standby
Additional Read
Capacity None (only primary) None (only primary) 2 standby DB instance
Automatic Failover
Detection None Yes Yes
Failover Duration NA New primary is available to
serve workload in as
quickly as 60 seconds New primary is available
to serve workload in
typically under 35
seconds
RDS Event Notification
Back to Notifications!
RDS Event Notification
knowledge portal
RDS Event Notification provides notification when a specific type of RDS event occurs.
These events are categorized into multiple categories like A vailability , Configuration Change,
Failure, Deletion, Low Storage and others.
SNS Topic
Storage is low Storage is low
3 45                          RDS Proxy</p>
<pre><code>                          Basics of Database Proxy 
</code></pre>
<p>Database Proxy is a intermediary between a user and database
Since the queries goes through Proxy and then to database, there are lot of
controls and optimizations that can be applied.
Proxy
Database Client
Use-Case  -  FailOver Scenarios
Proxies can be used in the scenario of master failover
Requests are maintained during the time.
Proxy Database
Client
Standby DB
Basics of Database Connections
Following are high-level steps that take place when app connects to database.
1.Application makes use of Database driver to open connection to DB.
2.Network Socket is opened in OS to connect application to DB.
3.Authentication takes place.
4.Operation Complete and Connection can be closed.
5.Network Socket is closed.
Database
Client
Connection Pooling
Database connection pooling is a way to reduce the cost of opening and
closing connections by maintaining a “pool” of open connections.
Database
Proxy Connections
Clients
Clients
RDS Proxy
AWS RDS proxy is a fully-managed database proxy for Amazon RDS.
Benefits Description
Connection Pooling Improves application performance by reducing the number of
open database connections
Availability Makes applications more resilient to database failures by
automatically connecting to a standby DB instance while
preserving application connections.
Authentication Can also enforce AWS Identity and Access Management (IAM)
authentication for databases,
Amazon Aurora
Closed Source Database
Overview of Database Offerings<br>
knowledge portal Databases are generally divided into two types:
● Open Source Databases
● Commercial Databases
Commercial Offering does come with various aspects that are not found in the open
source databases.
Open Source Databases                                Commercial Databases                                         <br>
Introducing Aurora
Amazon Aurora is a MySQL and PostgreSQL-compatible relational database built for
the cloud, that combines the performance and availability of traditional enterprise
databases with the simplicity and cost-effectiveness of open source databases.
Amazon Aurora is up to five times faster than standard MySQL databases and three
times faster than standard PostgreSQL databases.
It provides the security , availability , and reliability of commercial databases at 1/10th the
cost
Performance /
Availability of
Enterprise Databases Simplicity and Cost
Effectiveness of Open
Source Databases
Amazon Aurora
RDS - Multi-AZ &amp; Read Replica Architecture
knowledge portal In a typical setup, primary , standby and read replicas are three different instances in
multiple availability zones. The underlying storage is EBS volume.
Standby Instance Primary Instance Read Replica Synchronous
Replication Asynchronous
Replication
AZ 2 AZ 1 AZ 3
RDS with EBS Storage
knowledge portal
EBS Volume RDS with MySQL
Aurora Architecture
knowledge portal T wo Primary Components:  DB Instances + Storage Cluster V olume
Since Aurora and Storage Layer are independent, we can scale the storage easily .
Write Write   Availability Zone
Availability Zone
Availability Zone</p>
<p>Overview of Storage V olume
knowledge portal                                                 Cluster Storage Volume  Availability Zone 1
Availability Zone 2
Availability Zone 3</p>
<p>Scalability Aspect in Aurora
knowledge portal With this architecture, you can add a DB instance quickly because Aurora doesn&rsquo;t make
a new copy of the table data. Instead, the DB instance connects to the shared volume
that already contains all your data.
Write Write   Availability Zone
Availability Zone
Availability Zone</p>
<p>Scale at a Faster Pace
knowledge portal                                                 Cluster Storage Volume  Availability Zone 1
Availability Zone 2
Availability Zone 3</p>
<p>Aurora Architecture
knowledge portal T wo Primary Components:  DB Instances + Storage Cluster V olume
Since Aurora and Storage Layer are independent, we can scale the storage easily .
Read Write Write Write Read Read
Primary Instance Aurora Read Replica Aurora Read Replica
Aurora Architecture
knowledge portal</p>
<p>Aurora Endpoints
knowledge portal Y ou can connect to Aurora Cluster through endpoints.
Endpoints is Aurora Specific URL consisting of host and port.
There are three primary types of endpoints available:
● Cluster Level Endpoints
● Reader Level Endpoints
● Instance Level Endpoints</p>
<p>Cluster Endpoint   Reader Endpoint
Application
Aurora Endpoints
knowledge portal Endpoint Types Description
Cluster Level Endpoints Connects to current primary DB instance in the cluster.
Used for performing write operations.
Reader Level Endpoints Built-In endpoints for Read Replicas.
For Multiple Read Replicas, this endpoint will balance load
among all read replicas.
Instance Endpoints Allows connection directly to the instance.
Custom Endpoints Ability to create custom endpoints for our own requirements.
Aurora Features
knowledge portal Aurora provides wide variety of interesting features. Some of these includes:
Global Databases Serverless
Cross Region
Replication Auto-Scaling
BackTrack IAM DB Authentication
Sharing DB Clusters  RDS Proxy
Aurora Architecture
knowledge portal T wo Primary Components:  DB Instances + Cluster V olume
Since Aurora and Storage Layer are independent, we can scale the storage easily .
Primary Instance Aurora Read Replica Aurora Read Replica
Aurora Serverless
Auto-Scaling Database
Understanding the T ypical Setup
knowledge portal In a typical DB setup, one of the primary configuration during database setup is DB
instance size.
Example: t2.small
If your workload changes, you can modify the DB instance class size</p>
<p>Challenge with the Approach
knowledge portal In some environments, workloads can be intermittent and unpredictable.
There can be periods of heavy workloads that might last only a few minutes or hours,
and also long periods of light activity , or even no activity .
In these cases, it can be difficult to configure the correct capacity at the right times. It
can also result in higher costs when you pay for capacity that isn&rsquo;t used.</p>
<p>Choices for Customers
knowledge portal Provision For Peak        Expensive
Provision Less Than Peak End-user (business) impact
Continually Monitor and
Adjust capacity manually Require Experts &amp; Risk Outages
Aurora Serverless
knowledge portal Aurora Serverless automatically scales up and down based on the capacity your
workload consumes.
When DB is idle, it will automatically be shut down, and when workload resumes, it will
automatically spin it back up.
Y ou set the minimum and maximum capacity .
2 GB RAM              488 GB RAM
Pooled Aurora Resources
knowledge portal
W arm Instance Pool represents a warm fleet of instances that can be easily swapped in to
add capacity to your environment.
These instances are allocated in a range of sizes, providing Aurora Serverless with a more
granular approach to how it responds to variations in load.</p>
<pre><code>         Aurora Global Database 
</code></pre>
<p>Scalability Aspect
Overview of Global Database
knowledge portal Aurora Global Database allows a single Amazon Aurora database to span multiple A WS
regions.
It replicates your data with no impact on database performance, enables fast local reads
with low latency in each region, and provides disaster recovery from region-wide
outages.</p>
<p>Replication Approach
knowledge portal Data is replicated based on asynchronous replication between the storage layer of the
two regions.
Primary Region      Secondary Region Asynchronous<br>
Replication</p>
<p>Important Pointers
knowledge portal
Global Database does not support automated failover to the secondary region. This step
is manual.
Not all instance types are supported. Y ou can&rsquo;t use db.t2 or db.t3 instance classes.
Certain features like Backtrack are not supported.
Stopping and starting the DB clusters within the global database is not supported.
RDS Storage Auto-Scaling
Auto-Scaling Storage
Overview of Storage Auto Scaling
knowledge portal RDS Storage Auto Scaling automatically scales storage capacity in response to growing
database workloads, with zero downtime
Storage
Storage
Important Pointers to Remember
knowledge portal Amazon RDS starts a storage modification for an auto scaling-enabled DB instance
when these factors apply:</p>
<ol>
<li>Free available space is less than 10 percent of the allocated storage.</li>
<li>The low-storage condition lasts at least five minutes.</li>
<li>At least six hours have passed since the last storage modification.</li>
</ol>
<p>Important Pointers to Remember - 2
knowledge portal Autoscaling can&rsquo;t completely prevent storage-full situations for large data loads, because
further storage modifications can&rsquo;t be made until six hours after storage optimization
has completed on the instance.
The additional storage is in increments of whichever of the following is greater:
● 5 GiB
● 10 percent of currently allocated storage
Autoscaling can&rsquo;t be used with the following previous-generation instance classes that
have less than 6 TiB of orderable storage: db.m3.large, db.m3.xlarge, and db.m3.2xlarge.</p>
<p>Relax and Have a Meme Before Proceeding
knowledge portal</p>
<pre><code>                                Aurora Scaling 

                             Storage Scaling 
</code></pre>
<p>Aurora storage automatically scales  with the data in your cluster volume.
As your data grows, your cluster volume storage expands up to a maximum of
128 tebibytes (TiB) or 64 TiB
Even though an Aurora cluster volume can scale up in size to many tebibytes,
you are only charged for the space that you use in the volume.</p>
<pre><code>                             Instance Scaling 
</code></pre>
<p>You can scale your Aurora DB cluster as needed by modifying the DB instance
class for each DB instance in the DB cluster
Aurora supports several DB instance classes optimized for Aurora, depending
on database engine compatibility.</p>
<pre><code>                               Read Scaling 
</code></pre>
<p>You can achieve read scaling for your Aurora DB cluster by creating up to 15
Aurora Replicas in a DB cluster that uses single-master replication.
Each Aurora Replica returns the same data from the cluster volume with minimal
replica lag
As your read traffic increases, you can create additional Aurora Replicas and
connect to them directly to distribute the read load for your DB cluster.</p>
<pre><code>      Aurora Auto Scaling with Aurora replicas 
</code></pre>
<p>Aurora Auto Scaling dynamically adjusts the number of Aurora Replicas
provisioned for an Aurora DB cluster using single-master replication based on
the workload.
When the connectivity or workload decreases, Aurora Auto Scaling removes
unnecessary Aurora Replicas.
You define and apply a scaling policy to an Aurora DB cluster. The scaling policy
defines the minimum and maximum number of Aurora Replicas that Aurora Auto
Scaling can manage.</p>
<p>ElastiCache
Let’s Cache
Simple Analogy
knowledge portal
● There is a new vegetable shop in the locality which has become very popular.
● Every day 300-500 people visit and buy vegetables.
● Each visitor asks the price of at-least two-three veggies before making a purchase.
Imaging the condition of the employee inside that shop after a few days.</p>
<p>Simple Analogy - Smart Approach
knowledge portal
V egetable Shop Owner decided to create a dashboard that has a list of all the common vegetable
prices which are requested by the buyers.
Price List
Veggie A - $1
Veggie B - $2
Veggic C - $C
Simple Analogy - Learning
knowledge portal</p>
<ol>
<li>Since the price list of common items was listed, users no longer need to ask the employees
about it. This reduces the overall load on the employee.</li>
<li>Visitors can quickly get to go through the price list - Better Efficiency .</li>
</ol>
<p>Challenges with Database W orkloads
knowledge portal
There can be certain common queries within the database that hundreds of users might
request.
This would increase the load on the database and can lead to performance degradation.
SELECT * from user_data;
Caching Solutions
knowledge portal
With caching solutions, you can cache the response associated with frequent queries.
This allows better response time and decreases the load on the database servers.</p>
<p>Popular Caching Solutions
knowledge portal
T wo of the most popular caching solutions used for databases are:</p>
<ol>
<li>Memcached</li>
<li>Redis
T o use them, you will have to install, configure, optimize and secure the EC2 instances where
these engines would be running.</li>
</ol>
<p>Introducing A WS ElastiCache
knowledge portal
ElastiCache is a fully managed A WS service that makes it easier to deploy , operate and scale an
in-memory data-store or cache in the cloud.
It is like a managed service and within a few clicks, we can have an in-memory layer in our infra.
ElastiCache can also detect and replace failed nodes thus reducing the overhead.</p>
<p>Core Components - DynamoDB
DynamoDB Basics
Understanding the Basics
In DynamoDB, tables, items, and attributes are the core components that you work with.
T able is a collection of items, and each item is a collection of attributes.</p>
<p>UserID Name Age Interests
1 Harsh 30 Travelling
2 Zeal 30 Astronomy
DynamoDB Table item1
item2 Attributes
knowledge portal
Importance of Primary Key
Each item in the table has a unique identifier, or primary key , that distinguishes the item from
all of the others in the table
Other than the primary key , the table is schemaless, which means that neither the attributes nor
their data types need to be defined beforehand.
UserID Name Age Interests
1 Harsh 30 Travelling
2 Zeal 30 Astronomy
DynamoDB Table Primary Key
Consistency Model<br>
Important Storage Concept
Understanding Consistency Model
knowledge portal In DynamoDB, all of your data is stored on SSDs and is automatically replicated across
multiple A vailability Zones in an Amazon Region, providing built-in high availability and
data durability .
Availability Zone 1 Availability Zone 2 Availability Zone 3
Consistency Timeline
knowledge portal
When your application writes data to a DynamoDB table and receives an HTTP 200
response (OK), the write has occurred and is durable.
The data is eventually consistent across all storage locations, usually within one second or
less.</p>
<p>Eventual Consistency Reads
knowledge portal
When you read data from a DynamoDB table, the response might not reflect the results of
a recently completed write operation.
The response might include some stale data.
If you repeat your read request after a short time, the response should return the latest
data.</p>
<p>Strong Consistency Reads
knowledge portal When you request a strongly consistent read, DynamoDB returns a response with the
most up-to-date data, reflecting the updates from all prior write operations that were
successful.</p>
<ol>
<li>A strongly consistent read might not be available if there is a network delay or
outage. In this case, DynamoDB may return a server error (HTTP 500).</li>
<li>Strongly consistent reads may have higher latency than eventually consistent reads.</li>
<li>Strongly consistent reads use more throughput capacity than eventually consistent
reads.</li>
</ol>
<p>Important Note
knowledge portal DynamoDB uses eventually consistent reads, unless you specify otherwise.
Read operations (such as GetItem, Query , and Scan) provide a ConsistentRead
parameter.  If you set this parameter to true, DynamoDB uses strongly consistent reads
during the operation.
Example Command:
aws dynamodb get-item &ndash;table-name MusicCollection &ndash;key file://key .json
&ndash;consistent-read</p>
<p>Read/W rite Capacity Units
Managing Throughput
Throughput in DynamoDB
knowledge portal Throughput is the maximum amount of capacity that an application can consume from a
table or index
Client DynamoDB
Data Throughput Pipe
Setting the Read &amp; W rite Capacity
knowledge portal W e can specify throughput capacity in terms of read capacity units (RCUs) and write
capacity units.
.</p>
<pre><code>                               Read Request Unit 
</code></pre>
<p>knowledge portal One read request unit represents one strongly consistent read request, or two eventually
consistent read requests, for an item up to 4 KB in size.
If you need to read an item that is larger than 4 KB, DynamoDB needs additional read
request units.
.
Item Size Read Capacity Unit (Strong) Read Capacity Unit (Eventual)
4 KB 1 1
8 KB 2 1
10 KB 3 2
W rite Request Unit
knowledge portal One write request unit represents one write for an item up to 1 KB in size.
If you need to write an item that is larger than 1 KB, DynamoDB needs to consume
additional write request units.
.
Item Size Write Capacity Unit
1 KB 1
4 KB 4
10 KB 10
Capacity Modes in DynamoDB
Adjust Throughput Automatically
Understanding the Challenge
W e can  specify throughput capacity in terms of read capacity units (RCUs) and write capacity
units
If your application exceeds your provisioned throughput capacity on a table or index, it is
subject to request throttling.</p>
<p>knowledge portal
Fetch 400 KB of data
Sorry Dude, I’m busy.
T ypes of Capacity Modes
There are two primary capacity modes available in DynamoDB.</p>
<p>knowledge portal
On-Demand Mode  Provisioned Mode
Provisioned Mode
If you choose provisioned mode, you specify the number of reads and writes per second that you
require for your application.
Y ou can use auto scaling to adjust your table’s provisioned capacity automatically in response to
traffic changes.</p>
<p>knowledge portal</p>
<p>Recommended T raffic Patterns for Provisioned Mode
Provisioned mode is a good option if any of the following are true:
● Y ou have predictable application traffic.
● Y ou run applications whose traffic is consistent or ramps gradually .
● Y ou can forecast capacity requirements to control costs.</p>
<p>knowledge portal
On-Demand Mode
Amazon DynamoDB on-demand is  capable of serving thousands of requests per second
without capacity planning.
DynamoDB on-demand offers pay-per-request pricing for read and write requests so that you
pay only for what you use.</p>
<p>knowledge portal</p>
<p>DynamoDB Streams
Stream Records Real- Time
knowledge portal                                   Understanding the Basics
DynamoDB Streams  captures a time-ordered sequence of item-level modifications in any
DynamoDB table and stores this information in a log for up to 24 hours.
Applications can access this log and view the data items as they appeared before and after they
were modified, in near-real time.
Add userID 01
DEL userID 02 Stream Log
userID 01 added
userID 02 deleted Client DynamoDB
knowledge portal                        Sample Record Log in CloudW atch</p>
<p>knowledge portal                                    A Sample Use-Case</p>
<p>knowledge portal                                                    Use-Cases</p>
<ol>
<li>Allows setting up a relationship across multiple tables in which, based on the value of an
item from one table, you update the item in a second table</li>
<li>T riggering an event based on a particular item change</li>
<li>Audit or Archive Data</li>
<li>Replicating Data Across Multiple T ables</li>
</ol>
<p>DynamoDB - Global T able
Let’s Replicate
Basics of Global T ables
knowledge portal Global tables feature provides us with a fully managed, multi-Region, and multi-active
database that delivers fast, local, read and write performance for massively scaled, global
applications.</p>
<p>Basic T erminology
knowledge portal A global table is a collection of one or more replica tables, all owned by a single A WS
account.
A replica table is a single DynamoDB table that functions as a part of a global table. Each
replica stores the same set of data items.
When an application writes data to a replica table in one Region, DynamoDB propagates
the write to the other replica tables in the other A WS Regions automatically .</p>
<p>Important Pointers
knowledge portal In a global table, a newly-written item is usually propagated to all replica tables within
seconds.
With a global table, each replica table stores the same set of data items. DynamoDB does
not support partial replication of only some of the items.
Conflicts can arise if applications update the same item in different regions at about the
same time. T o ensure eventual consistency , DynamoDB global tables use a “last writer
wins”</p>
<p>DynamoDB Accelerator (DAX)
Let’s Accelerate Read Requests
knowledge portal                                 Understanding the Need
In most cases, the DynamoDB response times can be measured in single-digit milliseconds.
However, there are certain use cases that require response times in microseconds.
For these use cases, DynamoDB Accelerator (DAX) delivers fast response times for accessing
eventually consistent data.</p>
<p>knowledge portal                                  Overview of the Feature
Amazon DynamoDB Accelerator (DAX) is a fully managed, highly available, in-memory cache
for Amazon DynamoDB that delivers up to a 10x performance improvement.</p>
<p>knowledge portal Use-Case for DAX
Applications that require the fastest possible response time for reads. Some examples include
real-time bidding, social gaming, and trading applications.
Applications that read a small number of items more frequently than others
Applications that are read-intensive, but are also cost-sensitive.</p>
<p>knowledge portal                               Where it is not suitable for ?
DAX is not ideal for the following types of applications:
Applications that require strongly consistent reads (or that cannot tolerate eventually consistent
reads).
Applications that do not require microsecond response times for reads, or that do not need to
offload repeated read activity from underlying tables.
Applications that are write-intensive, or that do not perform much read activity .</p>
<pre><code>          R TO &amp; RPO 
     Health should always be good 
</code></pre>
<p>knowledge portal                                  Everything comes at price
● High A vailability Architecture is driven by your requirements.
● An highly available, multi-AZ, fault tolerant infrastructure is certainly possible,
however there is cost associated with it.</p>
<p>knowledge portal                                    Recovery Time Objective
● Recovery Time Objective (R TO) is the amount of time frame it takes for you to
recover your infrastructure and business operations after disaster has struck.
Sample Example:
● If R TO is 3 hours, then one needs to invest quiet good amount of money to make sure<br>
DR region is always ready in-case main region goes down due to disaster.</p>
<p>knowledge portal                                    Recovery Point Objective
● Recovery Point Objective (RPO) is concerned with data and maximum tolerance
period to which data can be lost.
● It helps in determining how well we should be designing the infrastructure.
Sample Example:
●  If RPO is 5 hours for database, then we should be taking backup of database every five
hours .</p>
<p>knowledge portal                                          R TO vs RPO
● R TO is more broader scope and covers whole business and systems involved while
RPO is more directly related to interval of backup to take to avoid data loss.</p>
<p>IAM DB Authentication
Challenges and Structure
Getting Started
knowledge portal
W e can authenticate to your DB instance using A WS Identity and Access Management
(IAM) database authentication.
IAM database authentication works with MySQL and PostgreSQL .
In this method, we don’t need to have a password, instead we can make use of
authentication token.</p>
<p>Things to Remember
knowledge portal
Network traffic to and from the database is encrypted using Secure Sockets Layer (SSL).
Y ou can use IAM to centrally manage access to your database resources, instead of managing
access individually on each DB instance.
When using IAM database authentication with MySQL, you are limited to a maximum of
20 new connections per second.</p>
<p>Intro to Amazon SQS
Message Queuing Service
Use-Case: Restoring Image Application
knowledge portal
Medium Corp is designing an application that will enhance and restore the images that
users submit through the online portal.</p>
<p>Current Architecture
knowledge portal
The overall architecture involves two components:</p>
<ol>
<li>Image Gatherer      - T akes the Images from the user via Upload button.</li>
<li>Imager Enhancer   -  Receives the Image from Image Gatherer.
Image Gatherer     Image Enhancer Send Image
Challenges
Due to popularity of the application and huge traffic spike, Medium Corp has decided to
add more image enhancer servers.
server-a 10.77.2.5
server-b 10.66.0.10
server-c 192.168.0.2
server-d 10.66.10.10
Better Architecture
knowledge portal One of the main function of message queue service is to take message from a Publisher
and forward that to a consumer.
The queue stores these messages internally .
Send to Queue
Take from Queue
Highly-Available Queue
Introduction to SQS
knowledge portal Amazon SQS is a fast reliable, scalable, and fully managed message queuing service.
Amazon SQS makes it simple and quiet cost effective to decouple the components of a
specific application.
Send to Queue
Take from Queue
SQS
Tightly Coupled Systems
knowledge portal
Components of system architecture directly communicate with each other and have
hard-dependency on each other.</li>
</ol>
<p>Producers Consumers
Loosely Coupled System
knowledge portal
Components of system architecture that can process the information without being
directly connected.
Producers
Consumers
SQS Dead-Letter Queues
T roubleshooting Problematic messages
Understanding the Challenge
knowledge portal Amazon SQS supports dead-letter queues, which other queues (source queues) can target for
messages that can&rsquo;t be processed (consumed) successfully .</p>
<p>Consumer Process
Understanding the Challenge
knowledge portal Amazon SQS supports dead-letter queues, which other queues (source queues) can target for
messages that can&rsquo;t be processed (consumed) successfully .</p>
<p>Consumer Process
Moving to Dead-Letter Queue
knowledge portal Move the message that cannot be processed to dead letter queue.</p>
<p>Consumer Process<br>
Dead-Letter Queue
Moving to Dead-Letter Queue
knowledge portal Move the the message that cannot be processed to dead letter queue.
Consumer Process<br>
Dead-Letter Queue
Troubleshoot
Overview of Dead Letter Queue
knowledge portal
Amazon SQS supports dead-letter queues, which other queues (source queues) can target for
messages that can&rsquo;t be processed (consumed) successfully
Dead-letter queues are useful for debugging your application or messaging system because
they let you isolate problematic messages to determine why their processing doesn&rsquo;t succeed.
The messages are sent to the dead letter queue after exceeding maximum receives.</p>
<p>Important Pointers to Remember
knowledge portal
When a message moves to a dead-letter queue, the timestamp remains unchanged.
Let’s understand this with an example:
● Message has been in the source queue for 1 day and moved to dead-letter queue.
● Message Retention Period in Dead Letter Queue is 4 days.
● Message will be deleted from the Dead Letter queue after 3 days.
Best practice is to have higher retention period for dead-letter queues then the source
queue.</p>
<p>Relax and Have a Meme Before Proceeding
knowledge portal</p>
<p>454         Amazon SQS queue types</p>
<pre><code>                            T ypes of SQS Queue 
</code></pre>
<p>There are two primary types of SQS queues.
Standard Queue
FIFO  Queue SQS
Message Ordering
Standard Queue Occasionally, messages are delivered in an order different from which they were sent.
FIFO Queue The order in which messages are sent and received is strictly preserved
Standard Queue
FIFO  Queue
Difference
Characteristic Standard Queue FIFO Queue
Throughput Standard queues support a nearly unlimited number of
API calls per second, per API action (SendMessage,
ReceiveMessage, or DeleteMessage). FIFO queues support up to 300 API calls per
second, per API method (SendMessage,
ReceiveMessage, or DeleteMessage).
Delivery A message is delivered at least once, but occasionally
more than one copy of a message is delivered. A message is delivered once and remains
available until a consumer processes and
deletes it. Duplicates aren&rsquo;t introduced into
the queue.
Ordering Messages can be out of order. Messages are in Order.
458 Message Queues in Database Transactions</p>
<pre><code>                      Understanding with a Use-Case 
</code></pre>
<p>●Let’s assume you have a single database hosted on RDS.
●Due to sales, the number of write transactions has reached 20x normal load.
●Many requests are failing regularly.
●New sale promotions are scheduled every alternate month.
Database
Possible Solution - V ertical Scaling
Increase the DB Instance Size of RDS and Provisioned IOPS to handle 20x
capacity
Database
Database Vertical Scaling Challenge:    Downtime + Increased Cost</p>
<pre><code>                  Better Approach - Add a Queue 
</code></pre>
<p>In this approach, the messages are temporarily stored in SQS queue which can
handle nearly infinite messages.
Database
SQS Queue
Insert
EC2 Instances Add Message
Add Message
462      Scaling based on Amazon SQS</p>
<pre><code>                                 Setting the Base 
</code></pre>
<p>In many scenarios, the number of EC2 instances that are required directly
correlates with number of messages in SQS queue.
If number of messages increases in SQS, there would be a need to increase
EC2 instances.
SQS Queue
EC2 Instances Pull Messages
Final Output
Scaling based on Amazon SQS
We can configure Auto-Scaling group to launch or terminate EC2 instances
based on the number of messages in the SQS queue.
SQS Attribute to check:  ApproximateNumberOfMessages</p>
<p>466                         Amazon MQ</p>
<pre><code>                                   Current Stage 
</code></pre>
<p>SQS is a simple queuing service.
Limited set of functionalities.
There are various Message Broker services like Apache Active MQ that
provides many set of features that are extensively used in on-premise
organizations.</p>
<pre><code>                                 Moving to MQ 
</code></pre>
<p>If you&rsquo;re using messaging with existing applications, and want to move your
messaging to the cloud quickly and easily, we recommend you consider
Amazon MQ.</p>
<pre><code>                               Pointers to Note 
</code></pre>
<p>If you are building brand new applications in the cloud, AWS recommends you
consider Amazon SQS and Amazon SNS.
Amazon SQS and SNS are lightweight, fully managed message queue and
topic services that scale almost infinitely and provide simple, easy-to-use APIs</p>
<pre><code>                   Active/standby broker for high availability 
</code></pre>
<p>An active/standby broker is comprised of two brokers in two different Availability
Zones, configured in a redundant pair.
Data is written on the shared EFS Volume.</p>
<pre><code> Simple Notification Service 
</code></pre>
<p>Notification Service
Let’s Message
knowledge portal SNS stands for simple notification service.
SNS is a fully managed messaging and mobile notification service for delivering messages
to the subscribed endpoints.
SNS Topic
Use-Cases for SNS
knowledge portal
A WS CloudW atch integrates well with SNS.
Whenever a disk usage of a server exceeds 95%, send an EMAIL and SMS notification to
the NOC team.
Whenever a server load in production is more than 90%, send and email and SMS
notification.
47 4                        SNS Fanout</p>
<pre><code>                        Basics of Fanout Pattern 
</code></pre>
<p>Fanout is a pattern in which message is delivered to multiple destinations.
Consumer 2        Consumer 1
Consumer 3      Producer
Simple Use-Case: Ordering a Product
Fanout is a pattern in which message is delivered to multiple destinations.
Publisher
Logistic Queue
Notification Queue
Customer Website Place Order
SNS Fanout Pattern
The Fanout scenario is when a message published to an SNS topic is
replicated and pushed to multiple endpoints, such as Kinesis Data Firehose
delivery streams, Amazon SQS queues, HTTP(S) endpoints, and Lambda
functions.</p>
<pre><code>                              Another Use-Case 
</code></pre>
<p>You can also use fanout to replicate data sent to your production environment
with your test environment
In production, you can attach a new SQS queue for test environment and can
continue to improve and test your application using data received from your
production environment.
Prod Queue
Dev Queue
Prod EC2
Dev EC2 SNS
479              SNS Message Filtering</p>
<pre><code>                             Revising the Basics 
</code></pre>
<p>By default, an Amazon SNS topic subscriber receives every message that&rsquo;s
published to the topic.
Prod Queue
Dev Queue SNSHello World Hello World
Hello World
Basics of SNS Filtering
A filter policy is a JSON object containing properties that define which
messages the subscriber receives
Priority Queue
Normal Queue SNS
Filter Queue
Alice Priority Queue
Bob Normal Queue Alice Alice
Amazon EventBridge
Connecting Services
Overview of Amazon Event Bridge
EventBridge delivers a stream of real-time data from event sources to targets.
knowledge portal</p>
<pre><code>                               Use-Case 1: EC2 to SNS 
</code></pre>
<p>knowledge portal Whenever a EC2 instance is stopped, Administrator should be notified.
EC2   SNS EventBridge
EC2 Stop
EC2 Terminate
Use-Case 2: Stop Dev EC2 Instances
knowledge portal Stop all DEV instances at 8PM on Fridays and Start at 9 AM on Mondays.
EventBridge
Schedule
Stop EC2
Start EC2 Fridays
Mondays
Step Functions
Coordinating across distributed components
Overview of Step Functions
knowledge portal
Step Functions are generally used as an orchestration for serverless functions.
One of the question that comes when you use serverless is, how can we turn serverless into
apps ?</p>
<p>Running Functions in Parallel
knowledge portal</p>
<p>Selecting Function Based on Data
knowledge portal
OR
Coordinating Lambda Function
knowledge portal</p>
<p>Overview of Step Functions
knowledge portal
Step Functions makes it easy to coordinate the components of distributed application using
visual workflow .</p>
<pre><code>                         Simple Email Service (SES) 

                    Understanding the Basics 
</code></pre>
<p>Amazon SES is an email platform  that provides an easy, cost-effective way for
you to send and receive email using your own email addresses and domains.
Many organization has generic emails like <a href="mailto:noreply@example.com" rel="external" target="_blank">noreply@example.com</a>  which is used
to send emails to users upon registration or other use-cases.
SES
How email sending works in Amazon SES
●Email sender makes a request to SES to send email to recipients.
●If the request is valid, SES accepts the email.
●SES sends the message over the Internet to the recipient&rsquo;s receiver.
Bounce Notifications (email not exist) &amp; Complaints (feedback) are sent back to
SES which then forwards it to the sender.</p>
<pre><code>                  Email format in Amazon SES 
</code></pre>
<p>Email Format Description
Formatted Construct simple test message using the form provided.
Raw For more complex use-cases like using HTML or attachments.
Raw Mail Example
Relax and Have a Meme Before Proceeding
knowledge portal</p>
<pre><code>                     Types of Amazon SES credentials 

                    Understanding the Basics 
</code></pre>
<p>To interact with Amazon SES you use security credentials to verify who you are
and whether you have permission to interact with Amazon SES
Access Type Credentials to Use
Amazon SES API AWS Access Keys
SES SMTP Interface Username and Password
SES Console IAM User and Password
Use-Case: SMTP Interface
There are a number of commercial and open source software packages that
support sending email through SMTP
You can configure any such SMTP-enabled software to send email through the
Amazon SES SMTP interface.</p>
<pre><code>                           SMTP Endpoint 

      Connecting to an Amazon SES SMTP endpoint 

                    Understanding the Basics 
</code></pre>
<p>To send email using the Amazon SES SMTP interface, you connect to an SMTP
endpoint.
The Amazon SES SMTP endpoint requires that all connections be encrypted
using Transport Layer Security (TLS).
SMTP Endpoint Only TLS Allowed
Mechanism for TLS
Amazon SES supports two mechanisms for establishing a TLS-encrypted
connection
1.STARTTLS
2.TLS Wrapper</p>
<pre><code>                 Approach 1 - ST AR TTLS 
</code></pre>
<p>STARTTLS is a means of upgrading an unencrypted connection to an encrypted
connection
To set up a STARTTLS connection, the SMTP client connects to the SES SMTP
endpoint on port 25, 587, or 2587, issues an EHLO command, and waits for the
server to announce that it supports the STARTTLS SMTP extension.
The client then issues the STARTTLS command, initiating TLS negotiation.
When negotiation is complete, the client issues an EHLO command over the
new encrypted connection, and the SMTP session proceeds normally.</p>
<pre><code>                          Overall Flow 

                 Approach 2 - TLS W rapper 
</code></pre>
<p>TLS Wrapper is a means of initiating an encrypted connection without first
establishing an unencrypted connection.
With TLS Wrapper, the Amazon SES SMTP endpoint doesn&rsquo;t perform TLS
negotiation: it&rsquo;s the client&rsquo;s responsibility to connect to the endpoint using TLS,
and to continue using TLS for the entire conversation.
To set up a TLS Wrapper connection, the SMTP client connects to the Amazon
SES SMTP endpoint on port 465 or 2465.</p>
<pre><code>                                 SES Templates 

                     Basics of Email T emplate 
</code></pre>
<p>An email template is a pre-defined email layout.
Rather than create a new email from scratch each time, you can use a template
as a base.
Hi $name
Thanks for
registration.
Email Template SES
Using templates in SES
You can use the CreateTemplate API operation to create email templates.
These templates include a subject line, and the text and HTML parts of the email
body.</p>
<pre><code>                   Sending Personalized Email 
</code></pre>
<p>You can use the SendTemplatedEmail operation to send an email to a single
destination.
You can include the values associated with the variables in TemplateData</p>
<pre><code>                  Bring your own IP addresses 

                     Basics of IP Reputation 
</code></pre>
<p>IP reputation is a measure that helps evaluate the quality of an IP address and
determine how legitimate its requests are
Bad IP Reputation generally corresponds to activities like sending spam emails,
viruses etc that originate from the IP.</p>
<pre><code>    Use-Case: Organization Migrating to Cloud 
</code></pre>
<p>Organization’s infrastructure is hosted in the on-premise datacenter.
They have certain Public IPs from years with very good reputation.
They decide to migrate to Cloud and server receive IP with NOT as good
reputation as their previous IPs.</p>
<pre><code>                  Introducing Bring Y our Own IP 
</code></pre>
<p>You can bring part or all of your publicly routable IPv4 or IPv6 address range
from your on-premises network to your AWS account.
On-Premise IPs
AWS</p>
<pre><code>                 Benefits of Bring Y our Own IP 
</code></pre>
<p>Benefits Description
IP Reputation
Many customers consider the reputation of their IP addresses to be a
strategic asset and want to use those IPs on AWS with their
resources.
Customer
whitelisting
BYOIP also enables customers to move workloads that rely on IP
address whitelisting to AWS without the need to re-establish the
whitelists with new IP addresses
Regulation and
compliance
Many customers are required to use certain IPs because of
regulation and compliance reasons. They too are unlocked by
BYOIP.</p>
<pre><code>                   Important  Requirements - Part 1 
</code></pre>
<p>The address range must be registered with your regional internet registry (RIR)
such as ARIN, RIPE, APNIC.
It must be registered to a business or institutional entity and cannot be
registered to an individual person.
The most specific IPv4 address range that you can bring is /24.
The most specific IPv6 address range that you can bring is /48 for CIDRs that
are publicly advertised, and /56 for CIDRs that are not publicly advertised.</p>
<pre><code>                 Important Requirements - Part 2 
</code></pre>
<p>The addresses in the IP address range must have a clean history . AWS might
investigate the reputation of the IP address and reserve the right to reject an IP
address range an IP has a poor reputation or is associated with malicious
behavior.</p>
<pre><code>                            Points to Note 
</code></pre>
<p>Customers can create Elastic IPs from the IPv4 space they bring to AWS and
use them with EC2 instances, NAT Gateways, and Network Load Balancers.</p>
<pre><code>                       Elastic Network Interface (ENI) 

           Revising Basics of Network Interface 
</code></pre>
<p>Network interface is a hardware component that connects a computer to a
computer network
A virtual network interface (VIF) is an abstract virtualized representation of a
computer network interface.</p>
<pre><code>                    Elastic network interfaces 
</code></pre>
<p>An elastic network interface  is a logical networking component in a VPC that
represents a virtual network card.
Some of the following attributes include:
●A primary private IPv4 address
●One or more secondary private IPv4 addresses
●One Elastic IP address (IPv4) per private IPv4 address
●One or more security groups
●A MAC address
●A source/destination check flag
Sample Attributes of ENI
172.31.0.5
54.20.32.43 00:00:5e:00:53:af
Rule Action CIDR
Port 22 ALLOWED 192.168.0.5/32 Elastic Network Interface
Portable NICs
You can create a network interface, attach it to an instance, detach it from an
instance, and attach it to another instance.
The attributes of a network interface follow  it as it&rsquo;s attached or detached from
an instance and reattached to another instance.
172.31.0.5
172.31.0.5
Importance of Default NICs
Each instance has a default network interface , called the primary network
interface. You cannot detach a primary network interface from an instance.
You can create and attach additional network interfaces.
The maximum number of network interfaces that you can use varies by
instance type.
NICs are availability zone specific.
Enhanced Networking</p>
<pre><code>                     Understanding the Basics 
</code></pre>
<p>Every network interface card has a specific bandwidth.
The networking bandwidth in-turn gets affected when we virtualization layer
comes into picture.
Virtualization Layer eth0 eth1
Network Interface
Basics of  Enhanced Networking
Enhanced Networking  uses single root I/O virtualization technique (SR-IOV) to
provide high performance networking capabilities on supported instance types.
SR-IOV is a method of device virtualization  that provides higher I/O
performance and lower CPU utilization when compared to traditional virtualized
network interfaces.
Virtualization Layer eth0 eth1
Network Interface
Mechanism to Enable Enhanced Networking
All current generation instance types support enhanced networking, except for
T2 instances.
You can enable enhanced networking using one of the following mechanisms:
Approach Description
Elastic Network Adapter (ENA) Supports network speeds of up to 100 Gbps for
supported instance types.
Intel 82599 Virtual Function (VF)
interface (ixgbevf driver) Supports network speeds of up to 10 Gbps for
supported instance types.
Instance and Supported Mechanism
Depending on the instance type, the supported mechanism to enable
Enhanced Networking changes.</p>
<pre><code>            V erify if Module is Used in a Interface 
</code></pre>
<p>ethtool -i eth0
Intel VF ENA
Placement Groups
Time to go fast
Placement Groups
knowledge portal ● Placement group are recommended for applications that require low latency , high
network throughput.
● Placement groups can also be used to influence placement of a group of EC2
instances.</p>
<p>Small Road vs Highway
knowledge portal</p>
<p>knowledge portal Let’s understand GUI way
Placement Group
Point 2 - Influencing Placement of EC2
knowledge portal ● A single server can run multiple virtual machines.
● This can lead to issues if you are running a cluster of servers.
Example:
● Medium Corp is running a MySQL cluster consisting of two servers in single AZ. In
the background, both the EC2 are part of the same underlying host.</p>
<p>Example Use-Case
knowledge portal
Medium Corp is running a MySQL cluster consisting of two servers in single AZ.  The
server are of type m4.large.
In the background, both the EC2 are part of the same underlying host.</p>
<pre><code>          Virtualization 
</code></pre>
<p>Solution - Placement Group
knowledge portal
With placement group, we can explicitly specify that two EC2 instance should not be part
of the same server (same rack of servers)
Virtualization
Virtualization</p>
<p>Racks in Data Center
knowledge portal</p>
<p>T ypes of Placement Groups
knowledge portal There are three types of placement groups available:
Sr No Type Description
1 Cluster Packs instances close to each other in an Availability Zone.
2 Partition Spreads instances in logical partition such that group of
instances in one partition do not share underlying hardware.
3 Spread Strictly places group of instances across distinct hardware to
reduce failures.
Cluster Placement Groups
knowledge portal Logical grouping of instances within a single A vailability Zone.
Intended for applications that require low network latency and high network throughput.</p>
<p>Partition Placement Groups
knowledge portal A WS ensures that each partition within a placement group has its own set of racks.
In the below diagram, there are 3 partition and each partition has multiple EC2 instances.
Each of these partition resides in a different rack inside the Data center.</p>
<p>Spread Placement Group
knowledge portal A spread placement group is a group of instances that are each placed on distinct racks, with
each rack having its own network and power source.
In the following diagram, there are 7 EC2 instances and each instance is in a separate rack.</p>
<p>Important Points - Cluster Placement Groups
knowledge portal
● A cluster placement group can&rsquo;t span multiple A vailability Zones.
● Only specific types of EC2 instances can be launched.
●  Maximum network throughput traffic between two instance in placement group is
limited by the slower of the two instance.
● Recommended to launch all instance together. Launching instance later can lead to
capacity errors. In such-case, stop and start all instances in the placement group.</p>
<pre><code>                     Prefix Lists 
</code></pre>
<p>Centralizing IP Address Data
Overview of Prefix Lists
A prefix list is a set of one or more CIDR blocks.
Y ou can create a prefix list from the IP addresses that you frequently use, and reference them as
a set in security group rules and routes instead of referencing them individually .
10.77.0.0/16
10.66.0.0/16
192.168.10.0/24
10.44.0.0/16     Prefix List
Security Group
Route Table
T ypes of Prefix List
knowledge portal There are two types of prefix lists:</p>
<p>Types of Prefix List Description
Customer-managed prefix lists Sets of IP address ranges that you define and manage.
AWS-managed prefix lists Sets of IP address ranges for AWS services.
Important Pointers
A prefix list supports a single type of IP addressing only (IPv4 or IPv6). Y ou cannot combine
IPv4 and IPv6 CIDR blocks in a single prefix list.
A prefix list applies only to the Region where you created it.
When you reference a prefix list in a resource, the maximum number of entries for the prefix
lists counts against the quota for the number of entries for the resource. For example, if you
create a prefix list with 20 maximum entries and you reference that prefix list in a security group
rule, this counts as 20 security group rules.
knowledge portal
Virtual Private Network
Let’s Route
VPN
knowledge portal ● VPN enables you to route traffic from yourself towards destination through itself.
● Something similar to Proxy .
128.10.50.20
Routing via VPN Server
knowledge portal
128.10.50.20
54.20.30.56
VPN use in Corporate Network
knowledge portal ● In Corporate environments, VPN is used to connect to instances in Private Subnet.
● VPN Server resides in the Public Subnet and you route your traffic via VPN server to
instances in Public Subnet.</p>
<pre><code>                                 AWS ClientVPN 
                   EC2 Based VPN Architecture 
</code></pre>
<p>In this approach, you install VPN softwares like OpenVPN in the EC2 instance
and use it to route traffic to private subnets.
IGW
Private Subnet Public Subnet VPNLocal Computer</p>
<pre><code>   Challenges with EC2 VPN Based Architectures 
</code></pre>
<p>1.High-Availability (What if VPN EC2 goes down)
2.Patch Management.
3.Upgrade of VPN Software
4.Performance Optimization
5.VPN Server Configuration</p>
<pre><code>                                   A WS Client VPN 
</code></pre>
<p>AWS Client VPN is a fully-managed remote access VPN  solution used by your
remote workforce to securely access resources within both AWS and your
on-premises network</p>
<pre><code>                     Benefits of A WS Client VPN 
</code></pre>
<p>AWS Client VPN is a pay-as-you-go  cloud VPN service
Fully elastic , it automatically scales up, or down, based on demand
AWS Client VPN, including the software client, supports the OpenVPN protocol.</p>
<pre><code>                   AWS ClientVPN - Point to Know 
                        Authentication Step 
</code></pre>
<p>Client VPN offers following authentication types
●Active Directory authentication (user-based)
●Mutual authentication (certificate-based)
●Single sign-on (SAML-based federated authentication) (user-based)</p>
<pre><code>           Mutual Authentication (Certificate Based) 
</code></pre>
<p>In Mutual Authentication, both client and server must provide digital certificates
to prove their identities.
client.crt
Provides Server Certificate Provides Client Certificate
server.crt Verify client.crt Verify server.crt
Certificate Authority
Client  VPN</p>
<pre><code>                         OpenVPN Clients 
</code></pre>
<p>You can connect to a Client VPN endpoint using common Open VPN client
applications.</p>
<pre><code>                       ClientVPN Practical Steps 
                      Step 1- Generate Certificates 
</code></pre>
<p>There will be three types of certificates that needs to be generated:
●CA Certificate.
●Server Certificate.
●Client Certificate.
ca.crt  server.crt     client.crt
Step 2 - Upload Certificates to ACM
In this step, we need to upload the Server Certificate and Server Key to AWS
Certificate Manager service.
AWS Certificate Manager server.crt+key Upload to ACM
Step 3 - Create ClientVPN Endpoint
In this step, we create a ClientVPN Endpoint in AWS .</p>
<pre><code>                   Important Configurations 
</code></pre>
<p>Following are some of the important configuration options while creating
ClientVPN
Important Options Description
Client IPv4 CIDR Specify an IP address range, in CIDR notation, from which to assign
client IP addresses. For example, 10.0.0.0/22.
Server certificate ARN Specify the ARN for the TLS certificate to be used by the server.
Certificate must be provisioned in ACM
Authentication Options Either Mutual or User Based Authentication.
Step 4 - Association
To enable clients to establish a VPN session, you must associate a target
network with the Client VPN endpoint. A target network is a subnet in a VPC.
Subnet A
Subnet B Client VPN
Step 5 - Authorization
To authorize clients to access the VPC in which the associated subnet is
located, you must create an authorization rule.
The authorization rule specifies which clients have access to the VPC.
Subnet A
Subnet B Client VPN All users can access.
Only admins
Step 6 - Download Configuration File
The configuration file includes necessary information related to certificate, URL,
ports etc  required to establish a VPN connection.</p>
<pre><code>             Step 7 - Download Configuration File 
</code></pre>
<p>The final step is add client certificate and client key in the downloaded
configuration file.
client.crt
config.ovpn
client.key  Central File
Client VPN Connect
ClientVPN Connectivity  Architectures
Connecting ClientVPN to Endpoints
1 - Access to VPC</p>
<pre><code>         2- Access to Peered VPC 

      3 - Access to On-Premise Network 

             4 - Access to Internet 

          5 - Client to Client Access 
</code></pre>
<p>6 - Restrict access using security groups</p>
<p>Site to Site Tunnel
Let’s Route
Site to Site VPN
knowledge portal A Site to Site (S2S) VPN allows two networking domains to communicate securely
between each other over an untrusted network like Internet.
The two sites can be A WS and on-premise data-center or even two different VPC’s.
VPN Connection
EC2 Instance
A vailability Challenges in S2S VPN
knowledge portal If you have a single tunnel endpoint and if one of the side goes down, then the entire
tunnel breaks.
VPN Connection
EC2 Instance
High A vailability in S2S VPN
knowledge portal
Mumbai
( ap-south )         North Virginia
( us-east )
Active
Passive
Site to Site VPN</p>
<p>Importance of VGW
● A Virtual Private Gateway (VGW) has built-in high-availability for VPN connection.
● A WS automatically creates 2 HA endpoints, each in a different AZ.
VPN Connection = 2 VPN Tunnels
Endpoint IP 1
Endpoint IP 2
Importance of VGW</p>
<p>Direct Connect
Let’s Route Centrally
Customer to VPC
knowledge portal</p>
<p>Packets travels via Hops</p>
<p>Challenges
● Internet is a good option if amount of traffic is within a certain limit.
● There are always latencies which can also be involved.
● Many of the organization have hybrid architecture : DataCenter + A WS
● In such cases, latency can cause major challenges for the application</p>
<p>Introducing DX
● In order to solve this challenge,  A WS introduced Direct Connect.
● A WS Direct connect let’s customer establish a dedicated direct network connection
between the client’s network and one of the direct connect locations.</p>
<p>Benefits of DX
Having direct connection between customer’s datacenter to A WS, brings tremendous amount
of benefits, some of them includes:
i) Consistent Network Performance:
ii) Reduces our bandwidth costs
iii) Private connectivity to our A WS VPC</p>
<p>knowledge portal
Architecture of DX</p>
<p>Virtual Interfaces
Connecting to A WS via DX
What after DX Line is Established?
knowledge portal
The next primary step after Direct Connect is established is to configure the Virtual Interfaces.</p>
<p>knowledge portal                                       Virtual Interface T ypes
Depending on your requirement, appropriate Virtual Interface (VIF) can be created.</p>
<p>Virtual Interface Type Description
Public Virtual Interface Enables access to public AWS services like AWS S3,
and others that are not in the VPC.
Private Virtual Interface Enables access to your VPC
Transit Virtual Interface Access one or more Amazon VPC Transit Gateways
associated with Direct Connect gateways
knowledge portal                           Steps 1 : Establish DX connection request
● Here we specify the connection name, location and the port speed.
● After we click on create, it will go for review to A WS and if approved, we get a LOA which we
can download and give it to provider who will be establishing DX connection on your behalf.
● It takes upto 3 working days for the LOA to be approved.</p>
<p>knowledge portal                                  Steps 2 : Create Virtual Interface
Create Virtual Interface based on your requirement.
Can be associated with Direct Connect Gateway or Virtual private Gateways.</p>
<p>Step 3 - Download Router Configuration
knowledge portal
After you have created the virtual interface for your A WS Direct Connect connection, you can
download the router configuration file.
The file contains the necessary commands to configure your router for use with your private or
public virtual interface</p>
<p>knowledge portal                                                     Important Pointers
● By default 1Gbps and 10 Gbps connections are available,  we can also have sub-1GB
connection from direct connect partners which includes 50 mbps, 100 mbps, 200 mbps,
400 mbps, 500 mbps.</p>
<p>●  Direct connect is not fault tolerant, so we need to either have secondary Direct Connect
or use VPN as backup. Use BGP to automatic failover to backup connection.
● In US, direct connect will grant you access in all the US related region.</p>
<p>Virtual Interfaces
knowledge portal</p>
<p>Direct Connect Gateway
Direct connect all the way
knowledge portal      Gateway T ypes for Virtual Interface
Following tables illustrates the supported gateway types for the Virtual Interfaces
Gateway Types Description
Virtual Private Gateway Allows connections to a single VPC in the same region
Direct Connect Gateway Allows connections to multiple VPCs and regions
knowledge portal               Overview of DX Gateway
Direct Connect Gateway  can be used to connect your direct connect connection over private VIF
to one or more VPC’s within the account that are located in same or multiple regions.
It allows us to combine private VIF’s with multiple VGW’s in local or in remote region.</p>
<p>knowledge portal                  Multiple Accounts
Multiple A WS accounts can also be integrated with DX Gateways.</p>
<p>knowledge portal               T ransit Gateway Association
The following diagram illustrates how the Direct Connect gateway enables you to create a single
connection to your Direct Connect connection that all of your VPCs can use.</p>
<p>Direct Connect - High A vailability
Allows us to have a better sleep.
knowledge portal                                Getting Started
If you have a single DX connection, it is subjected to scenario of failover.
In-case if your DX connection breaks, your link will break completely .
Hence it is recommended to have a backup connection of VPN over the Internet.</p>
<p>Direct Connect Connection</p>
<p>knowledge portal             Secondary Backup  Connection</p>
<p>Direct Connect Connection
VPN over Internet
knowledge portal          Dual Connection - Single Location
AWS Rack Customer / Partner Rack<br>
DX Connection
Mumbai Region</p>
<p>knowledge portal          Dual Connection - Single Location
AWS Rack Customer / Partner Rack<br>
DX Connection
Mumbai Region</p>
<p>knowledge portal</p>
<p>AWS Rack Customer / Partner Rack
Direct Connect (DX) Location
DX Connection
Dual Connection - Dual Location
DX Connection Location 1
Location 2</p>
<p>61 0                    Transit Gateways</p>
<pre><code>                 Use-Case: Connecting 4 VPCs 
</code></pre>
<p>More the Number of VPCs, more the number of peering connection you have to
establish for inter-connectivity related use-case.</p>
<pre><code>                      Introducing T ransit Gateway 
</code></pre>
<p>AWS Transit Gateway connects your  Amazon Virtual Private Clouds (VPCs)
and on-premises networks through a central hub
Transit Gateway
Larger Setup
Transit Gateway
Direct Connect
Site to Site VPN
61 4           Transit gateway concepts</p>
<pre><code>                         Concept 1 - Attachments 
</code></pre>
<p>Multiple resources can be attached to Transit Gateway.
Some of the supported entities:  VPCs, Direct Connect Gateway, VPN, SD-WAN
Transit Gateway
Site to Site VPN Attachment
Attachment Attachment
Concept 2 - Route T able
Defines how the traffic is routed between the connected resources.
Transit Gateway Route Entry
172.16.0.0/16 via ATT-A
192.168.0.0/16 via ATT-B
192.168.0.0/16 172.16.0.0/16 Attachment A
Attachment B
617           Transit gateway Practical</p>
<pre><code>                               Our Practical Setup 
</code></pre>
<p>Transit Gateway Attachment
Attachment 172.31.0.0/16
192.168.0.0/16 Route Entry
172.16.0.0/16 via ATT-A
192.168.0.0/16 via ATT-B
Success Criteria
EC2 Instance from VPC-1 should be able to communicate  to E2 Instance from
VPC-2 through Transit Gateway.</p>
<p>620           Routes in Transit Gateways</p>
<pre><code>                                 Route Propagation 
</code></pre>
<p>For a VPC attachment, the CIDR blocks of the VPC are propagated  to the
transit gateway route table.
Transit Gateway Attachment A
Attachment B 172.16.0.0/16 Route Entry
172.16.0.0/16 via ATT-A
192.168.0.0/16 Route Entry
192.168.0.0/16 via ATT-B propagated
propagated
Static Routes
In addition to propagated routes, you can also add static routes.
Static routes allows more flexible routing policy with option to even DROP
traffic.</p>
<pre><code>                           Route Evaluation Order 
</code></pre>
<p>The most specific route for the destination address is given higher priority.
For routes with the same destination IP address but different targets, the route
priority is as follows:
1.Static routes (for example, Site-to-Site VPN static routes)
2.Prefix list referenced routes
3.VPC propagated routes
4.Direct Connect gateway propagated routes
5.Transit Gateway Connect propagated routes
6.Site-to-Site VPN propagated routes</p>
<pre><code>  Attachment Speciﬁc Routing 

                           Default Route T able 
</code></pre>
<p>Your transit gateway automatically comes with a default route table .
By default, this route table is the default association  route table and the default
propagation route table.
Transit Gateway Attachment
Attachment A
B 172.31.0.0/16
192.168.0.0/16 Default Route Table
172.16.0.0/16 via ATT-A
192.168.0.0/16 via ATT-B
Understanding the Use-Case
All communication should be allowed EXCEPT VPC-B to VPC-Z
Transit Gateway Attachment
Attachment Attachment
A
BZ 172.31.0.0/16
192.168.0.0/16 10.77.0.0/16
Transit Gateway Attachment A
Attachment B Attachment C
A
BZ 172.31.0.0/16
192.168.0.0/16 10.77.0.0/16 Route for VPC-A Attachment
10.77.0.0/16 via ATT-C
192.168.0.0/16 via ATT-B
Route for VPC-B Attachment
172.31.0.0/16 via ATT-A Route for VPC-C Attachment
172.31.0.0/16 via ATT-A
Transit Gateway - VPN Attachments</p>
<pre><code>                   A WS T ransit Gateway + VPN 
</code></pre>
<p>AWS Transit Gateway + VPN, using the Transit Gateway VPN attachment ,
provides the option of creating an IPsec VPN connection between your remote
network and the Transit Gateway over the internet
Transit Gateway
VPN Tunnel
Benefits: Encrypted Traffic Each Tunnel ~1.25 Gbps
Points to Note
A single VPN tunnel has a maximum throughput of 1.25 Gbps
If you establish multiple VPN tunnels to an ECMP-enabled transit gateway, it
can scale beyond the default maximum limit of 1.25 Gbps.
Equal-cost multi-path routing (ECMP)  is a routing strategy where packet
forwarding to a single destination can occur over multiple best paths with equal
routing priority.</p>
<pre><code>    T ransit Gateway with Multiple VPN Connection 
</code></pre>
<p>When you create your VPN, you must choose Dynamic for Routing options.
Static routing does not support ECMP.
When you create your transit gateway, you must enable VPN ECMP support .
ECMP Enabled
VPN Attachment
To attach a VPN connection to your transit gateway, you must specify the
customer gateway.
For static VPNs, we have to add the static routes to the transit gateway route
table.</p>
<p>ECMP with multiple VPN tunnels with a transit gateway
Ensure that your customer gateway is configured to perform ECMP for traffic
going out to AWS for all VPN tunnels.
Confirm that your customer gateway is advertising the on-premises prefix to
AWS with the same BGP AS PATH attribute.
For AWS to choose all the available ECMP paths, the AS Path and AS Number
must match.</p>
<pre><code>                   Example Configuration 
</code></pre>
<p>You plan to use ECMP with two VPN connections. The AS Number of your
customer gateway is 65270. In this scenario, you configure your VPNs as
follows:
VPN-A
●Tunnel 1 – AS PATH: 65270 (while advertising the prefix)
●Tunnel 2 – AS PATH: 65270 (while advertising the prefix)
VPN-B
●Tunnel 1 – AS PATH: 65270 (while advertising the prefix)
●Tunnel 2 – AS PATH: 65270 (while advertising the prefix)
With a configuration similar to this information, AWS sends out traffic with
ECMP on all four VPN tunnels.
Transit Gateway Sharing</p>
<pre><code>                          Base Architecture 
</code></pre>
<p>Transit Gateway sharing allows VPCs across multiple accounts to use Transit
gateway for inter-connectivity.
Account 1 Transit Gateway
Account 2
Transit Gateway Attachment
Account 3
Transit Gateway Attachment</p>
<pre><code>              Points to Note 
</code></pre>
<p>An AWS Site-to-Site VPN attachment must be created in the same AWS
account that owns the transit gateway.
When a transit gateway is shared with you, you cannot create, modify, or delete
its transit gateway route tables, or its transit gateway route table propagations
and associations.</p>
<pre><code>                          Gateway Load Balancer 

                          Problem Statement 
</code></pre>
<p>Traffic Inspection  is one of the common use-cases in Enterprises.
Many providers offers virtual appliance related to IDS/IPS, Firewalls etc.
Network Appliance Application Server
Traffic: Internet to App Server
Traffic to Internet
Traffic Inspection
Subnet-1 Subnet-2
The Architecture
Network Appliance Application Server
Traffic: Internet to App Server
Traffic to Internet
Destination Target
0.0.0.0/0 eni-nw-appliance
10.77.0.0/16 localDestination Target
0.0.0.0/0 igw-id
10.77.0.0/16 localDestination Target
10.77.0.0/16 local
10.77.2.0/24 eni-nw-appliance
10.77.2.0/24
Subnet-1 Subnet-2
Challenges with the Architecture
The routing is done at a ENI level of the Network Appliance.
Issues:  High-Availability, Scaling</p>
<pre><code>                    Introducing GWLB 
</code></pre>
<p>Gateway Load Balancers enable you to deploy, scale, and manage  virtual
appliances, such as firewalls, IDS/IPS , and deep packet inspection systems
Network Appliances Application Server
Traffic Inspection
GWLB-E GWLB
Points to Keep In Mind
In order to work with GWLB, appliances need to support Geneve protocol  to
exchange traffic with GWLB.
Network Appliances
GWLB Original Traffic in
Geneve
Encapsulation
GWLB-E</p>
<p>NA T Gateway Performance
Multiple is better
Performance Aspect
knowledge portal NA T Gateway supports a burst of up to 10 Gbps of bandwidth.
Thus all the instances within the private subnet need to have traffic less than that of 10
Gbps. If more than 10 Gbps, then the network will be the bottleneck.
Thus when we need more bandwidth, than the recommended design is to split the
instance across multiple subnets and attach different NA T gateway to each of those
subnets.</p>
<p>knowledge portal                              Normal NA T Gateway based Architecture
Subnet 1 Subnet 2 Maximum burst up to 10 Gbps
knowledge portal                                Multiple NA T Gateway Approach
Subnet 1 Subnet 2
10 Gbps speed 10 Gbps speed
Egress-Only Internet Gateway
IPv6
knowledge portal        Understanding Egress-Only IGW
The IPv6 ddresses which are assigned from A WS are public routable addresses.
Thus, instance in the public subnet can initiate connection to Internet via the Internet
Gateway . Similarly resources from Internet can also initiate connection to the EC2 instance via
it’s public IPv4 or IPv6 addresses.
IPv6 addresses are globally unique, and are therefore public by default.
Egress-Only Gateway allows EC2 instance with IPv6 address to access internet directly but
prevent resource from internet to directly initiate connection with the EC2 instance.</p>
<p>knowledge portal          Architecture for Egress-Only IGW</p>
<p>Denial of Service
Attack difficult to mitigate
knowledge portal</p>
<p>DOS and DDoS are part and parcel of servers life
DOS and DDoS attacks are very common attack vectors used nowadays to bring down the
servers or flood the network.
The reason why they are so successful is because of ease of ability to launch the attack and
most of the protection mechanisms are based on expensive hardware.
knowledge portal
knowledge portal DDOS attacks are going really big!</p>
<p>knowledge portal Before vs After (DOS Attack)</p>
<p>Egress-Only Internet Gateway
IPv6
knowledge portal        Understanding Egress-Only IGW
The IPv6 ddresses which are assigned from A WS are public routable addresses.
Thus, instance in the public subnet can initiate connection to Internet via the Internet
Gateway . Similarly resources from Internet can also initiate connection to the EC2 instance via
it’s public IPv4 or IPv6 addresses.
IPv6 addresses are globally unique, and are therefore public by default.
Egress-Only Gateway allows EC2 instance with IPv6 address to access internet directly but
prevent resource from internet to directly initiate connection with the EC2 instance.</p>
<p>knowledge portal          Architecture for Egress-Only IGW</p>
<p>Denial of Service
Attack difficult to mitigate
knowledge portal</p>
<p>DOS and DDoS are part and parcel of servers life
DOS and DDoS attacks are very common attack vectors used nowadays to bring down the
servers or flood the network.
The reason why they are so successful is because of ease of ability to launch the attack and
most of the protection mechanisms are based on expensive hardware.
knowledge portal
knowledge portal DDOS attacks are going really big!</p>
<p>knowledge portal Before vs After (DOS Attack)</p>
<p>Mitigating DDOS
The stronghold for Fort
Mitigating DDOS
knowledge portal
● Be ready to scale as traffic surges.
● Minimize the attack surface area.
● Know what is normal and abnormal.
● Create a Plan for Attacks.</p>
<p>Be Ready to Scale
knowledge portal 1. Be Ready to Scale
●  Y our infrastructure should be designed to scale when the traffic increases.
●  It not only helps in Business but also during DDOS Attacks.
Example :
Whenever CPU load is more than 70% in Application servers, automatically add one more
Application server to meet the needs.
A WS Services  : ELB, Auto Scaling</p>
<p>Let’s Minimizing is the Key
knowledge portal 2. Minimize the attack surface area.
Decouple your infrastructure.
Example :
Application and Database should not be on the same server.
A WS Services :  SQS, Elastic BeanStalk</p>
<p>Normal and Abnormal
knowledge portal 3. Know what is normal and abnormal
● Key metrics need to be defined to understand the behavior.
Example :
W ebsite getting a huge surge in traffic in the middle of the night at 3 AM
A WS Services  :-  CloudW atch, SNS.</p>
<p>Create a Plan
knowledge portal
4. Create a Plan for Attacks.
For example :
●     Check whether the Source IP Address is the same.
●     Check from which country the increased traffic is coming from.
●     Nature of the attack ( SYN Flood, Application Level )
●     Can it be blocked with NACL or Security Group level.
It is recommended to have A WS Support. At-least Business Support.</p>
<p>A WS Services for DDoS Attack Mitigation
knowledge portal
Following are some of the key A WS services involved in DDoS attack mitigation
● A WS Shield
● Amazon CloudFront
● Amazon Route53
● A WS W AF
● Elastic Load Balancing
● VPC &amp; Security Groups</p>
<p>A WS Shield
DDoS Protection
Understanding A WS Shield
knowledge portal
A WS Shield is a managed Distributed Denial of Service (DDoS) service that safeguards the
workloads running on A WS against DDoS attacks.
There are two tiers of A WS Shield:
●      Shield Standard
●      Shield Advanced</p>
<p>Understanding A WS Shield
knowledge portal
A WS Shield standard provides basic level protection against most common network and
transport layer DDoS attacks.
For a higher level of protection, we can subscribe to the Shield Advanced. Shield Advanced
protects against large and sophisticated DDoS attacks with near-real-time visibility into the
attacks that might be occurring.
A WS Shield Advanced also gives customers 24x7 access to the A WS DDoS Response T eam
(DR T) during ongoing attacks.</p>
<p>A WS Shield Costs and Credits
knowledge portal
A WS Shield Advanced costs 3000$ per organization and requires Business or Enterprise
Support.
One interesting part about A WS Shield Advanced is that during the attack, if your
infrastructure has scaled, A WS will return you the amount occurred during scaling in the form
of credits. This is also referred to as Cost protection.</p>
<p>A WS Shield Dashboard
knowledge portal</p>
<p>A WS Network Firewall
Y et Another Firewall
Basics of Network Firewall
A WS Network Firewall is a stateful, managed, network firewall and intrusion detection and
prevention service for your virtual private cloud (VPC)
IP / Domain Action
facebook.com BLOCK
twitter.com ALLOW
10.77.0.0/16 ALLOW
Public Subnet
Private Subnet Internet Gateway
knowledge portal Benefits of Network Firewall
Y ou can use Network Firewall to monitor and protect your Amazon VPC traffic in a number of
ways, including the following:</p>
<ol>
<li>Pass traffic through only from known A WS service domains or IP address endpoints, such
as Amazon S3.</li>
<li>Use custom lists of known bad domains to limit the types of domain names that your
applications can access</li>
<li>Perform deep packet inspection on traffic entering or leaving your VPC
Deploying  Network Firewall
Let’s Deploy Network Firewall
Basic Deployment Architecture
The Network firewall protects the subnets within your VPC by filtering traffic going between
the subnets and locations outside of your VPC
Firewall Subnet
Customer Subnet</li>
</ol>
<p>Route T able Entries
Firewall Subnet
Customer Subnet
Destination Target
10.0.0.0/16 local
0.0.0.0/0 vpce-1234 Destination Target
10.0.0.0/16 local
0.0.0.0/0 igw-1234 Destination Target
10.0.2.0/24 vpce-1234
Firewall Subnet IGW
Customer Subnet 10.0.2.0/24
Configuration  Steps
Following are the 3 resource types that Network Firewall Manages.
Resource Type Description
RuleGroup Defines a set of rules to match against VPC traffic, and the actions to take
when Network Firewall finds a match.
FirewallPolicy Allows adding multiple rule groups and configure other settings.
Firewall Provides traffic filtering logic for the subnets in a VPC.
knowledge portal
CloudHSM
Secure Storage
Storing Expensive House Hold Items
knowledge portal Y ou have an expensive jewellery in your house and you are planning to go on a long
vacation.<br>
Where will you prefer to store the jewellery?
Cupboard Bank Locker
Storing Sensitive Digital Keys
knowledge portal Y ou have sensitive encryption keys that needs to be stored
Where will you prefer to store the keys?
Notepad Special Security Devices</p>
<p>Special Security Device - HSM
knowledge portal A hardware security module (HSM) is a physical device that provides extra security for
sensitive data
This type of device is used to provision cryptographic keys for critical functions such as
encryption, decryption and authentication for the use of applications, identities and
databases.</p>
<p>T amper Resistant
knowledge portal ● These devices are tamper resistant  , that  means if anyone  tries to tamper, they will
automatically delete the keys stored.</p>
<p>CloudHSM
A WS CloudHSM is a cloud-based hardware security module (HSM).
With CloudHSM, you can manage your own encryption keys using FIPS 140-2 Level 3
validated HSMs.
Prior to this, company’s had to store HSM on-premise and if infrastructure  was on A WS,
there were lot of latency involved.</p>
<p>Important Points for Exams
knowledge portal ● Cloud HSM is Single T enanted ( Single Physical Device only for you )
● It must be used within a VPC.
● W e can integrate Cloud HSM with RedShift &amp; RDS for Oracle.
● For fault tolerance, we will need to build cluster of 2 Cloud HSM.
● A WS uses Safenet Luna SA HSM appliance for Cloud HSM.
● They are FIPS validated.
● It generally has 2 partitions, one for A WS to monitor and second is cryptographic
partition which you have access to and has stored keys.</p>
<p>A WS KMS
Do things the right way
Basics of KMS
knowledge portal A WS KMS stands for A WS Key Management Service.
This service provides capability to encrypt and decrypt the data.
AWS KMS password: 1234
#.@42312gsd
User
Integration of KMS
knowledge portal A WS KMS also integrates with various A WS services like S3, DynamoDB, EBS and others.
AWS KMS S3 Bucket
EBS
KMS Practical
Time to Defend Easily
Revising Cryptography Concepts
knowledge portal Plaintext can refer to anything which humans can understand and/ or relate to. This may be as
simple as English sentences or even Python code.
Ciphertext, or encrypted text, is a series of randomized letters and numbers which humans
cannot make any sense of.
An encryption algorithm is step by step approach that tells on how the PT will be converted to
the CipherT ext.</p>
<p>KMS Practical W orkflow
knowledge portal 1. Create a Customer Managed Key (CMK)
2. Define the Administrative User &amp; Key User.
3. Encrypt and Decrypt data with the CMK.
Admin User Key User
Alice Bob
password123
#$5^s125)- KMS Key
KMS Architecture
Let’s Scramble
A WS KMS Architecture
knowledge portal “ This is  course”
Base64 ( C.T)</p>
<p>Some of Caveats
knowledge portal
● W e can encrypt of maximum 4 KB of data with CMK.
● Since data travels over network, there can be latency issue.
● A WS suggested the Customer Master Key + Data Key based approach.</p>
<p>Envelope Encryption
knowledge portal ● W e generate 1 CMK.
● W e then generate the Data Key . A WS returns PT &amp; CT version of it.
● W e use the PlainT ext data key to encrypt the files in server.
● W e then store CipherT ext Data Key  along with Encrypted file.
K
M
S
“Generate Data Keys”
Data +</p>
<p>Envelope Encryption
knowledge portal ● W e generate 1 CMK.
● W e then generate the Data Key . A WS returns PT &amp; CT version of it.
● W e use the PlainT ext data key to encrypt the files in server.
● W e then store CipherT ext Data Key  along with Encrypted file.
K
M
S
“Generate Data Keys”
Data +</p>
<p>Decryption Steps
knowledge portal ● Use the decrypt operation to decrypt the encrypted data key into a plaintext copy of
the data key .
● Use the plaintext data key to decrypt data locally .
K
M
S
“ Call Decrypt Interface “</p>
<p>Schedule Key Deletion
Delete the KMS Key
knowledge portal Deleting Key in KMS
Deleting KMS key is destructive and potentially dangerous and an irreversible process.
After a KMS key is deleted, you can no longer decrypt the data that was encrypted under that
KMS key , which means that data becomes unrecoverable.</p>
<p>CipherTextBlob
vEpXfo45WGZB9m3
QMEAS4wEQQMz2X
+Sgvh38nDE32HF23 KMS Key Decrypt
knowledge portal Important Note
Y ou should delete a KMS key only when you are sure that you don&rsquo;t need to use it anymore.
If you are not sure, consider disabling the KMS key instead of deleting it.
If you disable a KMS key , it cannot be used to encrypt or decrypt data until you re-enable it.
Y ou can re-enable a disabled KMS key if you need to use it again later
knowledge portal W aiting Period for Key Deletion
Because it is destructive and potentially dangerous to delete a KMS key , A WS KMS requires you
to set a waiting period of 7 – 30 days. The default waiting period is 30 days.
During the waiting period, A KMS key pending deletion cannot be used in any cryptographic
operations.</p>
<p>Network ACL
Multiple Layers for Defense
Understanding the Basics
A network access control list (ACL) is an optional layer of security for your VPC that acts as a
firewall for controlling traffic in and out of one or more subnets.
● Security Group works at an EC2 instance level.
● Network ACL works at a Subnet Level.
Network ACL Security Group
knowledge portal  Public/Private Subnets
Understanding with Use-Case
Company XYZ is getting lot of attacks  from a random IP 128.190.12.32. The company has
more than 500 servers and Security team decided to block that IP in firewall  for all the servers.</p>
<p>How to go ahead and achieve that goal ?
Network ACL 250 EC2
250 EC2
DENY 128.190.12.32
knowledge portal Each subnet in your VPC must be associated with a network ACL. If you don&rsquo;t explicitly
associate a subnet with a network ACL, the subnet is automatically associated with the
default network ACL.
Default NACL allows all inbound and outbound IPv4 traffic and, if applicable, IPv6 traffic.
Y ou can associate a network ACL with multiple subnets. However, a subnet can be
associated with only one network ACL at a time.
Important Pointers
Network ACL - Rule Ordering
Setting Right Set of NACL Rules
Basics of Rules
knowledge portal
Y ou can add or remove rules from the default network ACL
When you add or remove rules from a network ACL, the changes are automatically applied to
the subnets that it&rsquo;s associated with.</p>
<p>Rule Ordering
knowledge portal
Rules are evaluated starting with the lowest numbered rule.
As soon as a rule matches traffic, it&rsquo;s applied regardless of any higher-numbered rule that might
contradict it.
Rule Number Rule Contents
99 ALLOW from 10.77.0.5
100 DENY from ALL
Important Pointers - Deciding Ports
knowledge portal
● Clients that initiates the request chooses ephemeral port range.
● Port 0 to 1023  are well known or reserved ports.
● This range varies depending on the Operating System.
Example :-</p>
<pre><code>       Many Linux kernels uses ports 32768-61000 .
       Request originating from the ELB uses 1024-65535 
       Windows XP uses 1025-5000  port range. 
</code></pre>
<p>knowledge portal
SSH &ndash; 22
Nginx &ndash; 80
MySQL &ndash; 3306
serverA:22
clientB:55607
● Clients opens an port 55607  from which it sends data to serverA port 22
● serverA has to respond back to the same IP (clientB ) &amp; port ( 55607 ).
Client
Server
TCP/IP Communication
knowledge portal</p>
<p>Amazon Macie
Machine Learning based Security
Core Feature of Macie
knowledge portal S3 might contain sensitive information like PII data, database backups, SSL private keys and
various others.
Amazon Macie makes use of machine learning  to identify sensitive data stored in A WS.</p>
<pre><code>                                   Amazon GuardDuty 

                      Basics of Threat Detection 
</code></pre>
<p>Threat detection  is an organization&rsquo;s ability to monitor events  in the environment
and detect real security incidents.
1.A Prod server always connects to services in US region.
2.There is a communication between Prod Server &amp; North Korea.</p>
<pre><code>    Important Requirement for Threat Detection 
</code></pre>
<p>One of the important requirement for Threat Detection is that appropriate level of
logs and events are needed for analysis to work.
Threat Detection Tool</p>
<pre><code>                   Understanding the Challenge 
</code></pre>
<p>One of the primary challenge is the implementation of threat detection solution.
Organization have to configure appropriate set of tools and configure logging
and create necessary level of rules for detection.
The above point is not an issue for mid to large sized organization but difficult to
implement for smaller organizations due to resource constraints.</p>
<pre><code>            Introducing Amazon GuardDuty 
</code></pre>
<p>Amazon GuardDuty is a threat detection service  that continuously monitors for
malicious activity  and unauthorized behavior to protect your Amazon Web
Services accounts, workloads, and data stored in Amazon S3
Findings
Backdoor:EC2/C&amp;CActivity.B
Discovery:S3/MaliciousIPCaller
Backdoor:Lambda/C&amp;CActivity.B S3 Buckets
EC2 Instances
Account Users GuardDuty
Sample GuardDuty Findings</p>
<pre><code>                        Supported Resource T ypes 
</code></pre>
<p>A GuardDuty finding represents a potential security issue detected  within your
network.
Following are the supported types of findings available:
●EC2 finding types
●EKS Runtime Monitoring finding types
●IAM finding types
●Kubernetes audit logs finding types
●Lambda Protection finding types
●Malware Protection finding types
●RDS Protection finding types
●S3 finding types</p>
<pre><code>               Which Logs Are Analyzed By Default? 
</code></pre>
<p>When you enable GuardDuty in your AWS account, GuardDuty automatically
starts to monitor these log sources.
1.AWS CloudTrail event logs
2.AWS CloudTrail management events
3.VPC Flow Logs
4.DNS logs</p>
<pre><code>                               Amazon Inspector 

                        Basics of A WS Inspector 
</code></pre>
<p>Amazon Inspector is an automated vulnerability management service  that
continually scans AWS workloads for software vulnerabilities and unintended
network exposure.
Amazon Inspector Scan them ALL</p>
<pre><code>                                Similar to Nessus 

                      Supported Resource T ypes 
</code></pre>
<p>AWS Inspector can scan wide variety of AWS workloads.
These include:
●EC2 Instances.
●ECR Repositories
●Lambda Functions</p>
<pre><code>                    Amazon Inspector - Practical 

                           Points to Note - EC2 
</code></pre>
<p>To provide CVE data for your EC2 instance, Amazon Inspector requires that the
SSM agent be installed and activated.
This agent is pre-installed on many EC2 instances, but you may need to activate
it manually
Amazon Inspector
SSM Agent
Points to Note
With Amazon Inspector, you don&rsquo;t need to manually schedule or configure
assessment scans. Amazon Inspector automatically discovers and begins
scanning your eligible resources.</p>
<p>Relax and Have a Meme Before Proceeding
knowledge portal</p>
<pre><code>                  Security Hub 
</code></pre>
<p>Centralized Security Hub
Overview of Security Hub
knowledge portal
A WS Security Hub gives you a comprehensive view of your high-priority security alerts and
compliance status across A WS accounts.
AWS Guard Duty
AWS Inspector
AWS Macie      Security Hub</p>
<p>Supported Compliance Standard
knowledge portal
A WS Security Hub also has ability to generate its own findings by running automated and
continuous checks against the rules in a set of supported security standards.
Following Standards are supported:
● CIS A WS Foundation
● PCI DSS</p>
<pre><code>                  Security Hub 
</code></pre>
<p>Centralized Security Hub
Overview of Security Hub
knowledge portal
A WS Security Hub gives you a comprehensive view of your high-priority security alerts and
compliance status across A WS accounts.
AWS Guard Duty
AWS Inspector
AWS Macie      Security Hub</p>
<p>Supported Compliance Standard
knowledge portal
A WS Security Hub also has ability to generate its own findings by running automated and
continuous checks against the rules in a set of supported security standards.
Following Standards are supported:
● CIS A WS Foundation
● PCI DSS</p>
<pre><code>                               Web Application Firewalls 
                               Simple Analogy 
</code></pre>
<p>Imagine a security guard letting everyone into a concert as long as the ticket is
valid.
He does not check what they&rsquo;re bringing inside their bags.
If someone brings in something dangerous hidden in their bag, the guard won’t
notice.</p>
<pre><code>                 Basics of Network-Level  Firewalls 
</code></pre>
<p>Network-level  firewalls primarily checks the basic details like the  (source IP)
and where they want to go (destination IP and port).
These firewalls don’t see inside the actual request.
Firewall
Checks
Source IP
Ports Packet
W eb Application Firewall
A Web Application Firewall  looks inside the web requests to identify the
malicious code in the web request.
Web Application Firewall
Checks
Analyze The Actual Request Payload Packet
Example Analogy - Envelope
Source : 192.168.10.20
Destination: 10.77.20.50
Port: 22 Network level Firewall reads the basic details from outside of envelope to finalize
however WAF opens the envelope and, analyzes the inner contents of the
envelope</p>
<pre><code>                               W orkflow Architecture 
</code></pre>
<p>In a typical architecture, you will use Firewall and WAF to analyze traffic before
sending it to the backend application.
Firewall Web Application Firewall
Security Tools Packet</p>
<pre><code>                             W AF Provider Offerings 
</code></pre>
<p>Modsecurity  is one of the very popular open source web application firewall.
There are various other popular offerings from CloudFlare, Akamai, AWS and
other providers.
AWS WAF
AWS Web Application Firewall (WAF)
Setting the Base
AWS WAF is a managed  web application firewall offering.
It helps protect web applications from common web exploits  that could affect and
compromise your application.</p>
<pre><code>                  Benefit of A WS W AF - Integrations 
</code></pre>
<p>AWS WAF can easily be integrated  with Application Load Balancers, API
Gateways, AWS CloudFront distributions and more, making it easy to deploy.
Sample Reference
Supported Resource T ypes
You can protect the following resource types using AWS WAF
1.Amazon CloudFront distribution
2. Amazon API Gateway REST API
3. Application Load Balancer
4. AWS AppSync GraphQL API
5. Amazon Cognito user pool
6. AWS App Runner service
7. AWS Verified Access instance
8. AWS Amplify
The list of integrations can be updated in the future as new ones are added
regularly.</p>
<pre><code>                         What about W AF Rules 
</code></pre>
<p>You have option to either create your own WAF rules or you can use managed
rule sets that are available.
Create Custom Rules Use Managed Rules
Components of AWS WAF
Setting the Base
There are three important components of AWS WAF.
AWS WAF Rules Rule Groups WebACL
Components
1 - Rules
Rule defines how to inspect HTTP(S) web requests  and the action to take on a
request when it matches the inspection criteria.
Each rule can contain multiple rule statements.
Rules with multiple statements can be AND, OR, NOT
Rule Number Rule Statement
Rule 1 Check if request is coming from North Korea
Rule 2 Check for SQL Injection
Reference Screenshot - Geolocation Rule</p>
<pre><code>                                  Rule Actions 
</code></pre>
<p>What If a specific request matches a rule statement, what action should AWS
WAF take?
Rule Actions Description
Allow Allows the request to be forwarded to the protected AWS resource.
Block AWS WAF blocks the request..
Count AWS WAF counts the request but does not determine whether to allow it
or block it.
Captcha and
Challenge AWS WAF uses CAPTCHA puzzles and silent challenges to verify that
the request is not coming from a bot.
Reference Screenshot - Rule Actions</p>
<pre><code>                               2 - Rule Groups 
</code></pre>
<p>You can package multiple rules into a Rule Group for reuse.
Rule Group SQLi Rules
XSS Rules Country Rules
Header Rules
T ypes of Rule Groups
Types of Rule Groups Description
AWS Managed Created and Managed by AWS
AWS Marketplace Available by subscription through AWS Marketplace. Each of these
rule groups is owned and managed by the AWS Marketplace
seller.
Customer Managed Custom Collection of your own rules.
Reference Screenshot - Rule Groups</p>
<pre><code>                               3 - W ebACL 
</code></pre>
<p>WebACL acts as a central resource in AWS WAF. It acts as a container for rules
and rule groups .
You associate WebACL with one or more AWS resources like Load Balancers.
WebACL
Rule Group 1 Rule Group 2 Rule Group 3
ELBAssociation
Revision of Concepts</p>
<p>Relax and Have a Meme Before Proceeding
knowledge portal</p>
<p>HTTPS
Secure Communication
Overview of HTTPS
knowledge portal HTTPS is an extension of HTTP .
In HTTPS, the communication is encrypted using T ransport Layer Security (TLS)
The protocol is therefore also often referred to as HTTP over TLS  or HTTP over SSL.</p>
<p>Scenario 1:  MITM Attacks
● User is sending their username and password in plaintext to a W eb Server for authentication
over a network.
● There is an Attacker sitting between them doing a MITM attack and storing all the
credentials he finds over the network to a file:</p>
<p>Scenario 2:  MITM &amp; Integrity Attacks
● Attacker changing the payment details  while packets are in transit.</p>
<p>Introduction to SSL/TLS
T o avoid the previous two scenarios (and many more), various cryptographic standards were
clubbed together to establish a secure communication over an untrusted network and they were
known as SSL/TLS.</p>
<p>Protocol Year
SSL 2.0 1995
SSL 3.0 1996
TLS 1.0 1999
TLS 1.1 2006
TLS 1.2 2008
TLS 1.3 2018
Understanding it in easy way
knowledge portal Every website has a certificate (like a passport which is issued by a trusted entity).
Certificate has lot of details like domain name it is valid for, the public key , validity and others.</p>
<p>Understanding it in easy way
knowledge portal Browser (clients) verifies if it trusts the certificate issuer.
It will verify all the details of the certificate.
It will take the public key and initiate a negotiation.
Asymmetric key encryption is used to generate a new temporary
symmetric key which will be used for secure communication.</p>
<p>W eb Server Configuration
knowledge portal</p>
<p>A WS Certificate Manager
Certificates Again :)
Earlier Approach
knowledge portal I have a website and I need to use HTTPS. There are two ways, self-signed certificate and the CA
signed certificate.
Self Signed Certificate
CA Signed Certificate
Generating Certificates
knowledge portal T o generate a certificate for your domain, you will have to go to a Certificate Authority and after
required level of validation, you would be issued a certificate.
Certificate Authority
User Generate certificate for .in
Validated for 1 year.
cert private key
A WS Certificate Manager
knowledge portal A WS Certificate Manager (ACM) handles the complexity of creating, storing, and renewing public
and private SSL/TLS X.509 certificates and keys that protect your A WS websites and applications.
ACM
Load Balancer
Generate certificate for .in
Integrate certificate with ELB Cert Integrated
User
A WS Control T ower
Agility and Governance
Challenges with Multi-Account Environments
Most of the organizations follow a multi-account based architecture.
When the amount of A WS account increases, it leads to own set of challenges.
knowledge portal    Dev AWS 1
Dev AWS 2   Stage AWS  Prod AWS 2 Security AWS   Dev AWS 3  Prod AWS 1  Identity AWS
Challenge 1 - Identity Management
knowledge portal   Dev AWS 1
Dev AWS 2   Stage AWS  Prod AWS 2 Security AWS   Dev AWS 3  Prod AWS 1  Identity AWS username1, password1 username2, password2 username3 password3
Solution 1 - Single Sign On
knowledge portal   Dev AWS 1
Dev AWS 2   Stage AWS  Prod AWS 2 Security AWS   Dev AWS 3  Prod AWS 1  Identity AWS
Single sign-on (SSO) is an authentication method that enables users to securely authenticate with
multiple applications and websites by using just one set of credentials.
AWS SSO
Challenge 2 - Security Hardening
knowledge portal   Dev AWS 1
Dev AWS 2   Stage AWS  Prod AWS 2 Security AWS   Dev AWS 3  Prod AWS 1  Identity AWS     Enable AWS Config AWS Organizations &amp; SCP Centralized Logging
Solution 2 - Security Automation
knowledge portal
A WS CloudFormation StackSets allows you to create, update, or delete stacks across multiple
accounts and Regions with a single operation
●Enable AWS Config
●Enable AWS CloudTrail
●Enable AWS Guard Duty
Challenge 3 - Centralized Console
knowledge portal
W e need to have a centralized console that shows details of all A WS accounts, their security
compliance level,  and other information
Central AWS AWS Account 1
AWS Account 2
AWS Account 3
knowledge portal A WS Control T ower
A WS Control T ower offers a straightforward way to set up and govern an A WS
multi-account environment, following the best practices.
AWS Control Tower
AWS Organizations
CF StackSets Config Aggregators  AWS SSO
Best
Practices   DEV Account
Prod Account
Firewall Manager
Centrally Manage Rules
Understanding the Challenge
Most of the organizations are opting for Multi-Account based strategy for separation of
environments (dev , stage, prod)
Security T eam needs to create, maintain and update security services across all of the accounts.
AWS Account 1
AWS Account 2
AWS Account 3
WAF DNS Firewall N/W Firewall
Understanding the Basics
A WS Firewall Manager is a security management service which allows you to centrally configure
and manage firewall rules across your accounts and applications in A WS Organizations</p>
<pre><code>AWS Account 1 
AWS Account 2 
AWS Account 3   Common Rules 
</code></pre>
<p>Firewall Manager
WAF Rules
Supported Service
Firewall Manager supports wide variety of services, including:
● A WS W AF
● VPC Security Groups
● A WS Network Firewall
● Route53 DNS Firewall
● A WS Shield Advanced
● Palo Alto Cloud Next-generation firewalls
Important Prerequisite:  A WS Organizations + A WS Config.<br>
knowledge portal
Benefits of Firewall Manager</p>
<ol>
<li>
<p>Simplify management of firewall rules across your accounts</p>
</li>
<li>
<p>Ensure compliance of existing and new applications</p>
</li>
<li>
<p>Easily deploy managed rules across accounts</p>
</li>
<li>
<p>Centrally deploy protections for your VPCs</p>
<p>knowledge portal
AWS Secrets Manager</p>
<pre><code>          Understanding the Challenge 
</code></pre>
</li>
</ol>
<p>In many organizations, secrets are hard coded directly as part of the application.
If you want to rotate the secret credential, all the application server needs to be
updated. If you miss one, the production can go down.
Database DB Credentials
User = dbadmin
Pass = dbpwd1#
EC2Connect
Introducing Secrets Management
Secret management  is a practice that allows developers to securely store
sensitive data, such as passwords, keys, and tokens, in a secure environment
with strict access controls.
Popular Tools: HashiCorp Vault,  AWS Secrets Manager
Database EC2Connect
Fetch Credentials
Introduction to T opic
AWS Secrets Manager  helps you manage, retrieve, and rotate database
credentials, API keys, and other secrets throughout their lifecycles.
Database EC2Connect Fetch Credentials
Secrets Manager
Referenced from Docs</p>
<pre><code>                    Rotate A WS Secrets Manager secrets 
</code></pre>
<p>Rotation  is the process of periodically updating a secret.
Secrets Manager rotation uses an AWS Lambda function to update the secret
and the database.
To rotate a secret, Secrets Manager calls a Lambda function according to the
schedule you set up. You can set a schedule to rotate after a period of time, for
example, every 30 days.</p>
<p>Relax and Have a Meme Before Proceeding
knowledge portal</p>
<pre><code>                                 Rotating Secrets 

                         Basics of Rotation 
</code></pre>
<p>Rotation  is the process of periodically updating a secret.
Secrets Manager rotation uses an AWS Lambda function to update the secret
and the database.
Rotate Secret Every 30 days
Lambda Secrets Manager
Points to Note
To rotate a secret, Secrets Manager calls a Lambda function according to the
schedule you set up. You can set a schedule to rotate after a period of time, for
example, every 30 days.
Secrets Manager provides rotation function templates for various use-cases
related to RDS, DocumentDB, RedShift etc.
Replicate AWS Secrets Manager secrets</p>
<pre><code>             Understanding with Use-Case 
</code></pre>
<p>In a Disaster Recovery based architecture, it is necessary to setup necessary
level of replication across regions for failover.
us-east-1 RDS
Lambda Secret Manager
Replicating Data Across Regions
In this architecture, the data and secrets are replicated across regions.
us-east-1
Replication
Replication
ap-south-1 Secret Manager Secret Manager
Lambda Lambda RDS RDS
Points to Note
You can replicate your secrets in multiple AWS Regions to support applications
spread across those Regions to meet Regional access and low latency
requirements.
If you later need to, you can promote a replica secret to a standalone and then
set it up for replication independently.
If you turn on rotation for your primary secret, Secrets Manager rotates the
secret in the primary Region, and the new secret value propagates to all of the
associated replica secrets.</p>
<pre><code>                               IAM Access Analyzer 

                    Understanding the Basics 
</code></pre>
<p>AWS IAM Access Analyzer provides the following capabilities :
●IAM Access Analyzer helps identify resources in your organization and
accounts that are shared with an external entity.
●IAM Access Analyzer validates IAM policies against policy grammar and
best practices.
●IAM Access Analyzer generates IAM policies based on access activity in
your AWS CloudTrail logs.
Capability 1 - Identify Shared Resource
IAM Access Analyzer helps you identify the resources in your organization and
accounts, such as Amazon S3 buckets or IAM roles, shared with an external
entity.
Critical S3 Bucket AWS Account C
External Client
External Access External Access
Supported Resource T ypes
IAM Access Analyzer analyzes the following resource types:
●Amazon Simple Storage Service buckets
●AWS Identity and Access Management roles
●AWS Key Management Service keys
●AWS Lambda functions and layers
●Amazon Simple Queue Service queues
●AWS Secrets Manager secrets
●Amazon Simple Notification Service topics
●Amazon Elastic Block Store volume snapshots
●Amazon Relational Database Service DB snapshots
●Amazon Relational Database Service DB cluster snapshots
●Amazon Elastic Container Registry repositories
●Amazon Elastic File System file systems</p>
<pre><code>                                  Points to Note 
</code></pre>
<p>For each instance of a resource shared outside of your account, IAM Access
Analyzer generates a finding
You can review findings to determine if the access is intended and safe or if the
access is unintended and a security risk</p>
<pre><code>           Capability 2 - V alidating IAM Policy 
</code></pre>
<p>IAM Access Analyzer validates your policy against IAM policy grammar and best
practices.
You can view policy validation check findings that include security warnings,
errors, general warnings, and suggestions for your policy.</p>
<pre><code>           Capability 3 - Generate IAM Policy 
</code></pre>
<p>IAM Access Analyzer analyzes your AWS CloudTrail logs to identify actions and
services that have been used by an IAM entity (user or role) within your
specified date range.
It then generates an IAM policy that is based on that access activity.</p>
<pre><code>                                  Amazon CodeGuru 

                     Understanding the Challenge 
</code></pre>
<p>Development code can contain wide variety of issues  that needs to be
addressed and optimized.
Sample Code Type of Issues
Security
Performance
Quality
What is Needed
Customers need tools  that can scan the code from repository and quickly
identify the issues  so that they can be addressed in development stage itself.
Sample Code
Looks like there is
hardcoded secret here!
Security Guy
Setting the Base
Amazon CodeGuru provides set of tools to improve application code security,
quality, and performance with ML
CodeGuru Features Description
CodeGuru Security Identity Vulnerabilities in Code &amp; Provide Recommendations
CodeGuru Profiler Visualize &amp; Provide Recommendation on App Performance.
CodeGuru Reviewer Evaluates Code Against Best Practices
CodeGuru Profiler
CodeGuru Profiler visualizes your application performance , showing you the
methods that take the most time and CPU capacity to execute.
This helps you diagnose and isolate root causes of application issues during
operational events much faster.</p>
<pre><code>                        CodeGuru Reviewer 
</code></pre>
<p>CodeGuru Reviewer connects to code repositories  such as GitHub, AWS
CodeCommit and Bitbucket.
It evaluates your code against best practices  observed in popular open source
code repositories and Amazon’s own code base</p>
<pre><code>                            CodeGuru Security 
</code></pre>
<p>CodeGuru Security is an ML and program analysis-based code scanning tool
that finds security vulnerabilities  in your Java, Python, and JavaScript code.
CodeGuru Security detects OWASP Top 10 issues and many others.
CodeGuru Security is a static application security testing ( SAST ) tool.</p>
<pre><code>                                       AWS CodeBuild 
                     Understand with an Example 
</code></pre>
<p>A developer has written a C-based code and he wants to deploy the final
application to the production environment.
The First step : Compilation to get the output binary.
gccCompile
Application
Binary
Introducing A WS CodeBuild
AWS CodeBuild is a fully managed build service  in AWS.
It compiles your source code, runs tests, and produces ready-to-deploy software
packages.
Store final app
binary to S3
Fetch Code Compilation
Run Tests Store Artifacts
Overview of Buildspec File
A buildspec  is a collection of build commands and related settings, in YAML
format, that CodeBuild uses to run a build.</p>
<pre><code>                                       AWS CodeDeploy 
                              CodeBuild  W orkflow 
</code></pre>
<p>AWS CodeBuild  compiles the application, runs necessary tests, and uploads the
artifacts to S3 bucket.
Issue:  The application binary is still in S3 and not deployed to Production.
AWS CodeBuild
S3 Bucket
Application
Binary
Fetch Code Compilation
Run Tests Store Artifacts
Overview of CodeDeploy
AWS CodeDeploy is a managed deployment service  that automates software
deployments to a variety of compute services such as Amazon EC2, Fargate,
Lambda and others.
Deploy
Code Deploy
S3 Bucket Application
Binary
AWS Codepipeline
Current Setup
At this stage, we managed each component manually to build and deploy the
application.
AWS CodeBuild
GitHub
Code Deploy S3EC2
Application
Binary</p>
<pre><code>                   Overview of Code Pipeline 
</code></pre>
<p>AWS CodePipeline is a fully managed continuous delivery service  that helps you
automate your release pipeline.
Pipeline
EC2
Source CodeBuild CodeDeploy
W orkflow - Part 1
When developers commit changes to the source repository, CodePipeline automatically
detects the changes. The changes are built, and the resulting application can be deployed
to the staging servers for testing.</p>
<pre><code>                           W orkflow - Part 2 
</code></pre>
<p>If the application is stable on the staging server, and after a manual approval step is
completed, CodePipeline deploys the tested and approved code to production
instances.</p>
<pre><code>                                    Simple Pipeline 
                     Pipeline with Approval Stage 
             Launch T emplates 
</code></pre>
<p>Launching EC2 The Easy W ay
Understanding the Challenge
When you launch an EC2 instance, there are various configurations that needs to be set.
Some of the common configuration includes:
● AMI ID
● Instance T ype
● Security Group
● Key Pair
● Storage
● IAM Role
● VPC
Everytime when you intend to launch instance, going through process is time consuming,
knowledge portal
Introduction to Launch T emplates
Launch templates enable you to store launch parameters so that you do not have to specify
them every time you launch an instance.
knowledge portal</p>
<pre><code>      EC2 Auto Scaling  
</code></pre>
<p>Up and Down, Round and Round
knowledge portal                                     Understanding Scalability
.
● Scalability is the ability of a system to change in size depending on the needs.
● Infrastructure should scale to support changing in traffic patterns.</p>
<p>knowledge portal                  Launch and Remove Servers Based on Load
What if new servers automatically get launched on high load?
Simple Scaling Policy:
Base :  2 servers
Scalable :
If average CPU utilization &gt; 60%      ;      add two more instance
If average CPU utilization &lt; 30%       ;     remove two instance</p>
<pre><code>                        Overview of EC2 Auto-Scaling 
</code></pre>
<p>Amazon EC2 Auto Scaling helps you maintain application availability and allows you to
automatically add or remove EC2 instances according to conditions you define.
Example Scenario:
● Minimum: 2 EC2 instance
● Maximum: 10 EC2 instance
● Threshold:   50% of CPU</p>
<p>knowledge portal                                 Multiple T ypes of Scaling
Type of Scaling Description
Scheduled Scaling Servers are scaled based on a specific schedule.
For example, every week the traffic to your web application
starts to increase on Wednesday, remains high on
Thursday, and starts to decrease on Friday
Dynamic Scaling Follow the demand curve for scaling activities.
CPU Utilization higher then 90%
Predictive Scaling Predictive Scaling has machine learning algorithms that
detect changes in daily and weekly patterns, automatically
adjusting their forecasts.
Dynamic Scaling
Overview
2 T ypes of Scaling
There are two primary types of scaling  approaches that are available:
knowledge portal             Scaling Types
Manual Scaling Dynamic Scaling
Dynamic Scaling
When you configure dynamic scaling, you define how to scale the capacity of your Auto
Scaling group in response to changing demand.
Scaling Policy Types Descriptions
Target tracking scaling Increase or decrease the current capacity of the group based
on a target value for a specific metric.
Step scaling Increase or decrease the current capacity of the group based
on a set of scaling adjustments, known as step adjustments,
that vary based on the size of the alarm breach.
Simple scaling Increase or decrease the current capacity of the group based
on a single scaling adjustment.
Simple Scaling Policy
With simple scaling policy , you can configure a specific number of instances to be added
when a threshold reaches certain value.
knowledge portal</p>
<p>Step Scaling Policy
In step scaling, the adjustment of the current capacity of instances vary based on the size
of the alarm breach.
knowledge portal</p>
<p>T arget T racking Policy
With target tracking scaling policies, you select a scaling metric and set a target value.
The scaling policy adds or removes capacity as required to keep the metric at, or close to,
the specified target value.
knowledge portal</p>
<p>Use Case of Thermostat
A thermostat is a component which senses the temperature of a physical system and
performs actions so that the system&rsquo;s temperature is maintained near a desired setpoint.
Example:
● Desired = 24
● Current = 18
knowledge portal</p>
<p>Example T arget T racking Policy
Metric T ype = CPU Utilization
T arget V alue = 50%
knowledge portal
50% CPU 50% CPU
Example T arget T racking Policy
Metric T ype = CPU Utilization
T arget V alue = 50%
Actual V alue = 70%
knowledge portal
70% CPU 70% CPU
Example T arget T racking Policy
Metric T ype = CPU Utilization
T arget V alue = 50%
knowledge portal
50% CPU 50% CPU
40% CPU
Example T arget T racking Policy
Metric T ype = CPU Utilization
T arget V alue = 50%
Actual V alue = 15%
knowledge portal
15% CPU 15% CPU
15% CPU
Example T arget T racking Policy
Metric T ype = CPU Utilization
T arget V alue = 50%
Actual V alue = 45% (average)
knowledge portal
45% CPU 15% CPU
15% CPU
Scheduled Scaling
Overview and Practical
Overview of Scheduled Scaling
Scheduled scaling allows you to set your own scaling schedule.
For example, let&rsquo;s say that every week the traffic to your web application starts to increase
on W ednesday , remains high on Thursday , and starts to decrease on Friday .
Scaling actions are performed automatically as a function of time and date.
knowledge portal
Relax and Have a Meme Before Proceeding
knowledge portal</p>
<p>Auto-Scaling LifeCycle Hooks
Challenges and Structure
Overview of LifeCycle Hooks
knowledge portal Auto-Scaling Lifecycle hooks allows us to have control over instance launch and
termination state within auto-scaling group.
Sample Use-Case:
● Y ou have EC2 instance which is scheduled to be terminated.
● Y ou want to backup all it’s logs to S3 and run some deregistration scripts.
● T erminate instance once 2nd steps is completed.</p>
<p>knowledge portal</p>
<p>knowledge portal
Step 1: Instance A waiting T ermination
knowledge portal
Step 2: Confirmation from Automation
knowledge portal
Step 3: Go Ahead!
A WS Config
Overview of Infrastructure Changes
A WS Config - High Level Overview
knowledge portal
A WS Config is primarily used to record the resource configuration changes over time.
An EC2 instance was hosting website from past 90 days. Suddenly in last one week, there
have been a lot of issues with the requests. What was changed?</p>
<p>Audit and Compliance
knowledge portal
A WS Config comes with large set of rules that can continuously monitor your A WS
environment and report the findings.</p>
<p>Conformance Packs
knowledge portal
A conformance pack is a collection of A WS Config rules and remediation actions that can
be easily deployed</p>
<p>Pricing of A WS Config
knowledge portal Y ou pay $0.003 per configuration item recorded in your A WS account per A WS Region. A
configuration item is recorded whenever a resource undergoes a configuration change or a
relationship change.
Based on rule evaluation. A rule evaluation is recorded every time a resource is evaluated
for compliance against an A WS Config rule.
Y ou are charged per conformance pack evaluation in your A WS account per A WS Region
based on the tier below .</p>
<pre><code>                         AWS Conﬁg Aggregator 

                    Understanding the Basics 
</code></pre>
<p>An aggregator  is an AWS Config resource type that collects AWS Config
configuration and compliance data from the following:
1.Multiple accounts and multiple regions.
2.Single account and multiple regions.
3.An organization in AWS Organizations and all the accounts in that
organization which have AWS Config enabled.</p>
<pre><code>                    Understanding the W orkflow 
</code></pre>
<p>Config Aggregator can collection Config Data from multiple external accounts.
Config Aggregator AWS Account A
AWS Account B AWS Account C Collect
Config Data
Collect
Config Data
Important Step - Authorization
In the external accounts, you need to allow a specified aggregator account  and
Region to collect AWS Config configuration and compliance data from your
current account.
External AWS Account
Elastic Beanstalk
T raditional Approach
Use-Case:  Deploy a simple Hello World application for production.
Resources to be created:   AWS EC2, ELB, Auto-Scaling, CloudWatch,
Web-Server Configuration, and others.
EC2 Resource CloudWatch EC2ASG Logs</p>
<pre><code>                       Elastic Beanstalk Approach 
</code></pre>
<p>Use-Case:  Deploy a simple Hello World application for production.
Solution:  Create Elastic Beanstalk Environment with correct configuration.
EC2 Resource CloudWatch EC2ASG Logs
Elastic Beanstalk Create
Elastic Beanstalk Managed Environment
Introducing Elastic Beanstalk
With AWS Elastic Beanstalk, you simply upload your application, specify the
presets and platform type, and Elastic Beanstalk automatically handles  the
details of capacity provisioning, load balancing, scaling, and application health
monitoring.
Presets
Highly Available
Create env with
following
configuration
Elastic Beanstalk
Environment Presets
You can choose among wide range of presets to launch environments based on
your requirement.</p>
<pre><code>                             Practical W orkflow 

                      Elastic Beanstalk - Deployment Policy  
                               Simple Use-Case 
</code></pre>
<p>Use-Case:  You want to deploy v2 of the application.
v1-app
v1-app v2-app Deploy Parallely
Deployment Policies in Elastic Beanstalk
There are multiple set of Deployment policies supported in Elastic Beanstalk.
Deployment Policies
All at once
Rolling
Rolling with additional batch
Immutable
Traffic splitting
Elastic Beanstalk
Deployment Policy - All At Once
Deploys the new version to all instances simultaneously.
Pros:  Fastest method.
Cons:  Causes downtime; all users experience the update at once.
v1-app v1-app v2-app v2-app v2-faulty-app
Working Environment Newer Faulty Environment
Deployment Policy Options A vailable
Deployment Policies Description
All at once Deploys the new version to all instances simultaneously.
Rolling Updates a batch of instances at a time; the environment remains available
Rolling with additional batch Launches an extra batch of instances to maintain full capacity during deployment.
After update, old instances are terminated.
Immutable Deploys the new version to a fresh group of instances (a full batch), then swaps
them in after successful deployment.
Traffic splitting Splits incoming traffic between old and new application versions, allowing gradual
exposure.
Blue / Green
Blue environment  = Existing environment in production receiving live traffic.
Green environment  = Parallel environment running different version of app.
Deployment  = Routing production traffic from blue to green environment.
Elastic Beanstalk    v1   v1
v2   v2
Rolling Deployments
Deployment Approach - Rolling
Application is deployed to your environment one batch of instances at a time.
v1-app v1-app v2-app v1-app v2-faulty-app
Working Environment Partially Faulty Environment
Point to Note - Rolling Update
Advantages:
1.Reduces complete downtime, safer than all-at-once.
2.Each batch of instance is taken out of service while deployment takes place.
Disadvantages:
1.Reduces the overall capacity of servers. Might impact during high traffic load.
2.Not suitable for critical applications.</p>
<pre><code>                Deployment Policy - Rolling with additional batch 
                                  Setting the Base 
</code></pre>
<p>Deploy the new version in batches, but first launch a new batch of instances to
ensure full capacity during the deployment process.
v1-app v1-app
Working Environment v1-app v1-app
Working Environment v2-app
Temporary Extra Batch v2-app Deploy on
original batch
W orkflow Steps - Success Deployment (batchSize of 1)
Let’s consider instance-A  and instance-B  are currently running and batchsize=1.
Deployment is initiated with new version of application.
1.instance-C  is launched and deployment first happens here. After successful
deployment, the instance-C gets registered in the load balancer.
2.instance-A  is deregistered from ELB and deployment happens on instance-A
with newer version of app. After successful deployment, the instance-A is
registered back to the load balancer.
3.instance-B  is deregistered from load balancer and terminated.</p>
<pre><code> W orkflow Steps - Failed Deployment (batchSize of 1) 
</code></pre>
<p>Let’s consider instance-A  and instance-B  are currently running and batchsize=1.
Deployment is initiated with new version of application.
1.instance-C  is launched and deployment happens here.
2.Deployment fails.
3.instance-C  gets terminated.</p>
<pre><code>                                         Advantages 
</code></pre>
<p>No Loss of Capacity -  Your environment maintains full capacity throughout the
update, ensuring continued performance for your users.
Zero Downtime -  Application remains available to users throughout the deployment.
Reduced Deployment Risk -  Any issues are limited to the current batch, and the
batch can easily be discarded if deployment fails.</p>
<pre><code>                                     Disadvantages 
</code></pre>
<p>Higher Cost -  You pay for the additional batch of instances during the deployment,
increasing costs temporarily.
Instance quotas -   If you are near your AWS instance limit, you might not be able to
add the additional batch.</p>
<pre><code>                              Deployment Method - Blue/Green 
                                   Setting the Base 
</code></pre>
<p>Blue environment  = Existing environment in production receiving live traffic.
Green environment  = Parallel environment running different version of app.
Deployment  = Routing production traffic from blue to green environment.
Elastic Beanstalk    v1   v1
v2   v2
V arious ways to achieve Blue Green
Updating DNS Routing via Route53
Swap the Auto-Scaling Groups behind your ELB
Swap Launch Configurations
Swap Beanstalk Environments (applies only to EB environments)
EC2 Image Builder</p>
<pre><code>                              Setting Up the Base 
</code></pre>
<p>One of my responsibilities was to provide the latest “Hardened AMI” ID to
developers from which they can launch their EC2 instances for testing.
Golden AMI Run Ansible
Hardening Role
Create AMI
Terminate EC2
Zeal
Understanding the Challenge
1.Entire process is manual.
2.What happens if Security Guy is on leave?</p>
<pre><code>                            EC2 Image Builder 
</code></pre>
<p>Keeping Virtual Machine and container images up-to-date can be time
consuming, resource intensive, and error-prone.
EC2 Image Builder simplifies  the building, testing, and deployment of Virtual
Machine and container images for use on AWS or on-premises.</p>
<pre><code>              Benefits - Integration with Other Services 
</code></pre>
<p>Benefit of EC2 Image builder is that it integrates well with other AWS services
like AWS Inspector for vulnerability scanning related use-cases.
Scan EC2
AWS Inspector
Benefits - Readymade Build Component
AWS provides several ready to use build components to install and configure
various software and configurations in the base AMI.</p>
<p>Amazon Kinesis
Streaming Data
knowledge portal Streaming data is the continuous flow of data generated by various sources
Basics of Streaming Data.
Processing Store Sensor 1
Sensor 2
Sensor 3
knowledge portal A financial institution tracks changes in the stock market in real time and adjust it’s portfolio
accordingly .
A media publisher streams billions of clickstream records from its online properties
Examples of Streaming Data</p>
<p>knowledge portal Streaming data processing requires two layers: a storage layer and a processing layer.
The storage layer needs to support record ordering and strong consistency , replayable reads and
the processing layer is responsible for consuming data from the storage layer, running
computation on that data and many other tasks.
Challenges with W orking of Streaming Data
Storage Layer Processing Layer
knowledge portal Amazon Kinesis makes it easy to collect, process, and analyze real-time, streaming data so you
can get timely insights and react quickly to new information.
Amazon Kinesis offers key capabilities to cost-effectively process streaming data at any scale
Basics of Amazon Kinesis</p>
<p>3 entities
knowledge portal There are 3 entities in this kind of use case:
Producer, Stream Store, Consumer
Amazon Kinesis
Producers Consumers
Amazon Kinesis Services
Capabilities of Kinesis Set of Services
Kinesis Offerings
knowledge portal Amazon Kinesis is a set of services which makes it easy to work with set of streaming data on
A WS.
Sr No Kinesis Services Description
1 Kinesis Data Stream Captures, processes and stores data streams in real-time
2 Kinesis Data Firehose Primary to move data from point A to point B.
3 Kinesis Data Analytics Analyze streaming data in real-time with SQL / Java code.
4 Kinesis Video Stream Capture, processes and stores video streams.
Kinesis Data Stream
knowledge portal It allows us to capture, process and store data streams.</p>
<p>Kinesis Firehose
knowledge portal Kinesis firehose delivers data from point A to point B.</p>
<p>Kinesis Data Analytics
knowledge portal Kinesis Data Analytics has ability to analyze data streams in real time.</p>
<p>Kinesis Video Stream
knowledge portal Amazon Kinesis Video Streams makes it easy to securely stream video from connected
devices to A WS</p>
<p>913                Amazon OpenSearch</p>
<pre><code>                        Understanding the Basics 
</code></pre>
<p>Amazon OpenSearch is initially based on the forked version of ElasticSearch
Allow ingesting, searching and visualization of data.</p>
<pre><code>                   Storage Options - OpenSearch 

                             Basics of Nodes 
</code></pre>
<p>Amazon OpenSearch Service uses dedicated master nodes to increase cluster
stability.
A dedicated master node  performs cluster management tasks, but does not hold
data or respond to data upload requests
Master Nodes
Data Nodes
Storage Options
Master Nodes
“Hot” Data Nodes
Ultra Warm Indices
UltraWarm Data Nodes
Understanding the Basics
Standard data nodes use &quot; hot&quot; storage, which takes the form of instance stores
or Amazon EBS volumes attached to each node.
Hot storage provides the fastest possible performance for indexing and
searching new data.
OpenSearch Data Node
EBS  Instance Store
Benefits of UltraW arm Mode
The UltraWarm tier acts like a caching layer on top of the data in Amazon S3.
UltraWarm moves data from Amazon S3 onto the UltraWarm nodes on demand,
which speeds up access for subsequent queries on that data
You can add or remove UltraWarm nodes to increase or decrease the amount of
cache against your data in Amazon S3 to optimize your cost per GB</p>
<pre><code>                 Points to Note - UltraW arm 
</code></pre>
<p>Data in UltraWarm is immutable (cannot modify the data)
If needed, you can bring back data to hot tier.</p>
<pre><code>                              Cold Storage 
</code></pre>
<p>Cold storage lets you store any amount of infrequently accessed or historical
data on your Amazon OpenSearch Service domain and analyze it on demand, at
a lower cost than other storage tiers
Similar to UltraWarm storage, cold storage is backed by Amazon S3. When you
need to query cold data, you can selectively attach it to existing UltraWarm
nodes.</p>
<pre><code>                  Points to Note - Cold Storage 
</code></pre>
<p>Data is not directly queryable and must be attached before being analyzed.</p>
<pre><code>                             Billing Pointers 
</code></pre>
<p>The hot tier  requires you to pay for what is provisioned, which includes the
hourly rate for the instance type. Storage is either Amazon EBS or a local SSD
instance store.
UltraWarm nodes  charge per hour just like other node types, but you only pay for
the storage actually stored in Amazon S3.
Cold storage  doesn’t incur compute costs, and like UltraWarm, you’re only billed
for the amount of data stored in Amazon S3.</p>
<pre><code>                              OpenSearch Architecture 
</code></pre>
<p>Amazon Athena
Query Logs from S3
Getting the basics right
knowledge portal Amazon Athena is service that allows us to analyze various log files from a data source using
standard SQL
SQL Query Analyze Data
Athena S3 Bucket Users
Approach Before Athena
knowledge portal
Y ou have CloudT rail logs in S3 and you want to see who has logged in, in the past 10 days.
● Create EC2 instances.
● Deploy monitoring stack like Splunk, ELK or others.
● Add the data source from S3 to import CloudT rail logs.
● Begin Analyzing.</p>
<p>VPC Flow Logs
Logs are A wesome
Simple Analogy - Visitor Register
knowledge portal In many of the societies across India, whenever a visitor visits, they first have to fill in their
information in the visitor register.
Some of the information includes:
● Name
● Source Place.
● Destination Place.
● Entry  and Exit Date/Time
● Purpose of W ork</p>
<p>Comparing Analogy with A WS Environment
knowledge portal Even in A WS, there can be thousands of users across the world who might be visiting your
environment.
Genuine
Hackers IP : 10.0.5.57
IP : 112.20.50.60
EC2-1 EC2-2 EC2-N
VPC Flow Logs
knowledge portal VPC Flow Logs is a feature that enables you to capture information about the IP traffic
going to and from network interfaces in your VPC.
Visitor Register VPC Flow Log
Capture Information Scope
knowledge portal The scope of the VPC Flow logs:</p>
<ol>
<li>
<p>Record the traffic information that is visiting the resource (eg EC2)</p>
</li>
<li>
<p>Record data about resource connecting to which outbound endpoint.
10.77.2.50 → EC2 Instance EC2 Instance → 192.168.0.5
knowledge portal</p>
<p>knowledge portal
Dashboards Built using VPC Flow Logs Data
Interface Level Flow Logs
knowledge portal VPC Flow Logs captures traffic at an interface level.
Flow logs do not capture real-time log streams for your network interfaces.</p>
</li>
</ol>
<p>High-Level Flow Logs Format
knowledge portal
version          -  The VPC Flow Logs Version
account-id     -  AWS Account ID
interface-id    -  The network interface id
srcaddr         -  The source address
destaddr        -  Destination Address
src port         -  Source Port
dest port       -  Destination Port
protocol        -  The protocol number
packets          -  Number of packets transferred
bytes              -  Number of bytes transferred
start               -  Start time in unix seconds
end                -  End time in unix seconds
action             -  ACCEPT or REJECT
log status       -  Logging status of flow log
2 7742829482 eni-4d788e3d 115.73.149.218 10.0.5.157 12053 23 6 2 88 1485439809 1485440090 REJECT OK
T ype of T raffic Not Logged
knowledge portal Flow logs do not capture all IP traffic. Some of these include:
● T raffic generated by instances when they contact the Amazon DNS server. If you use
your own DNS server, then all traffic to that DNS server is logged.
● T raffic generated by a Windows instance for Amazon Windows license activation.
● T raffic to and from 169.254.169.254 for instance metadata.
● DHCP traffic.</p>
<pre><code>                                 Service Quota 

                     Understanding the Basics 
</code></pre>
<p>AWS maintains service quotas (formerly called service limits) for each account
to help guarantee the availability of AWS resources and prevent accidental
provisioning of more resources than needed.
For example, you cannot run 100 EC2 instance in a new account suddenly.</p>
<pre><code>                         A WS Service Quota 
</code></pre>
<p>Each AWS service defines its quotas and establishes default values for those
quota. Depending on service, you can increase the quota value.</p>
<p>Advance Route53 Features
Interesting Features of Route53
Managed DNS Providers
knowledge portal Generally a managed DNS server supports basic functionality like :
● Domain Registration <br>
● GUI for putting DNS records
● Mapping &amp; Resolving various DNS Records.
● WHOIS Management</p>
<pre><code>  Route53 does a lot more 
</code></pre>
<p>knowledge portal
● Support of Public and Private Hosted Zones.
● Routing - W eighted, Latency , Geolocation, Round Robin
● Health Checks &amp; Monitoring
● Route53 Endpoints
● DNS Firewall</p>
<p>Traffic Flow Hosted Zone Health Checks
Route53 Health Checks
Back to Monitoring!
Overview of Health Checks
knowledge portal
Amazon Route 53 health checks monitor the health and performance of your web
applications, web servers, and other resources
Sends Sample Request
Received Response
Route53 Health Checkers
Route 53 has health checkers in locations around the world.
When you create a health check that monitors an endpoint, health checkers start to send
requests to the endpoint that you specify to determine whether the endpoint is healthy .
Health Checkers India
Ireland
USA
T ypes of Health Checks
Back to Monitoring!
T ype of Health Checks
knowledge portal
There are three primary type of Health Checks supported by Route53</p>
<ol>
<li>HTTP and HTTPS health checks</li>
<li>TCP health checks</li>
<li>HTTP and HTTPS health checks with string matching
Sends TCP Request
Received TCP Response
T ype 1 - HTTP/HTTPS
T wo important factors as part of this health check:</li>
<li>Route 53 must be able to establish a TCP connection with the endpoint within four
seconds.</li>
<li>In addition, the endpoint must respond with an HTTP status code of 2xx or 3xx
within two seconds after connecting.
knowledge portal
TCP () success.
HTTP 2xx or 3xx response
T ype 2 - TCP
Route 53 must be able to establish a TCP connection with the endpoint within ten seconds.
knowledge portal
TCP () success.
T ype 3 -  HTTP/HTTPS  with string matching</li>
<li>Route 53 must be able to establish a TCP connection with the endpoint within four
seconds.</li>
<li>In addition, the endpoint must respond with an HTTP status code of 2xx or 3xx
within two seconds after connecting.</li>
<li>Must receive response body within next two seconds containing a specific string.</li>
<li>The string must appear entirely in the first 5,120 bytes of the response body or the
endpoint fails the health check.
knowledge portal
TCP () success.
HTTP 2xx or 3xx response
Response Body: “”
Routing Policies
Great DNS Provider<br>
Routing Policies
knowledge portal Routing Policies determine how Amazon Route53 responds to the queries.
There are various supported routing policies available in Route53.
Each policy supports a specific use-case.
● Simple
● W eighted<br>
● Latency
● Failover
● Geolocation
● Multi-value answer</li>
</ol>
<p>Simple Routing Policy
knowledge portal In simple routing, there is a plain one to one mapping between domain and host.
Example:    blog..internal  A   128.199.241.125</p>
<p>knowledge portal                                               Failover Routing</p>
<p>Failover routing lets you route traffic to a resource when the resource is healthy or to a
different resource when the first resource is unhealthy .</p>
<p>knowledge portal                                            W eighted Routing
50% 50%W eighted routing helps us to route the traffic to multiple resources in a proportion that we
specify from our end.</p>
<p>knowledge portal                                        Latency Based Routing
If your application is hosted in multiple A WS regions, we can improve the performance for
the users by serving their request from A WS region that provides lowest latency .</p>
<p>GeoLocation Routing
knowledge portal Geolocation routing allows us to choose different resources for different users based on
different countries / continents.</p>
<p>Join us in our Adventure
.in/t wit t er
Be Awesome
.in/link edin
instructors@.in
Failover Routing Policy
Back to Monitoring!
knowledge portal                                               Failover Routing</p>
<p>Failover routing lets you route traffic to a resource when the resource is healthy or to a
different resource when the first resource is unhealthy .</p>
<p>knowledge portal                                            Maintenance Page</p>
<p>Relax and Have a Meme Before Proceeding
knowledge portal</p>
<p>W eighted  Routing
Route53 Routing Policy
knowledge portal            Overview of W eighted  Routing Policy
W eighted Routing  allows us to specify the proportion in which traffic should be routed to the
underlying servers.
If we want to send small portion of traffic to a new website theme, you can specify the weight of
1 and 99. The resource with 1 gets 1% of the traffic and other gets 99% of traffic.
India Singapore EC2 (Asia)
Oregon EC2 Weight: 1
Weight: 99
Geolocation Routing
Route53 Routing Policy
knowledge portal                    Overview of Geolocation Routing
Geolocation Routing allows us to choose resources based on the geographic location of the
users
For example, you might want all queries from Asia to be routed to an ELB load balancer in the
Singapore region.
India
USASingapore EC2 (Asia)
Oregon EC2
knowledge portal                                Important Caution
Geolocation Routing works by mapping database to IP address.
The results are not always accurate  as some ISP might not have any geolocation data associated
with them, and some ISP might move the IP block to different country without notification.
For such cases, Route 53 allows us to have a default resource block associated with the routing
policy .
Multivalue Answer Routing
Route53 Routing Policy
knowledge portal            Overview of Multivalue Answer Routing
Multivalue Answer Routing  allows us to return multiple values (such as IP address) in response
to a DNS query .
Multivalue Answer Routing also allows us to check the health of the resource so that Route53
responds with details of only healthy resources.
Route53 can respond to up to DNS query with up to 8 healthy records.</p>
<p>Latency Routing
Route53 Routing Policy
knowledge portal            Overview of Latency Based Routing
If your application is hosted in multiple A WS regions, we can improve the performance for the
users by serving their request from A WS region that provides lowest latency .
A request that is routed to Singapore today might be routed to India tomorrow .
India Singapore EC2 (Asia)
Oregon EC2 100 ms
50 ms Preferred
Route53 Resolver</p>
<pre><code>                  Understanding the Basics 
</code></pre>
<p>Amazon Route 53 Resolver responds to DNS queries  from AWS resources for
public records, Amazon VPC-specific DNS names, and Amazon Route 53
private hosted zones, and is available by default in all VPCs.
Route53 Resolver IP for example.com?
192.168.10.50
Address of Route53 Resolver
An Amazon VPC connects to a Route 53 Resolver at a VPC+2  IP address.
Route53 Resolver
VPC
172.31.0.0/16 172.31.0.2
Contents of /etc/resolv.conf  file of EC2 instance.</p>
<pre><code>                         Query Resolution 
</code></pre>
<p>A Route 53 Resolver automatically answers DNS queries for:
1.Local VPC domain names for EC2 instances (for example,
ec2-192-0-2-44.compute-1.amazonaws.com).
2.Records in private hosted zones (for example, acme.example.com).
3.For public domain names, Route 53 Resolver performs recursive lookups
against public name servers on the internet.</p>
<pre><code>                                       Hybrid DNS 

                        Revising the Basics 
</code></pre>
<p>Private hosted zones  contain records that specify how you want to route traffic
in an Amazon VPC.
01.demo.internal 172.31.0.5
02.demo.internal 192.168.10.5
Private Hosted Zone
Association
Problem Statement
Route53 does not  respond to queries which are not originating from the VPC.
If EC2 from VPC-2 sends query for 01.demo.internal to VPC-1 + 2 Address, it
will not be resolvable.
Associated
Peering VPC-1 VPC-2
Hybrid Architecture
On-Premise servers will not be able to resolve the domain of the Private Hosted
Zone through VPC-1 + 2 address.
Associated
VPC-1 On-Premise</p>
<pre><code>                        Probable Architecture 
</code></pre>
<p>●Host Custom DNS Server in VPC.
●On-Premise sends queries to Custom DNS Server.
●Custom DNS Server forwards it to Route53 and responds back.
On-Premise
Custom DNS Server
DNS Query DNS Query
DNS Answer DNS Answer
Challenge with Custom DNS Architecture
Customer has to manage Custom DNS Server.
High-Availability, Security, Scalability, Optimization = Customer Responsibility</p>
<pre><code>          Better Solution - Resolver Endpoints 
</code></pre>
<p>AWS has released Route53 Resolver Endpoints that can allow resolution of
private hosted zone domains from outside of the VPC.
On-Premise
Resolver Endpoint
DNS Query DNS Query
DNS Answer DNS Answer</p>
<pre><code>                    Route53 Resolver Endpoints 

        Basics of Route53 Resolver Endpoints 
</code></pre>
<p>AWS has released Route53 Resolver Endpoints that can allow resolution of
private hosted zone domains from outside of the VPC.
On-Premise
Resolver Endpoint
DNS Query DNS Query
DNS Answer DNS Answer</p>
<pre><code>                    T ypes of Resolver Endpoints 
</code></pre>
<p>There are 2 primary types of Resolver Endpoints
Resolver Endpoints
Inbound Resolver Endpoint Outbound Resolver Endpoint
Understanding Resolver Endpoints
Inbound Resolver  endpoints allow DNS queries to your VPC from your
on-premises network or another VPC.
Outbound Resolver  endpoints allow DNS queries from your VPC to your
on-premises network or another VPC.</p>
<pre><code>           Route53 Resolver - Inbound Endpoints 

            Understanding Resolver Endpoints 
</code></pre>
<p>Inbound Resolver  endpoints allow DNS queries to your VPC from your
on-premises network or another VPC.</p>
<pre><code>                 Inbound Endpoint W orkflow - 1 
</code></pre>
<p>1.A client in the on-premises data center needs to resolve a DNS query to an
AWS resource for the domain dev.example.com. It sends the query to the
on-premises DNS resolver.
2.The on-premises DNS resolver has a forwarding rule that points queries to
dev.example.com to an inbound endpoint.
3.The query arrives at the inbound endpoint through a private connection,
such as AWS Direct Connect or AWS Site-to-Site VPN, depicted as a virtual
gateway.</p>
<pre><code>                 Inbound Endpoint W orkflow - 2 
</code></pre>
<ol start="4">
<li>
<p>The inbound endpoint sends the query to Route 53 Resolver at the VPC +2.</p>
</li>
<li>
<p>Route 53 Resolver resolves the DNS query for dev.example.com and returns
the answer to the client via the same path in reverse.</p>
<pre><code>      Route53 Resolver - Outbound Endpoints 

         Understanding Outbound Endpoints 
</code></pre>
</li>
</ol>
<p>Outbound Resolver  endpoints allow DNS queries from your VPC to your
on-premises network or another VPC.</p>
<pre><code>                 Outbound Endpoint W orkflow - 1 
</code></pre>
<p>1.An Amazon EC2 instance needs to resolve a DNS query to the domain
internal.example.com. The authoritative DNS server is in the on-premises
data center. This DNS query is sent to the VPC+2 in the VPC that connects
to Route 53 Resolver.
2.A Route 53 Resolver forwarding rule is configured to forward queries to
internal.example.com in the on-premises data center.
3.The query is forwarded to an outbound endpoint.</p>
<pre><code>                 Outbound Endpoint W orkflow - 2 
</code></pre>
<ol start="4">
<li>The outbound endpoint forwards the query to the on-premises DNS resolver
through a private connection between AWS and the data center. The connection
can be either AWS Direct Connect or AWS Site-to-Site VPN, depicted as a
virtual private gateway.</li>
<li>The on-premises DNS resolver resolves the DNS query for
internal.example.com and returns the answer to the Amazon EC2 instance via
the same path in reverse.</li>
</ol>
<p>CNAME vs ALIAS
Understand the Use-Case
knowledge portal                                         CNAME Records
CNAME records are used for pointing a domain name to another hostname.
In below diagram, example.internal has CNAME to .in
When we resolve example.internal, the response will be 192.168.0.5
example.internal            .in
192.168.0.5 CNAME
knowledge portal                          Challenge with CNAME Record
There is one important drawback of CNAME Record.
It cannot be used with the ROOT domain.
example.com CNAME acme.com &laquo; CANNOT WORK
example.com CNAME
myelb.us-east-1.amazonaws.com
knowledge portal                                          Use ALIAS Record
If we want ROOT domain to point to ELB, S3 Bucket, CloudFront distribution, it will not work
with CNAME Records.
T o resolve this drawback of CNAME record, we make use of ALIAS record which allows us to even
point ROOT domain to DNS of A WS Services.
example.com ALIAS
myelb.us-east-1.amazonaws.com
Cross Account Association of PHZ</p>
<pre><code>                    Understanding the Challenge 
</code></pre>
<p>By default, Route53 only provides option to associate Private hosted zone with
the VPCs as part of the same account.</p>
<pre><code>                 Cross Account Architecture 
</code></pre>
<p>Route53 also supports functionality related to associating Private Hosted Zone
to the VPC that belongs to other AWS Account.
Private Hosted Zone VPC
AWS Account A AWS Account B Association
Practical
1.Use create-vpc-association-authorization to authorize  the association
between the private hosted zone in Account A and the VPC in Account B.
2.Use associate-vpc-with-hosted-zone to associate  an Amazon VPC with a
private hosted zone.
Step 1 - Find The Hosted Zone ID</p>
<pre><code>        Step 2 - Create VPC Association Authorization 
</code></pre>
<p>Run this command in AWS account were the Private Hosted Zone is created.
Replace Hosted Zone ID, VPC Region and VPC ID.</p>
<pre><code>        Step 3 - Associate VPC with Hosted Zone 
</code></pre>
<p>Run this command in External AWS Account that hosts the VPC.</p>
<p>Elastic Container Registry (ECR)
Storing Container Images
Understanding with Analogy
knowledge portal Google Play is an online store where people go to find their favorite apps, games, movies,
TV shows, books, and mor
Android
Android
Importance of Container Registry
knowledge portal Container Registry is a single place for your team to manage Docker images.
Whenever you launch a Docker Container, the associated image is pulled from Registry .</p>
<p>Basics of ECR
knowledge portal Amazon ECR is a fully managed container registry for storing Docker Images.
Docker Image 1
Docker Image 2
docker pull
ECR
Container Orchestration in A WS
Choosing Right Orchestrator
Container Orchestration in A WS
There are two primary services that are extensively used for container orchestration use-cases.</p>
<pre><code> Container Orchestration 
</code></pre>
<p>Elastic Container Service Elastic Kubernetes Service
knowledge portal
Important Difference
knowledge portal Pointers AWS EKS AWS ECS
Open-Source Yes No
Complexity More Complex Less Complex
Community Support More Less
Choosing Right Orchestrator
If you plan  to work exclusively on A WS, you should choose ECS as it offers more in-depth A WS
integration than Amazon EKS.
Organizations with limited expertise and insufficient resources to invest in learning Kubernetes
can go with ECS.
If you plan to deploy containers across multiple platforms, you can choose EKS.</p>
<p>knowledge portal
Elastic Container Service (ECS)
Container Management
Basics of Service
knowledge portal Amazon Elastic Container Service  (Amazon ECS) is a highly scalable and fast container
management service.
Y ou can use it to run, stop, and manage containers on a cluster.
ECR
ECSContainer 1
Container 2
High-Level W orkflow
knowledge portal  ECS agent
Container 1
Container 2
ECS
IAM Server
Components of ECS
Container Management
Basic Components
knowledge portal There are three primary components of ECS Cluster:
T ask Definition, T asks and Service
ECSTask Definition
Tasks
Services
Component - T ask Definition
knowledge portal A task definition is a text file that describes one or more containers that form your
application.
It contains information like operating system, containers to use, ports to open, storage</p>
<p>Component - T ask
knowledge portal A task is the instantiation of a task definition within a cluster.
After you create a task definition for your application within Amazon ECS, you can
specify the number of tasks to run on your cluster.
Task Definition     task-1
task-2
Component - Service
knowledge portal Service to run and maintain your desired number of tasks simultaneously in an Amazon
ECS cluster.
If any of your tasks fail or stop for any reason, the Amazon ECS service scheduler launches
another instance based on your task definition
Task Definition     task-1    task-2
Service Description
Service     task-3    task-4
ECS Networking
Container Management
Let’s Network
knowledge portal There are 3 primary networking mode that you can use in ECS
Network Mode Description
Host Mode The networking of the container is tied directly to the underlying host
that&rsquo;s running the container.
Bridge Mode The bridge network mode allows you to use a virtual network bridge to
create a layer between the host and the networking of the container.
AWS VPC Mode With the awsvpc network mode, Amazon ECS creates and manages an
Elastic Network Interface (ENI) for each task and each task receives its
own private IP address within the VPC.
Host Mode (Not Recommended)
knowledge portal The networking of the container is tied directly to the underlying host that&rsquo;s running the
container.
T o connect to container: HOST IP + Port</p>
<p>Bridge Mode
knowledge portal With bridge mode, you&rsquo;re using a virtual network bridge to create a layer between the host
and the networking of the container.</p>
<p>A WS VPC Mode
knowledge portal Amazon ECS creates and manages an Elastic Network Interface (ENI) for each task and
each task receives its own private IP address within the VPC.
This ENI is separate from the underlying hosts ENI.</p>
<pre><code>                        Introduction to Kubernetes 
                               Setting the Base 
</code></pre>
<p>Kubernetes (K8s) is an open-source container orchestration engine  developed
by Google.
It was originally designed by Google, and is now maintained by the Cloud Native
Computing Foundation.</p>
<pre><code>                        Architecture of Kubernetes 
</code></pre>
<p>A Kubernetes cluster consists of a control plane  + a set of worker machines,
called nodes, that run containerized applications
Control Plane Node 1
Node 2
Node 3
Basic W orkflow
User communicates to Control Plane and provides necessary instructions to run
containerized applications.
Control Plane Node 1
Node 2
Requirements
Run 2 containers of Nginx
Run app in the largest server Submit Requirements
Example - Run 1 Container of Apache
If you have instructed Kubernetes to run 1 container  of Apache, Kubernetes will
launch it in one of the worker nodes and will  regularly monitor the state of that
container to ensure it always runs.
Control Plane Node 1
Node 2
Requirements
Run 1 container of Apache Submit Requirement
Kubernetes is A wesome
Kubernetes provides amazing set of features and is designed on the same
principles that allow Google to run billions of containers  a week.
Some of the popular features include:
●Pod Auto-Scaling
●Service discovery and load balancing
●Self-Healing of Containers
●Secret management
●Automated rollouts and rollbacks</p>
<p>Elastic Kubernetes Service
Managed Kubernetes in A WS
Operating Kubernetes is Hard
Building and Maintaining entire Kubernetes cluster takes lot of time and resources.
knowledge portal
Understanding the Basics
Amazon Elastic Kubernetes Service (Amazon EKS) is a managed service that you can use to run
Kubernetes on A WS.</p>
<p>knowledge portal
EKS
Benefits of EKS
EKS provides tight integration with various other A WS services like ECR, IAM, ELB to provide
end to end features for application deployments.</p>
<p>knowledge portal
EKS
ECR
IAM
ELB
EKS Practical Steps
Let’s Create EKS Cluster
Approaches to Create EKS Cluster
There are two primary ways to create EKS Cluster
knowledge portal
EKS     eksctl
AWS Console / CLI
Step 1 - Build EKS Cluster
In this step, we build the base EKS Cluster.
Appropriate IAM Role needs to be associated so EKS can manage resource on your behalf.</p>
<p>knowledge portal
EKSIAM
KMS
EC2
ELB
Important Configuration - Building Cluster
knowledge portal Configs Description
Kubernetes Version Sets the K8s Version for your cluster.
Cluster Service Role Allows EKS to manage resources.
VPC VPC for cluster resources.
Cluster Endpoint Access Public / Private Access to EKS Cluster.
Networking Add-Ons To Configure appropriate networking in cluster.
Logging Enable Logging for K8s Components.
Step 2 - Create Node Group
A node group is a group of EC2 instances that supply compute capacity to your Amazon EKS
cluster.
Configuration: AMI ID, Instance T ype, Auto-Scaling Configuration, Disk Size.</p>
<h2 id="challenges-and-structure">EKS
m5.large
t2.micro
c4.xlarge
Node Group
IAM Role for NodeGroup
An IAM Role needs to be associated with NodeGroup to ensure EC2 instance can perform
following operations:
Fetch Images from ECR,  Manage Network Interfaces,  and others.  <br>
Node Group
IAM
knowledge portal
A WS Fargate
Serverless Compute
Basic Approach
In traditional approach, there is a need to create set of EC2 instances where containers can run.
Challenges:   Define and Deploy EC2, Security of EC2, Manage EC2
Container Orchestrator
Container 1
Container 2
knowledge portal
Serverless Approach
In the serverless approach, we do not have to worry about provisioning and managing EC2
A WS Fargate  is a serverless, pay-as-you-go compute engine that lets you focus on building
applications without managing servers
Container Orchestrator
knowledge portal
AWS Fargate
Migration Strategies
Challenges and Structure</h2>
<p>Migration Strategy Description Use-Case / Example
Re-Host Referred to as a “lift and shift.
Move application without any changes. MySQL to EC2 MySQL
Re-Platform Referred to as “lift, tinker, and shift.”
Make a few cloud optimizations to achieve
a tangible benefit. Move on-premise MySQL to RDS.
Re-Factor/Re-Architect Re-imagine how the application is
architected and developed using
cloud-native features. Migrating to serverless.
Re-Purchase Move from perpetual licenses to a
software-as-a-service model. Nessus to AWS Inspector
Retire Remove applications which are no longer
needed. On-Premise FTP server
Retain Keep applications that are critical for the
business but that require major refactoring
before they can be migrated. Old good servers still running.
Migration - T ools and Services
knowledge portal Migration is not always related to servers.
Organizations might still continue to use on-premise and might want to migrate data from old
magnetic tapes.
A WS services that helps in migrations:
● A WS Snowball
● Server Migration Service
● Database Migration Service
● Application Discovery Service
● A WS Snowmobile</p>
<p>1 051              AWS Snowball Family</p>
<pre><code>                   Understanding with Use-Case 
</code></pre>
<p>Organization A has hosted all of it’s storage infrastructure in data-center.
Total Storage: 500 TB.
They have now decided to use S3 due to the benefits that it provides.
Bandwidth Transfer Time
100 Mbps 510 days.
500 Mbps 101 days
1 Gbps 50 days
A WS Snowball Family
Allows customers to Accelerate moving offline data or remote storage to the
cloud
AWS Team       Customer Send Storage Device
Ship Back Device AWS Internal Network</p>
<pre><code>                  How the Storage Devices Look 
</code></pre>
<p>Snowball Edge
Snowmobile
Edge Computing Functionality
These devices can also come with edge computing capabilities.
This means, you can run your applications in EC2 instances in the devices so
that you can work in edge environments with limited connectivity.
Process data locally (Image/ Video Processing, Machine Learning etc)</p>
<pre><code>                                        Snowcone 
</code></pre>
<p>AWS Snowcone is a small, rugged, and secure device offering edge computing,
data storage, and data transfer on-the-go, in severe environment with little or no
connectivity.
Can carry in backpack, drones and others.
8 TB of usable storage</p>
<pre><code>                                   Snowball Edge 
</code></pre>
<p>AWS Snowball Edge is a type of Snowball device with on-board storage and
compute power for select AWS capabilities
Available in Multiple Storage Capacity like 100 TB, 40 TB and others.</p>
<pre><code>                                   Snowball Edge 
</code></pre>
<p>Device Description
Snowball Edge Storage Optimized (for data
transfer) This option has a 100 TB (80 TB usable) storage capacity.
Snowball Edge Storage Optimized (with
EC2 compute functionality) This option has up to 80 TB of usable storage space, 24
vCPUs, and 80 GB of memory for compute functionality
Snowball Edge Compute Optimized Most compute functionality, with 104 vCPUs, 416 GB of
memory, and 28 TB of dedicated NVMe SSD for compute
instances.
Snowball Edge Compute Optimized with
GPU Identical to the Compute Optimized option, except for an
installed GPU
A WS Snowmobile
AWS Snowmobile moves extremely large amounts of data to AWS.
Transfer up to 100 PB per Snowmobile, a 45-foot-long ruggedized shipping
container pulled by a semi-trailer truck.</p>
<pre><code>                                 A WS OpsHub 
</code></pre>
<p>AWS OpsHub is a graphical user interface you can use to manage your AWS
Snowball devices.</p>
<p>VMW are Migrations
Virtualization &amp; Cloud
Many organizations are migrating
knowledge portal ● Many organizations are migrating from their on-premise environments to EC2.
● VMW are was one of the most used solutions for virtualization and private clouds.</p>
<p>Migrate VM to EC2
knowledge portal</p>
<p>Choose the appropriate A WS region &amp; Subnets
knowledge portal</p>
<p>Migration Completed
knowledge portal</p>
<p>Important Pointer
knowledge portal A WS Management Portal for vCenter allows customer to manage the A WS resources from
their VMW are vCenter dashboard itself.</p>
<h2 id="supportd-platforms-vsphere-and-hyper--v">A WS SMS
Server Migration Service
Getting Started
knowledge portal A WS Server Migration Service (SMS) is an agentless service which makes it easier and faster
for you to migrate thousands of on-premises workloads to A WS.
Supportd Platforms: vSphere and Hyper- V</h2>
<p>Application Discovery Service
Overview Video
Overview of A WS Application Discovery Service
knowledge portal
A WS Application Discovery Service helps enterprise customers plan migration projects by
gathering information about their on-premises data centers.
For enterprises which has hundreds to thousands of servers on-premise, getting to know
network dependency , right instance types for them can be challenging.</p>
<p>Important Pointers
knowledge portal
It supports both agentless discovery and agent-based discovery
● Agentless service needs installation of the discovery connector in VMware vCenter .
● Agent-based service requires agent to be installed in OS.</p>
<pre><code>                       Database Migration Service 

                       Understanding the Basics 
</code></pre>
<p>AWS Database Migration Service (AWS DMS) is a cloud service that makes it
possible to migrate  relational databases, data warehouses, NoSQL databases,
and other types of data stores.
You can use AWS DMS to migrate your data into the AWS Cloud or between
combinations of cloud and on-premises setups.</p>
<pre><code>                        High-Level W orkflow 
</code></pre>
<p>At a basic level, AWS DMS is a server in the AWS Cloud that runs replication
software.
You create a source and target connection to tell AWS DMS where to extract
from and load to
DMS Server
RDS On-Premise DB
AWS Schema Conversion</p>
<pre><code>           Challenges with Database Migration 
</code></pre>
<p>Database Migration is not just about taking backup  of source database and
upload it to destination.
In many of the use-cases, the overall schema also needs to be changed.
Source DB Destination DB
Understanding the Basics
You can use the AWS Schema Conversion Tool  (AWS SCT) to convert your
existing database schemas from one database engine to another
Destination DB
AWS SCT
Supported OL TP Conversions - SCT
AWS SCT supports the following OLTP conversions.</p>
<pre><code>                       Schema Conversion T ools 
</code></pre>
<p>AWS offers two schema conversion solutions to make heterogeneous database
migrations predictable, fast, secure, and simple.
1.DMS Schema Conversion - Fully Managed Experience
2.AWS Schema Conversion Tool (AWS SCT) software.</p>
<pre><code>                                Point to Note 
</code></pre>
<p>DMS Schema Conversion is a web-version of the AWS Schema Conversion
Tool (AWS SCT).
DMS Schema Conversion provides more limited functionality compared to the
AWS SCT desktop application.</p>
<pre><code>                           Primary Use-Cases 
</code></pre>
<p>AWS DMS traditionally moves smaller relational workloads (&lt;10 TB), whereas
AWS SCT is primarily used to migrate large data warehouse workloads.
AWS DMS supports ongoing replication to keep the target in sync with the
source; AWS SCT does not.
SCT can also run in offline mode.</p>
<pre><code>                       Migration Types in DMS 

                        Understanding the Basics 
</code></pre>
<p>When you are migrating the data from source to destination, DMS provides
multiple set of options for migrations.
One Time Migration, Continue replicating data changes etc
DMS Server
RDS On-Premise DB Load Full Data
3 Primary Options
Migration Type Description
Migrate existing data perform a one-time migration from the source endpoint to the target
endpoint.
Migrate existing data and
replicate ongoing changes perform a one-time migration from the source to the target, and then
continue replicating data changes from the source to the target.
Replicate data changes only don&rsquo;t perform a one-time migration, but continue to replicate data
changes from the source to the target.
Points to Note
Most engines require some additional configuration to make it possible for the
capture process to consume the change data in a meaningful way, without data
loss.
For example, Oracle requires the addition of supplemental logging, and MySQL
requires row-level binary logging  (bin logging).</p>
<pre><code>                              Points to Note 
</code></pre>
<p>You can also create a task that captures ongoing changes after you complete
your initial (full-load) migration to a supported target data store.
This process is called ongoing replication or change data capture ( CDC ).</p>
<pre><code>                   A WS Outposts 
</code></pre>
<p>A WS in On-Premise
Cloud is Servers Behind the Scenes
Cloud is basically set of Servers behind the scenes.
These servers reside in the A WS Datacenter.
Everything from Power, Cooling, Internet Connectivity , Physical Security is managed by A WS.
knowledge portal
Challenge 1: Latency
AWS DC
Possible Solution 1 - On-Premise Servers
AWS DC
Challenges with Hybrid Architecture
knowledge portal</p>
<ol>
<li>Different set of API’s to manage servers and services.</li>
<li>Automation is difficult.</li>
<li>Additional learning required.</li>
</ol>
<p>A WS Outposts
knowledge portal A WS Outposts is a fully managed service that offers the same A WS infrastructure, A WS
services, APIs, and tools to virtually any datacenter, co-location space, or on-premises
facility .
AWS Side Customer Side</p>
<p>Services that you can Run
knowledge portal With A WS Outposts, we can run wide variety of A WS services locally .
Some of these include:
● Amazon EC2
● Amazon EBS
● S3
● RDS
● EKS
● EMR</p>
<p>Installation Step
knowledge portal</p>
<p>Use-Case for A WS Outposts
knowledge portal A WS Outposts can be used for wide-variety of use-cases.
Some of these include:
● Low-Latency Requirements
● Data Residency
● Local Data Processing</p>
<pre><code>                                   AWS DataSync 

                     Understanding the Basics 
</code></pre>
<p>AWS DataSync is an online data transfer service  that simplifies, automates, and
accelerates moving data between storage systems and services.
DataSync provides end-to-end security, including encryption and integrity
validation, to help ensure that your data arrives securely, intact, and ready to
use.
Location 1      Location 2 Move Files
Supported Endpoints
DataSync can copy data to and from:
●Network File System (NFS) file servers
●Server Message Block (SMB) file servers
●Hadoop Distributed File System (HDFS)
●Object storage systems
●Amazon Simple Storage Service (Amazon S3) buckets
●Amazon EFS file systems
●Amazon FSx for Windows File Server file systems
●Amazon FSx for Lustre file systems
●Amazon FSx for OpenZFS file systems
●Amazon FSx for NetApp ONTAP file systems
●AWS Snowcone devices
●Google Cloud Storage buckets
●Azure Files</p>
<pre><code>  T ransferring between on-premises storage and A WS 

      T ransferring between A WS storage services 
</code></pre>
<p>T ransferring data from Google Cloud Storage to Amazon S3
1.You deploy a DataSync agent in your Google Cloud environment.
2.The agent reads your Google Cloud Storage bucket
3.Objects from your Google Cloud Storage bucket move securely through TLS 1.2 into
the AWS Cloud by using a public endpoint.
4.The DataSync service writes the data to your S3 bucket.
AWS Compute Optimizer</p>
<pre><code>                     Understanding the Challenge 
</code></pre>
<p>In most of the organizations, over provisioning is a big challenge.
This leads to large cost at the end of the month.</p>
<pre><code>                    A WS Compute Optimizer 
</code></pre>
<p>AWS Compute Optimizer recommends optimal AWS resources  for your
workloads to reduce costs and improve performance by using machine learning
to analyze historical utilization metrics</p>
<pre><code>                       Recommendations 
</code></pre>
<p>AWS Computer Optimizer also provides the recommendations related to the
optimal instance types.</p>
<pre><code>                       Supported Resource T ypes 
</code></pre>
<p>AWS Compute Optimizer delivers recommendations for selected types of:
●EC2 instances,
●EC2 Auto Scaling groups
●EBS volumes
●Amazon ECS services on AWS Fargate
●Lambda functions.</p>
<pre><code>                              Points to Note 
</code></pre>
<p>AWS Compute Optimizer uses Amazon CloudWatch metrics  as basis for the
recommendations.
By default, CloudWatch metrics are the ones it can observe from an hypervisor
point of view, such as CPU utilization, disk IO, and network IO.
If you want AWS Compute Optimizer to take into account operating system level
metrics, such as memory usage, you need to install a CloudWatch agent on your
EC2 instance</p>
<pre><code>             Enhanced Infrastructure Metrics 
</code></pre>
<p>Enhanced infrastructure metrics is a paid feature  of Compute Optimizer that
applies to Amazon EC2 instances.
Extends the utilization metrics analysis look-back period to up to three months
(93 days), compared to the 14-day (2-week) period.  This gives Compute
Optimizer a longer history of utilization metrics data to analyze.</p>
<pre><code>                Export Recommendations 
</code></pre>
<p>You can export your recommendations to record them over time, and share the
data with others.
Recommendations are exported in a CSV file, and its metadata in a JSON file,
to an existing Amazon Simple Storage Service (Amazon S3) bucket that you
specify.</p>
<p>T rusted Advisor
Recommendations are always good
What is T rusted Advisor ?
knowledge portal
A WS T rusted Advisor analyzes your A WS environment and provides best practice
recommendations in five major categories:</p>
<p>T rusted Advisor Check Categories
knowledge portal Categories Description
Cost optimization Recommendations that can potentially save you money.
Performance Recommendations that can improve the speed and responsiveness of your
applications.
Security Recommendations for security settings that can make your AWS solution more
secure.
Fault tolerance Recommendations that help increase the resiliency of your AWS solution.
Service limits Checks the usage for your account and whether your account approaches or
exceeds the limit for AWS services and resources.
AWS Tags
Understanding the Challenge
Let us assume that we have 10 keys for different set of locks.
Challenge:  It becomes difficult to identify which key is for what purpose.</p>
<pre><code>                Good Solution - T ag the Key 
</code></pre>
<p>In this approach, we tag a key with a small paper note providing description and
it’s usage.
Tag: a label attached to someone or something for the purpose of identification</p>
<pre><code>           Challenge in A WS to Identify Resource 
</code></pre>
<p>An organization can be running hundreds of servers in AWS.
On the longer run, it becomes difficult to identify the purpose of each resource.
us-east-1
Reference - EC2 Instance without T ags</p>
<pre><code>                          Solution - A WS T ags 
</code></pre>
<p>A tag is a label that you assign to an AWS resource.
It allows in easy identification and to understand its purpose.
us-east-1 email-server app-server db-server
Reference - EC2 Instance with T ags</p>
<pre><code>                        T ag Structure in A WS 
</code></pre>
<p>Each tag consists of a key and an optional value, both of which you define.
env: production   env: development</p>
<p>Resource Groups
Organizing Resources Centrally
Overview of Resource Groups
knowledge portal A WS Management console is organized based on services.
With resource groups, customers can organize groups of resources under a central console.
Resource Group - SecurityTeam
EC2 RDS ELB
EBS</p>
<p>Resource Groups for Automation
W e can automate many tasks based on resource groups.
Example Automation T asks:
● Restart EC2 Instances
● Attach IAM to EC2 Instances
● Create AMI of Instances
● Perform Patching Activities
Resource Group - EC2-Automation
EC2-1
EC2-2 EC2-3 EC2-4
Tagging Strategies
1 - T ags for Resource Organization
Using Resource Groups and Tag Editor, you can consolidate and view data for
applications that consist of multiple services, resources, and Regions in one
place.
Resource Group - SecurityTeam EC2 RDS ELB
EBS</p>
<pre><code>                     2 - T ags for cost allocation 
</code></pre>
<p>AWS Cost Explorer and detailed billing reports let you break down AWS costs by
tag.</p>
<pre><code>                     3 - T ags for automation 
</code></pre>
<p>Resource or service-specific tags are often used to filter resources during
automation activities.
Example:
Stop ALL EC2 instances with Tags of “Test” at 10 PM and Start at 10 AM</p>
<pre><code>                     4 - T ags for access control 
</code></pre>
<p>IAM policies support tag-based conditions, letting you constrain IAM permissions
based on specific tags or tag values.
Example:
Allow Developer to start and stop EC2 instance having tags of “env: developer”</p>
<pre><code>                        Tagging - Best Practices 
               Important Best Practices - Part 1 
</code></pre>
<p>1.Do not add personally identifiable information (PII) or other confidential or
sensitive information in tags. Tags are accessible to many AWS services,
including billing.
2.Tag keys and values are case sensitive. As a best practice, decide on a
strategy for capitalizing tags, and consistently implement that strategy
across all resource types.
For example , decide whether to use Costcenter, costcenter, or CostCenter,
and use the same convention for all tags</p>
<pre><code>               Important Best Practices - Part 2 
</code></pre>
<ol start="3">
<li>
<p>Use too many tags rather than too few tags.</p>
</li>
<li>
<p>Changing/Modifying Tags can have consequences. For example, other
dependent resources like automation scripts, IAM Policies can break.</p>
<pre><code>                    A WS T ags 
 Meta-Data to A WS Resources 
</code></pre>
</li>
</ol>
<p>Understanding the Basics
knowledge portal A tag is a label that you assign to an A WS resource.<br>
Each tag consists of a key and an optional value, both of which you define.
Let’s understand this with a simple use-case:
There are three EC2 instances running. How will you identify them?
email-server     payment-app     compliance-system
Architecture Perspective
knowledge portal A resource can have multiple tags assigned to it.</p>
<p>Important Restrictions
knowledge portal
A WS has hundreds of services. Not all of them support tagging.
Maximum number of tags per resource – 50
T ag keys and values are case-sensitive.
.</p>
<p>Important Use-Cases for T ags - Billing
knowledge portal
T ags can be integrated in Billing and that allows customers to understand their A WS bill in a
granular way .</p>
<p>Important Use-Cases for T ags - IAM
knowledge portal
T ags can be used with IAM to control the access to resources.
Example Use-case:
Allow Alice to only delete resources which has a tag of env as development.
env: production   env: development
Follow the T agging Strategy
knowledge portal
It is important to have a consistent and effective tagging strategy .
Example
Alice creates a resource with the tag of key of env and value of production
Matthew creates a resource with the tag of Env and value of Production
Follow the A WS T agging Strategies document.</p>
<p>EC2 Pricing
The backbone of internet
T ypes of Instances
knowledge portal
There are 4 ways to pay for an EC2 instance :</p>
<ul>
<li>On-demand instance</li>
<li>Reserved instance</li>
<li>Spot instances</li>
<li>Dedicated hosts</li>
</ul>
<p>On-Demand instance
knowledge portal With On-demand instances, we pay for compute capacity per hour or per second
depending on the instances which is being run.
No upfronts payments are needed and we can increase or decrease the capacity whenever it
is needed.</p>
<p>Challenges with On-Demand
knowledge portal Monday :       500 customers using 16GB RAM on-demand servers individually .
W ednesday :   10 customers using  16GB RAM on-demand servers individually .
A “Cloud Service Provider” will not have a clear picture on how many servers should the
provision. T oo high → resources might unused and too low → money loss</p>
<p>Reserved Instance
knowledge portal Reserved Instance provides us with significant discount (upto 75%) compared to
on-demand instance pricing.
Reserved instance are assigned to a specific availability zone and provides capacity
reservation for A WS EC2 instances.
Example :
Y ou know you will always be running 20 servers of m4.2xlarge type, then buy reserved
instances  for them.</p>
<p>Reserved Instance - Part 2
knowledge portal Pricing Option Monthly Cost  Total 3 year cost
On-Demand Instance $0.096 $20,484
3 year all up-front - Reserved - $7589
Savings ~37% Example: m5.4xlarge instance type</p>
<p>Spot Instance
knowledge portal Spot instances  allows us to bind on spare Amazon EC2 computing capacity for up to 90%
of the on-demand cost.
Such instances are recommended for applications which can have flexible start and end
times</p>
<p>Dedicated Host
knowledge portal A dedicated host is a physical EC2 server dedicated for your use.
It can be purchased on-demand as well as reserved instance.</p>
<p>Reserved Instances
Money Optimization
T ypes of Reserved Instances
knowledge portal Type of RIs Description
Standard RIs
These provide the most significant discount (up to 72% off On-Demand) and
are best suited for steady-state usage.
Convertible RIs
These provide a discount (up to 54% off On-Demand) and the capability to
change the attributes of the RI
Scheduled RIs These are available to launch within the time windows you reserve.</p>
<p>RI T ypes
knowledge portal With convertible RI, we can :
● Convert to  new instance family  eg R3 to M4 to C4 to T2
● Convert to new operating system eg Windows to Linux
● Convert to new instance price [ eg if A WS reduces the public rate for our instance ]
● Convert to new instance size    [ eg :  from m4.xlarge to m4.2xlarge ]
● Convert tenancy [ eg dedicated instance to default ]
● Convert to different payment option [ no upfront to partial upfront ]
Reservation T erm
knowledge portal</p>
<p>Reservation Term Description
No Upfront No upfront required. Lower discount rate compared to others.
Partial Upfront You make a low upfront payment and are then charged a discounted hourly
rate for the instance for the duration of the Reserved Instance term.
All Upfront You pay for the entire Reserved Instance term with one upfront payment.
Provides the largest discount.</p>
<p>Regional vs Zonal RIs
knowledge portal</p>
<p>Regional RI Zonal RI
Ability to Reserve
Capacity No Reservation in Capacity. Capacity Reserved in the specific
Availability Zone.
Availability Zone
Flexibility The Reserved Instance
discount applies to instance
usage in any Availability Zone
in the specified Region. Reserved Instance discount applies to
instance usage in the specified Availability
Zone only.
Instance size
flexibility The Reserved Instance
discount applies to instance
usage within the instance
family, regardless of size. No instance size flexibility—the Reserved
Instance discount applies to instance
usage for the specified instance type and
size only.
Scenario
knowledge portal Scenario 1 :<br>
Customer has following instances running:
●       2 x m4.large instance running in us-east-1a and us-east-1b region.
●       2 x t2.large instance running across us-east-1b and us-east-1c region
Customer has following RI:
●          2 x m4.large, default tenancy ,  us-east-1b region (zonal RI)
●          2 x t2.large,    default tenancy ,  us-east-1 regional RI
Additional pay :   1 x m4.large instance will be charged at the on-demand rate.</p>
<p>On-Demand Capacity Reservations
Reserving EC2 Capacity
Understanding the Challenge
knowledge portal
With On-Demand Instance, there are chances that new instance might not launch due to
insufficient capacity error.
T ypical Solution → Go with Reserved Instances (1 year, 3 year term)</p>
<p>Benefits of On-Demand Capacity Reservation
knowledge portal
On-Demand Capacity Reservations enable you to reserve compute capacity for your
Amazon EC2 instances in a specific A vailability Zone for any duration
Y ou can create Capacity Reservations at any time, without entering into a one-year or
three-year term commitment, and the capacity is available immediately .</p>
<p>On-Demand Capacity Reservation with RI
knowledge portal On-Demand Capacity Reservation Regional RI
Term No commitment required. Can be created
and canceled as needed. Requires a fixed one-year
or three-year commitment
Capacity
benefit Capacity reserved in a specific
Availability Zone. No capacity reserved.
Billing
discount No billing discount. Provides a billing discount. You can combine Capacity Reservations with Regional Reserved Instances to receive a discount.
Pricing
knowledge portal
When the Capacity Reservation enters the active state, you are charged the equivalent
On-Demand rate whether you run instances in the reserved capacity or not.
If you do not use the reservation, this shows up as unused reservation on your EC2 bill.
For example, if you create a Capacity Reservation for 20 m4.large Linux instances and run 15
m4.large Linux instances in the same A vailability Zone, you will be charged for 15 active
instances and for 5 unused instances in the reservation.</p>
<pre><code>                    EC2 Fleet 
</code></pre>
<p>Launching EC2 based on Requirements
Original Feature
knowledge portal
EC2 Fleet allows users to launch a fleet of Spot Instances that spans EC2 instance types and
A vailability Zones without having to write custom code to discover capacity or monitor
prices.
Very Big Data To Analyze
4 vCPU 4 vCPU 4 vCPU 4 vCPU
Understanding With A Use-Case
knowledge portal
Let us assume, to perform the analysis, you require in total of 16 vCPU.
vCPU = 16 Instances Types for 16 vCPU
1 x c5.4xlarge
2 x c5.2xlarge
4 x c5.xlarge
Setting W eight
knowledge portal
Y ou can assign a set of weighted capacity to a set of EC2 instance T ypes.
Instances Types for 16 vCPU
1 x c5.4xlarge
2 x c5.2xlarge
4 x c5.xlarge Instance Type Weight
c5.4xlarge 16
c5.2xlarge 8
c5.xlarge 4
Setting W eight
knowledge portal
Target Capacity = 16
Setting T arget Capacity
knowledge portal
EC2 Fleet will select the most cost effective combination of instance types and A vailability
Zones (both specified in the template) using the current prices for the Spot Instances and
public prices for the On-Demand Instances
Spot Instances                  c5.4xlarge
c5.2xlarge    c5.2xlarge
c5.xlarge c5.xlarge c5.xlarge c5.xlarge
Overview of EC2 Fleet - New
knowledge portal
The EC2 Fleet attempts to launch the number of instances that are required to meet the
target capacity that you specify in the fleet request.
The fleet can comprise only On-Demand Instances, only Spot Instances, or a combination of
both On-Demand Instances and Spot Instances.</p>
<p>Interpret the Requirements
knowledge portal
I want total of 16 vCPUs.
8 vCPU should be fulfilled using On-Demand instance type.
8 vCPU should be fulfilled using Spot instance type.</p>
<p>Allocation Strategy for Spot Instances
Optimizing Costs
Understanding Spot Instance Pool
knowledge portal
A Spot instance pool is a set of unused EC2 instances with the same instance type and size
(for example, m5.large), availability zone (AZ), in the same region
Spot Instance Pool for m5.large</p>
<p>Allocation Strategy
knowledge portal
Depending on your requirements and use-case, there are three primary allocation strategy for
Spot instances.
Allocation Strategy Description
lowest-price The Spot Instances come from the Spot capacity pool with the
lowest price. This is the default strategy.
diversified The Spot Instances are distributed across all Spot capacity pools.
capacity-optimized Provisions Spot Instances from the most-available Spot Instance
pools by analyzing capacity metrics.
Preference - lowest-price
knowledge portal
Choose the lowest-price allocation strategy if:
If your fleet is small or runs for a short time, the probability that your Spot Instances will be
interrupted is low , even with all of the instances in a single Spot capacity pool.
Therefore, the lowest-price strategy is likely to meet your needs while providing the lowest
cost.
Since the price constantly changes, the existing instances in ASG can be terminated and be
replaced by new , cheaper once thus potentially disrupting your service at a higher rate.</p>
<p>Preference - diversified
knowledge portal
If your fleet is large or runs for a long time, you can improve the availability of your fleet by
distributing the Spot Instances across multiple pools using the diversified strategy .
For example, if your EC2 Fleet specifies 10 pools and a target capacity of 100 instances, the
fleet launches 10 Spot Instances in each pool.
If the Spot price for one pool exceeds your maximum price for this pool, only 10% of your
fleet is affected.</p>
<p>Preference - capacity-optimized
knowledge portal
If your fleet runs workloads that may have a higher cost of interruption associated with
restarting work and checkpointing, then use the capacity-optimized strategy
This strategy does not look at the prices of the instance types in each pool configure but
instead looks for the optimal capacity volume and chooses those instances to run your service
on.
While the overall hourly cost of capacity-optimized allocation strategy might be slightly
higher, the possibility of having fewer interruptions can lower the overall cost of your
workload.</p>
<p>EC2 T enancy
Understanding the EC2 T enancy
knowledge portal Every EC2 instance that we launch in the VPC has a specific tenancy attribute associated with
it. There are three tenancy attributes which are available:</p>
<p>Shared T enancy
knowledge portal
In this approach, your EC2 instance is launched on the shared hardware where EC2 instances
of other customers also run.</p>
<p>Dedicated Instance
knowledge portal
Dedicated Instances are EC2 instances that run on the hardware which is dedicated to a single
customer.
Dedicated instances may share the hardware with other EC2 instances that belongs to the same
A WS accounts.</p>
<p>Dedicated Hosts
knowledge portal
Dedicated Host is a physical server that allows us to use our existing per-socket, per-core or even
per- VM based software licenses which includes Windows Server, SUSE, and various others.
With dedicated hosts, we can use the same physical server over the time, even if the instance is
stopped and started.
Turning Oﬀ RI Sharing</p>
<pre><code>                    Understanding the Basics 
</code></pre>
<p>The management account of an organization can turn off Reserved Instance (RI)
discount and Savings Plans discount sharing for any accounts in that
organization, including the management account.
This means that RIs and Savings Plans discounts aren&rsquo;t shared between any
accounts that have sharing turned off</p>
<p>1179                  EBS Volume Types</p>
<pre><code>                Performance Metrics in Storage Device 
</code></pre>
<p>Storage Device is a piece of equipment on which information can be stored
Common disk performance metrics are :
●Input / Output operations per second ( IOPS )
●Throughput ( MB/s or MiB/s )</p>
<pre><code>                         Basic Metrics Information 
</code></pre>
<p>IOPS is a count of the read/write operations per second
Throughput is the actual measurement of read/write bits per second that are
transferred over a network</p>
<pre><code>                              EBS V olume T ypes 
</code></pre>
<p>EBS provides different volume types which differs in performance and price.
Hard Disk Drives Solid State Drive
Solid State Drives (SSD)
Optimized for transactional workloads involving frequent read/write operations
with small I/O size, where the dominant performance attribute is IOPS.
SSD-backed volume types include:
General Purpose SSD
Provisioned IOPS SSD
Hard Disk Drives (HDD)
Optimized for large streaming workloads where the dominant performance
attribute is throughput.
HDD-backed volume types include:
Throughput Optimized HDD
Cold HDD Volumes</p>
<pre><code>                              Previous Generation 
</code></pre>
<p>Hard disk drives that you can use for workloads with small datasets where data
is accessed infrequently and performance is not of primary importance.
Magnetic Volumes</p>
<pre><code>                              General Purpose SSD 
</code></pre>
<p>Characteristic gp3 gp2
Baseline IOPS Baseline of 3000 IOPS 3 IOPS/GiB (minimum 100 IOPS) to a maximum
of 16,000 IOPS
Baseline Throughput 125 MiB/s
Maximum throughput =
1000 MiB/s
Throughput between 128 MiB/s and 250 MiB/s,
depending on the volume size.
Generation Newer Older
gp3 offers SSD-performance at a 20% lower cost per GB than gp2 volumes.
Provisioned IOPS
Highest performance SSD volume designed for mission critical application workloads.
Characteristic io2 Block Express io2 io1
Durability 99.999% durability (0.001%
annual failure rate) 99.999% durability
(0.001% annual failure
rate)99.8% - 99.9% durability (0.1%</p>
<ul>
<li>
<p>0.2% annual failure rate)
Use cases Workloads that require:
Sub-millisecond latency
More than 64,000 IOPS or
1,000 MiB/s of throughput Workloads that require
sustained IOPS
performance or more
than 16,000 IOPS Workloads that require
sustained IOPS performance
or more than 16,000 IOPS
Max IOPS per
volume 256,000 64,000 † 64,000 †
Max
throughput
per volume 4,000 MiB/s 1,000 MiB/s † 1,000 MiB/s †
Hard Disk Drives
Characteristic Throughput Optimized HDD Cold HDD
Volume type st1 sc1
Max IOPS per volume 500 250
Max throughput per
volume 500 MiB/s 250 MiB/s
Use cases Big data, Data Warehouse Throughput-oriented storage for data that is
infrequently accessed
Scenarios where the lowest storage cost is
important
Sample Question
Medium Corp is an E-Commerce organization and you have been assigned
responsibility related to performance optimization of servers. They have a
critical database server which receives lot of connections and they tried
increasing RAM and CPU but still it is slow.  What type of EBS volume type will
you suggest ?
●General Purpose SSD
●Throughput Optimized
●Provisioned IOPS
●Cold HDD</p>
<pre><code>                   EBS Optimized Instances 

                 Understanding the Basics 
</code></pre>
</li>
</ul>
<p>The available network bandwidth of an instance depends on the number of
vCPUs that it has.
EBS volumes are mounted to the E2 instance via Network.
EC2 Instance EBS Volumes Bandwidth Mount
Understanding the Challenge
If EC2 instance is using the available bandwidth and has high Network I/O, it
can impact the overall performance at EBS level.
EC2 Instance EBS Volumes Bandwidth Mount
Internet
High Network Activity
Performance Impact
EBS Optimized EC2 Instances
An Amazon EBS–optimized instance uses an optimized configuration stack and
provides additional, dedicated capacity  for Amazon EBS I/O.
EC2 Instance
EBS Volumes Dedicated Capacity for EBS
Supported Instance T ypes
Not ALL instance types support EBS Optimization.
Some instances types have EBS Optimization enabled by default.
For certain instance types, you have to explicitly enable EBS Optimization.</p>
<p>Amazon Elastic File System (EFS)
Network Attached Storage
Overview of Elastic File System
knowledge portal Amazon Elastic File System (Amazon EFS) provides a simple, serverless, set-and-forget
elastic file system for use with A WS Cloud services and on-premises resources.
It is built to scale on demand to petabytes without disrupting applications, growing and
shrinking automatically  as you add and remove files
Mount
Elastic File System EC2
Attachment to Multiple T argets
knowledge portal Multiple compute instances, including Amazon EC2, Amazon ECS, and A WS Lambda,
can access an Amazon EFS file system at the same time, providing a common data source
for workloads.
Elastic File System</p>
<p>Understanding EFS Architecture
knowledge portal T o access file system from instance inside the VPC, we need to create mount target in the
VPC.</p>
<p>Network File System
knowledge portal Network File System (NFS) is a networking protocol for distributed file sharing.
EFS uses the Network File System version 4 (NFS v4) protocol
NFS Server
Mount
Client
Pricing Considerations
knowledge portal A WS EFS is expensive when compared to other storage options like EBS, S3.
Consideration Pricing
1 TB EFS with 80% frequently accessed data $250
1TB EBS Storage $102
1 TB of S3 Storage $24
Important Pointers
knowledge portal If performance is your concern, always prefer EBS.
EFS can even be accessed from on-premise datacenter using an A WS Direct Connect or
A WS VPN connection.
With Amazon EFS, you pay only for what you use per month.</p>
<pre><code>                              EFS - File System Policies 

              Understanding the Challenge 
</code></pre>
<p>When you create  EFS volume, by default, any EC2 instance will be able to
mount it provided sufficient network connectivity is present (no authentication)
mount
mount EFS
Implementing Restriction - T raditional W ay
Traditionally when EFS volume was launched, the primary way to restrict access
to EFS volume was through security groups.
EFS
Security Group
Rules
Allow 2049 from 172.31.20.50/32
EFS File System Policy
EFS File System policy is a resource based policy  that allows granular control
on the capabilities and accessibility at a EFS level.
File System Policy
Enforce Read-Only Access By Default
Prevent Anonymous Access
Enforce In-Transit Encryption
EFS File System Policy</p>
<pre><code>Grant read and write access to a specific A WS role 
</code></pre>
<p>Policy Example - Grant read-only access to IAM Role</p>
<pre><code>                                 EFS - Access Points 

                               Setting the Base 
</code></pre>
<p>When a EFS is mounted on EC2 instance, by default the root of the file system
is made available to the EC2.
mount -t nfs
Understanding the Challenge
If EFS has multiple set of directories for different application, you do not want the
ROOT of the file system available to all the clients.
Application 1
Application 2 Directories in EFS
app-1-folder
app-2-folder
secret-folder
EFS Access Points
Amazon EFS access points are application-specific entry points  into an EFS file
system that make it easier to manage application access to shared datasets
Application 1
Application 2 Directories in EFS
app-1-folder
app-2-folder
secret-folder app-1-folder
app-2-folder
S3 V ersioning
V ersioning in Object Storage
knowledge portal Challenge 1 - Multiple Object with Same Key
a.txt
a.txt
a.txt
Storage Store File
a.txt
knowledge portal Challenge 2 - Accidental Deletion of Objects
a.txt
Storage Delete File</p>
<p>knowledge portal          V ersioning in Object Storage
V ersioning allows users to keep multiple variants of an object in the same S3 bucket.
Y ou can use versioning to preserve, retrieve, and restore every version of every object stored in
your Amazon S3 bucket.
a.txt    a.txt
a.txt
Storage    a.txt
knowledge portal        Important Pointers for V ersioning
Once you version enable a bucket, it can never return to an unversioned state. Y ou can,
however, suspend versioning on that bucket.
The versioning state applies to all (never some) of the objects in that bucket.</p>
<p>Multi-Part Upload<br>
Saves our computer lives
Understanding Multi-Part
knowledge portal
● Multi-Part upload is a way in which we upload an entire file in the form of small individual
chunks to the storage device.
● While uploading data via multi-part, we need to specify the part number and its position in the
uploaded object. This will help A WS reconstruct data.</p>
<p>S3 Event Notification
S3 is more than just storage
Overview of S3 Event Notification
knowledge portal The Amazon S3 notification feature enables you to receive notifications when certain
events happen in your bucket.
Lambda
SQS
SNS
X Operation
S3 Bucket
S3 T ransfer Acceleration
Least Latencies
Overview of S3 T ransfer Acceleration
S3 T ransfer Acceleration allows users to accelerate data uploads from all over the world to
centralized S3 bucket.
The transfers are accelerated by routing data to the closest edge location.
CloudFront Edge
User S3 Bucket
Direct S3 Upload Optimized Network
STA Path
Edge Locations
knowledge portal</p>
<p>S3 T ransfer Acceleration
knowledge portal</p>
<p>Range GET in A WS S3
Back to Logging!
Data Retrieval Options
knowledge portal
There are two options while retrieving data from A WS S3.
Retrieval Configuration Description
Retrieve an entire object A single GET operation can return you the entire
object stored in Amazon S3.
Retrieve object in parts
Using the Range HTTP header in a GET request, you
can retrieve a specific range of bytes in an object
stored in Amazon S3.</p>
<p>How it W orks
knowledge portal
Give me only first 10 MB of the file.
Alright, here you go.
Benefits
knowledge portal
There are two important benefits of using this type of operation:</p>
<ol>
<li>This resumable download is useful when you need only portions of your object data.</li>
<li>It is also useful where network connectivity is poor and you need to react to failures.</li>
</ol>
<p>S3 Storage Classes
Cloud Storage is Saviour
Use-Case - Netflix
knowledge portal Netflix offers various different subscription plans for various category of requirements.
Main Aim: W atch the Entertainment Content</p>
<p>Initial Challenge - S3
knowledge portal A WS has millions of active customers.
Each customer might have different requirements for data storage.
Main Aim: Store Data.</p>
<p>S3 Storage Classes
knowledge portal Amazon S3 offers a range of storage classes designed for different use cases.</p>
<p>Storage Classes Description
S3 Standard Offers high durability, availability, and performance
object storage for frequently accessed data
S3 Standard-Infrequent Access For data that is accessed less frequently, but requires
rapid access when needed.
Amazon S3 Glacier Low-cost storage class for data archiving</p>
<p>A WS S3 Standard
knowledge portal S3 Standard offers high durability , availability , and performance object storage for frequently
accessed data.
Designed for durability of 99.999999999% of objects ( eleven nines )
Example :-</p>
<p>If we have 10,000 files stored in S3 ( 11 nines durability ) then you can expect to lose one file
every ten million years.</p>
<p>A WS S3 Standard IA
knowledge portal S3 Standard-IA is for data that is accessed less frequently , but requires rapid access when
needed.
Comparing storage cost of 1TB data stored in S3 based on accessibility patterns.</p>
<p>Criteria Amazon S3 Amazon S3 IA
Storage of 1TB Data $23.44 $23.50
50% storage accessed in
last 30 days - $18.18
0% storage accessed in last
30 days - $12.80
Amazon S3 Glacier
knowledge portal Glacier is meant to be for archiving and for storing long-term backups.
Ideally meant for data that needs to be archived for years without much requirement of access.</p>
<p>Criteria Amazon S3 Glacier
Storage of 1TB Data $23.44 $4.10
Multiple S3 Storage Classes</p>
<p>Durability vs A vailability
knowledge portal ● Durability is percent ( % ) over one year period of time that the file which is stored in S3
will not be lost.
● A vailability is percent (%) over one year period of time that the file stored in S3 will
not be available.
Example :-
For Servers, A vailability is one of the key metric and any minute of downtime is a loss.
However what happens if component of server itself fails and server goes down ?</p>
<p>S3 Intelligent- Tiering
Smart Automated System
Overview of S3 Intelligent Tiering
knowledge portal The S3 Intelligent Tiering  is primarily designed to optimize cost by automatically moving
data to most cost-effective tier.
● 1TB of data stored in Standard S3  = $23.44
● 1TB of data stored in Standard IA  = $12.80
Organization stores terabytes of data in S3.
It will be great if a solution automatically moves infrequent data to Standard IA.</p>
<p>Overview of S3 Intelligent Tiering
knowledge portal The S3 Intelligent Tiering  works by storing data in one of the two access tiers:
● Frequent Access Tier     (Costly)
● Infrequent Access Tier  (Much cheaper)
Frequent Access Tier Infrequent Access Tier
Overview of S3 Intelligent Tiering
knowledge portal The S3 Intelligent Tiering  works by storing data in one of the two access tiers:
● Frequent Access Tier      (Costly)
● Infrequent Access Tier   (Much cheaper)
Frequent Access Tier Infrequent Access Tier
Overview of S3 Intelligent Tiering
knowledge portal
Frequent Access Tier Infrequent Access Tier     Smart Automation System
Revising S3 Intelligent Tiering
knowledge portal Amazon S3 monitors access patterns of the objects in S3 Intelligent- Tiering, and moves the
ones that have not been accessed for 30 consecutive days to the infrequent access tier.
If an object in the infrequent access tier is accessed, it is automatically moved back to the
frequent access tier.
A monthly monitoring and automation fee is charged at a per object level.</p>
<p>S3 Storage Class - One Zone IA
Back again!
Understanding the Basics
knowledge portal Storage classes like Standard S3, Standard IA stores the data in minimum 3 availability zones.
Due to this, the overall cost per of storage is increased with such architecture.
Availability Zone 1      Availability Zone 2      Availability Zone 3
Overview of One Zone IA
knowledge portal S3 One Zone-IA stores data in a single AZ and costs 20% less than S3 Standard-IA.
It’s a good choice for storing secondary backup copies of on-premises data or easily recreatable
data.
Data will be lost in-case of availability zone destruction.
Availability Zone 1
Pricing Comparison
knowledge portal
Overview of Pricing comparison between storage classes:
● 1TB of data stored in Standard S3  = $23.44
● 1TB of data stored in Standard IA  = $12.80
● 1 TB of data stored in One Zone IA = $10.24</p>
<p>S3 Storage Class - Glacier
Back again!
Overview of Glacier
knowledge portal Amazon S3 Glacier is a low-cost, cloud-archive storage service that provides secure and durable
storage for data archiving and online backup.
Storage Class
Glacier  Glacier Deep Archive
Pricing Comparison
knowledge portal
Storage Class &amp; Data Storage Pricing
1 TB Data stored in S3 Standard $23.44
1 TB Data stored in One Zone IA $12.80
1 TB Data stored in Glacier $4.10
1 TB Data stored in Glacier Archive
$1.02
Glacier vs Glacier Deep Archive
knowledge portal T o keep costs low , Amazon S3 Glacier provides three options for access to archives, from a few
minutes to several hours.
Glacier Deep Archive provides two access options, which range from 12 to 48 hours
Storage Class Expedited Standard Bulk
Amazon S3 Glacier 1–5 minutes 3–5 hours 5–12 hours
S3 Glacier Deep Archive Not available Within 12 hours Within 48 hours
Important Note
knowledge portal Amazon S3 Glacier for archiving data that might infrequently need to be restored from minutes
to few hours.
S3 Glacier Deep Archive for archiving long-term backup cycle data that might infrequently
need to be restored within 12 hours</p>
<p>S3 Requester Pays
Back to Billing!
Understanding the Challenge
knowledge portal
In general, bucket owners pay for all Amazon S3 storage and data transfer costs associated
with their bucket.
Request to Download 1 TB file
Access granted, here you go.
After Requester Pays
With Requester Pays buckets, the requester instead of the bucket owner pays the cost of the
request and the data download from the bucket.
The bucket owner always pays the cost of storing data.
Request to Download 1 TB file
Access granted, here you go.
But your AWS account will pay for it.
S3 Encryption
S3 is Back
What’s the Need ?</p>
<p>Let’s be Proactive</p>
<p>S3 also needs Encryption
knowledge portal A WS S3 offers multiple approaches to encrypt the data being stored in S3.
i) Server Side Encryption
● Request Amazon S3 to encrypt your object before saving it on disks in its data
centers and then decrypt it when you download the objects.<br>
ii) Client Side Encryption
● Encrypt data client-side and upload the encrypted data to Amazon S3. In this case,
you manage the encryption process, the encryption keys, and related tools.</p>
<p>Server Side Encryption
knowledge portal Within Server-Side encryption, there are three options that can be used depending on the
use-case.
● Server-Side Encryption with Amazon S3-Managed Keys (SSE-S3)
● Server-Side Encryption with Customer Master Keys (CMKs) Stored in A WS Key
Management Service (SSE-KMS)
● Server-Side Encryption with Customer-Provided Keys (SSE-C)
SSE with Amazon S3-Managed Keys (SSE-S3)
knowledge portal  i) Server-Side Encryption with Amazon S3-Managed Keys (SSE-S3)</p>
<p>● In this approach, each object is encrypted with a unique key .
● Uses one of the strongest block ciphers to encrypt the data, AES 256.
Data 1
Data 2 Encrypted
Encrypted
SSE with CMK  (SSE-KMS)
knowledge portal  ii) Server-Side Encryption with CMKs Stored in A WS Key Management Service (SSE-KMS)</p>
<p>Encrypting data with own CMK allows customers to create, rotate, disable customer
managed CMK’s. W e can also define access controls and enable auditing.
Data 1
Data 2 Encrypted
Encrypted     KMS  CMK
S3 Encryption
S3 is Back
What’s the Need ?</p>
<p>Let’s be Proactive</p>
<p>S3 also needs Encryption
knowledge portal A WS S3 offers multiple approaches to encrypt the data being stored in S3.
i) Server Side Encryption
● Request Amazon S3 to encrypt your object before saving it on disks in its data
centers and then decrypt it when you download the objects.<br>
ii) Client Side Encryption
● Encrypt data client-side and upload the encrypted data to Amazon S3. In this case,
you manage the encryption process, the encryption keys, and related tools.</p>
<p>Server Side Encryption
knowledge portal Within Server-Side encryption, there are three options that can be used depending on the
use-case.
● Server-Side Encryption with Amazon S3-Managed Keys (SSE-S3)
● Server-Side Encryption with Customer Master Keys (CMKs) Stored in A WS Key
Management Service (SSE-KMS)
● Server-Side Encryption with Customer-Provided Keys (SSE-C)
SSE with Amazon S3-Managed Keys (SSE-S3)
knowledge portal  i) Server-Side Encryption with Amazon S3-Managed Keys (SSE-S3)</p>
<p>● In this approach, each object is encrypted with a unique key .
● Uses one of the strongest block ciphers to encrypt the data, AES 256.
Data 1
Data 2 Encrypted
Encrypted
SSE with CMK  (SSE-KMS)
knowledge portal  ii) Server-Side Encryption with CMKs Stored in A WS Key Management Service (SSE-KMS)</p>
<p>Encrypting data with own CMK allows customers to create, rotate, disable customer
managed CMK’s. W e can also define access controls and enable auditing.
Data 1
Data 2 Encrypted
Encrypted     KMS  CMK
SSE with Customer-Provided Keys (SSE-C)
knowledge portal Allows customers to set their own encryption keys.
Encryption key needs to be provided as part of the request and S3 will manage both the
encryption as well as the decryption options.
Data 1    AWS S3     #^&amp;#@<del>()   Encrypt
Key   Encrypted Data
Client Side Encryption
knowledge portal
Client-side encryption is the act of encrypting data before sending it to Amazon S3.
#^&amp;#@</del>()    AWS S3     #^&amp;#@~()   Store
S3 - Cross Region Replication
Storage Service
Understanding the Use-Case
Many compliance has a requirement that the data must be replicated across greater
distances.
Cross-Region Replication allows data from S3 buckets to be replicated across regions.
knowledge portal      Singapore
Mumbai
Replication
Important Pointers
Both source and destination buckets must have versioning enabled.
knowledge portal
S3 Object Lock
Mastering S3
Overview of WORM
knowledge portal W rite once read many (WORM) describes a data storage device in which information, once
written, cannot be modified.
This write protection affords the assurance that the data cannot be tampered with once it is
written to the device.
Modify / Delete
Storage
Use-Case - Ransomware
Ransomware also blackmail trojans , blackmail software are malicious programs with the
help of which an intruder can prevent the computer owner from accessing data, its use or the
entire computer system.
Private data on the foreign computer is encrypted or access to it is prevented in order to
demand a ransom for decryption or release.</p>
<p>S3 Object Lock
knowledge portal With S3 Object Lock, you can store objects using a write-once-read-many (WORM) model.
Y ou can use it to prevent an object from being deleted or overwritten for a fixed amount of
time or indefinitely .
Modify
S3
Retention Modes
knowledge portal
Retention Mode Description
Governance Mode When deployed in Governance mode, AWS accounts with
specific IAM permissions are able to remove object locks from
objects.
Compliance Mode In Compliance Mode, the protection cannot be removed by any
user, including the root account.</p>
<pre><code>                      S3 Storage Class Analysis 

                    Understanding the Basics 
</code></pre>
<p>By using Amazon S3 analytics Storage Class Analysis you can analyze storage
access patterns to help you decide when to transition the right data to the right
storage class.
This will help you tune your lifecycle policies.</p>
<pre><code>                          Points to Note 
</code></pre>
<p>Storage class analysis only provides recommendations for Standard to Standard
IA classes.
Does not provide recommendation for Glacier.
Offers option to create CSV report
You can also export this daily usage data to an S3 bucket and view them in a
spreadsheet application, or with business intelligence tools, like Amazon
QuickSight.</p>
<pre><code>                             Amazon S3 Inventory 

                      Understanding the Basics 
</code></pre>
<p>Amazon S3 Inventory provides comma-separated values (CSV) of output files
that list your objects and their corresponding metadata on a daily or weekly
basis for an S3 bucket</p>
<pre><code>                            Inventory List 
</code></pre>
<p>Following is some of the list of metadata for each listed object that Inventory list
contains:
●Bucket name
●Key name
●Version ID
●IsLatest
●Delete marker
●Size
●Last modified date
●Storage class
●Encryption status</p>
<pre><code>                             S3 Batch Operations 

                      Understanding the Basics 
</code></pre>
<p>S3 Batch Operations lets you manage billions of objects at scale  with just a few
clicks.
Bucket with 1 million objects
Batch Operations Add tag to all objects in bucket
Consider it Done Tag All Objects
Client
Points to Note
To create a job, you give S3 Batch Operations a list of objects and specify the
action to perform on those objects.
A batch job performs a specified operation on every object that is included in its
manifest.
You can use a comma-separated values (CSV)-formatted Amazon S3 Inventory<br>
report as a manifest, which makes it easy to create large lists of objects located
in a bucket</p>
<pre><code>                      Supported Operations 
</code></pre>
<p>Some of the supported Batch operations, include:
●Copy objects
●Invoke AWS Lambda function
●Replace all object tags
●Delete all object tags
●Replace access control list
●Restore objects
●S3 Object Lock retention
●S3 Object Lock legal hold
●Replicating existing objects with S3 Batch Replication</p>
<h2 id="easily-use-the-cloud-storage">Storage Gateway
Hybrid Storage
Introduction
knowledge portal A WS Storage Gateway is a hybrid storage service that allows the on-premise application to
easily use the cloud storage</h2>
<p>Storage Gateway
knowledge portal Storage Gateway appliance uses standard storage protocols like NFS, iSCSI which the
application connects to and stores the data.
The other end of storage gateway connects to A WS storage services like S3, Glacier and
EBS Snapshots</p>
<p>Storage Gateway Configuration
knowledge portal There are three different configuration available :</p>
<ul>
<li>Gateway Stored V olume</li>
<li>Gateway Cached V olume</li>
<li>Gateway-virtual tape library</li>
</ul>
<p>Gateway Stored V olumes
knowledge portal Gateway Stored V olume :<br>
Stores primary data locally while asynchronously backing up data to A WS.</p>
<p>Gateway Cached V olumes
knowledge portal Gateway Stored V olume :<br>
Data is stored primarily on A WS S3 with cache of recently read or written data stored
locally in the on-premise server.</p>
<p>Gateway-virtual tape library
knowledge portal Gateway-virtual tape library
Virtual tapes stored in S3 with frequently accessed data stored on-premise.</p>
<p>T ape based storage
knowledge portal T ape backup  is practice of periodically copying data from primary storage device to a tape
cartridge so data can be recovered if there is any data crash or failure on primary device.
T ape solutions remains most cost effective solution till date.</p>
<p>VTS and VTL
knowledge portal</p>
<p>File Gateway
Storage Gateway T ype
Overview of File Gateway
knowledge portal A WS Storage Gateway&rsquo;s file interface, or file gateway provides an interface via NFS, SMB
for synchronization of data from on-premise to S3 bucket.</p>
<pre><code>                                   Amazon FSx 

                         Basics of Filesystems 
</code></pre>
<p>There are multiple popular set of file systems / storage platforms  available in the
industry that are used extensively based on specific use-cases
File Systems Description
Lustre Parallel distributed file system, generally used for large-scale
cluster computing (HPC)
Open ZFS Encompasses the functionality of traditional file systems and logical
volume manager.
Benefits: protection against data corruption, efficient data
compression etc
Understanding the Challenges
Many organizations have use-case to leverage the rich feature sets and fast
performance of widely-used open source and commercially-licensed file
systems.
This would lead to lot of time-consuming administrative tasks like hardware
provisioning, software configuration, patching, and backups.</p>
<pre><code>                        Introduction to FSx 
</code></pre>
<p>Amazon FSx makes it easy and cost effective to launch and run popular file
systems.
It provides cost-efficient capacity and high levels of reliability, and integrates with
other AWS services so that you can manage and use the file systems in
cloud-native ways.</p>
<pre><code>                              Benefits of FSx 
</code></pre>
<p>Benefits Description
Simple and fully managed In minutes and with a few clicks, you can launch a fully managed file
system.
No need to worry about configuring, patching, backups etc.
Secure and compliant Amazon FSx automatically encrypts your data at-rest and in-transit.
Complies with PCI-DSS, ISO, SOC certifications
Integration with AWS
services Integrate with AWS services, including Amazon S3, AWS KMS,
Amazon SageMaker, Amazon WorkSpaces, AWS ParallelCluster.
Amazon FSx for Lustre
Provides cost-effective, high-performance, scalable file storage for compute
workloads such as machine learning, high performance computing (HPC), video
processing, and financial modeling.
Integrates seamlessly with Amazon S3, SageMaker, EKS etc</p>
<pre><code>              Amazon FSx for Windows File Server 
</code></pre>
<p>Provides simple, fully managed, highly reliable file storage that’s accessible over
the industry-standard Server Message Block ( SMB ) protocol.
Built on Windows Server, providing full SMB support and a wide range of
administrative features  like user quotas, data deduplication, and end-user file
restore. Accessible from Windows, Linux, and macOS.
Integrates with Microsoft Active Directory  (AD) to support Windows-based
environments and enterprises.</p>
<pre><code>                      FSx for OpenZFS 
</code></pre>
<p>Provides simple, cost-effective, high-performance file storage built on the
OpenZFS file system accessible over the industry-standard NFS protocol .
Provides powerful OpenZFS data management capabilities including
Z-Standard/LZ4 compression, instant point-in-time snapshots, and data cloning,
thin provisioning, and user/group quotas.</p>
<pre><code>           Amazon FSx for NetApp ONT AP 
</code></pre>
<p>Provides feature-rich, high-performance, and highly-reliable storage built on
NetApp’s popular ONTAP file system and fully managed by AWS.
Accessible via industry-standard NFS, SMB, and iSCSI protocols.
Integrates with Microsoft Active Directory (AD) to support Windows-based
environments and enterprises.</p>
<pre><code>                         Amazon FsX for Lustre 

                     Understanding the Basics 
</code></pre>
<p>Amazon FSx for Lustre provides fully managed shared storage with the
scalability and performance of the popular Lustre file system.</p>
<pre><code>                                Use-Cases 
</code></pre>
<p>Accelerate machine learning (ML)
Enable high performance computing (HPC)
Unlock big data analytics
Increase media workload agility (VFX)</p>
<pre><code>                          Use-Case W orkflow 
</code></pre>
<p>Data Stored in S3 is loaded in
FSx for Processing Processing
Output of Processing
is returned back to S3
for retention.
Data Repository
FSx for Lustre is natively integrated with data repositories  such as Amazon S3,
making it easier to process datasets with the Lustre file system.</p>
<pre><code>                        Lazy Loading of Data 
</code></pre>
<p>Lazy loading  is the practice of delaying load or initialization of resources or
objects until they’re actually needed to improve performance and save system
resources
S3 - Petabytes of Data
Load necessary data
Processing
File system deployment options
Amazon FSx for Lustre provides two file system deployment options: scratch
and persistent.
Depending on the option, the overall storage capacity and throughput changes.</p>
<pre><code>                   Deployment Option 1 - Scratch 
</code></pre>
<p>Scratch file systems are designed for temporary storage and shorter-term
processing of data. Provides high burst throughput.
Data isn&rsquo;t replicated and doesn&rsquo;t persist if a file server fails</p>
<pre><code>               Deployment Option 2 - Persistent 
</code></pre>
<p>Persistent file systems are designed for longer-term storage and workloads.
The file servers are highly available, and data is automatically replicated within
the same Availability Zone in which the file system is located.</p>
<pre><code>                            Points to Note 
</code></pre>
<p>You can configure FSx for Lustre to keep content synchronized in both directions
between the file system and the linked S3 buckets
Alternatively, you also have the option to import and export batches of new and
changed data between the file system and S3 for fine-grained control over data
synchronization.</p>
<pre><code>                 Increasing FSx Storage Capacity 

                 Understanding the Basics 
</code></pre>
<p>When you increase the storage capacity of your Amazon FSx file system, behind
the scenes, Amazon FSx adds a new, larger set of disks to your file system.
Amazon FSx then runs a storage optimization process in the background to
transparently migrate data from the old disks to the new disks.</p>
<pre><code>                  Understanding the Use-Case 

                          Points to Note 
</code></pre>
<p>Storage optimization can take between a few hours and a few days, with
minimal noticeable impact on the workload performance.
You can only increase the amount of storage capacity for a file system; you
cannot decrease storage capacity.
To increase the storage capacity for an FSx for Windows File Server file system,
use the AWS CLI command update-file-system .</p>
<pre><code>                                     AWS Systems Manager 
                               Setting the Base 
</code></pre>
<p>AWS Systems Manager is a collection of capabilities  that helps you manage
your applications and infrastructure running on AWS and on-premises
environments.
AWS Systems Manager Run Command
Parameter Store Sessions Manager<br>
Patch Manager    State Manager   Inventory
Compliance
Fleet Manager   Distributor
Additional Example
Think of Systems Manager as a central command center  where you can
monitor, maintain, and configure your AWS resources at scale without needing to
log into individual servers or instances.</p>
<pre><code>                                    Basic W orkflow 
</code></pre>
<p>Most AWS Systems Manager features rely on the SSM Agent  running on your
EC2 instances.
Through the Systems Manager console, customers can remotely execute
specific tasks  and manage their instances by communicating with the installed
agent.
AWS Systems Manager
SSM Agent
Completed Perform Task A
EC2
Setup and Conﬁgure Node for Systems Manager
Step 1 - Installing SSM Agent
SSM Agent must be installed in the EC2 instance.
Systems Manager
SSM Agent
EC2
Step 2 - Configure IAM Role
SSM Agent needs permissions to interact with various AWS services (like SSM,
EC2, CloudWatch, S3, etc.) on your behalf.
By attaching an IAM role with the correct policies, you allow the SSM Agent to
securely communicate with SSM endpoints.
SSM Agent
EC2IAM Role
Step 3 - Attach IAM Policy to IAM Role
The AmazonSSMManagedInstanceCore  is an AWS managed policy that
provides the minimum set of permissions required for an EC2 instance to be
managed by SSM.
This is the policy you should attach to the IAM role assigned to your EC2
instances that you want to manage using SSM
SSM Agent
EC2IAM Role
AmazonSSMManagedInstanceCore
SSM - Overview of Sessions Manager
Setting the Base
Sessions Manager  allows customers to connect to the instances through an
interactive one-click browser-based shell  or through the AWS CLI.</p>
<pre><code>                      Key Features of Session Manager 
</code></pre>
<p>Key Feature Description
No Open Inbound Ports No need for ports like 22 (SSH) to be open on instances.
No SSH Keys Required Avoid overhead of distributing, rotating, and revoking SSH keys.
Role-Based Access Control Uses AWS IAM policies to control who can start sessions.
Auditing and Logging Session activity can be logged to Amazon S3 or CloudWatch Logs for
auditing and compliance.
Reference Screenshot - Command Logged</p>
<pre><code>               A WS Session Manager CLI Approach 
</code></pre>
<p>You can also initiate sessions to the EC2 instances directly from the CLI.</p>
<pre><code>                                    SSM - Run Command 
                                     Setting the Base 
</code></pre>
<p>SSM Run Command  is a feature of AWS Systems Manager that lets you
remotely execute scripts, commands, and automations  on your EC2 instances or
on-premises servers without the need to SSH or RDP into them.
Systems Manager
SSM Agent
Anti-Virus Installed yum -y install
antivirus
EC2
Practical - SSM Run Command
Important Steps to Follow
1.EC2 instance must have SSM Agent installed
2.Instances must have appropriate IAM Role.
3.Security Group must allow outbound access towards SSM endpoints.
Benefits of Run Command
Benefits Description
No direct login required Eliminates the need to open inbound ports or manage SSH keys.
Auditability All actions are logged in AWS CloudTrail.
Scalability Commands can be run across thousands of instances
simultaneously.
Security Uses IAM for granular access control.
Common Use-Cases for Run Command
Use-Case Description
Ad-hoc commands Run shell commands or PowerShell scripts as needed.
Software deployment Deploy or update software packages at scale.
Troubleshooting Gather logs or run diagnostics scripts.
SSM - Parameter Store
Setting the Base
Parameter Store  is a service that lets you securely save and manage
configuration settings and secrets (like passwords or API keys) for your
applications in a central way .
Parameter Store Parameters Value
dev-dev-host dev-db..in
dev-db-pass supersecretpass
dev-db-user dbadmin
Application What is dev db host?
dev-db..in
T ype of Parameters
A parameter is any piece of data that is saved in Parameter Store, such as a
block of text, a list of names, a password and so on.
There are three different parameter types available based on the use-case.
Parameter Types Parameter Type
String
StringList
SecureString
Reference Screenshot - Parameter T ypes</p>
<pre><code>                            Parameter T ype - String 
</code></pre>
<p>It can be used to store plain text data , including serialized JSON or XML.
Used for non-sensitive information like environment names, feature flags, or
URLs.</p>
<pre><code>                     Parameter T ype - StringList 
</code></pre>
<p>A comma-separated list of plain text strings .
Used for lists of values, such as IP addresses, server names, or multiple email
addresses.</p>
<pre><code>                        Parameter T ype - SecureString 
</code></pre>
<p>An encrypted value , protected with AWS KMS (Key Management Service).
Used for sensitive information like passwords, API tokens, or secrets.
KMS Parameter Store
Application
Reference Screenshot - SecureString</p>
<pre><code>                               Revising the T opic 
</code></pre>
<p>Type Encrypted Typical Use Example Value
String No Non-sensitive, plain text mydb.example.com
StringList No List of plain text values val1,val2,val3
SecureString Yes Sensitive data (secrets) supersecretpassword
Points to Note - Parameter Store
Parameter Tier
Parameter Store offers standard and advanced  parameters.</p>
<p>Feature Standard Advanced
Total number of parameters allowed 10,000 100,000
Maximum size of a parameter value 4 KB 8 KB
Parameter policies available No Yes
Sharing with other AWS Account No Yes
Cost No additional charge Charges apply                            Standard vs Advanced Tier
Reference Screenshot - Parameter Policies</p>
<pre><code> Reference Systems Manager parameters in A WS services 
</code></pre>
<p>There is a special syntax you can use to automatically fetch the value of a
Parameter Store parameter inside certain AWS services (like Run Command,
ECS, Lambda, and others), without writing any code.
{{ssm: parameter-name }}
When you use {{ssm: parameter-name }}, AWS will replace that placeholder with
the actual value stored in Parameter Store at runtime.
Example:  echo &lsquo;{{ssm:demo-string}}&rsquo; &gt; /tmp/string.txt
Parameter Hierarchies
A parameter hierarchy  is a way of organizing your parameters  in a tree-like
structure, using slash-separated names.
This allows you to group related parameters and manage them more easily.</p>
<pre><code>                             Parameter Hierarchies 

                        Retrieving Parameters by Path 
</code></pre>
<p>You can use the GetParametersByPath API to retrieve all parameters under a
specific path.</p>
<pre><code>                         AWS Systems Manager - Automation 
                                Setting the Base 
</code></pre>
<p>AWS Systems Manager Automation enables you to automate operational tasks
across AWS resources  safely and at scale.
It supports wide range of services including EC2, S3, RDS, and many more.
SSM Automation
Create new
AMI from EC2
Quarantine
EC2
Benefits of SSM Automation
Benefits Description
Consistency Ensures tasks are executed the same way every time, reducing human
error.
Scalability Enables execution of tasks across thousands of instances and resources
in multiple accounts and regions.
Cost and Time Savings Reduces manual effort, freeing up engineers for higher-value tasks.
Reference Screenshot - Automation</p>
<pre><code>                            Points to Note - SSM  Automation 
                            Automation Runbook 
</code></pre>
<p>An SSM Automation runbook  is essentially a predefined document that contains
a series of steps to automate AWS operational tasks.</p>
<pre><code>                                  Point to Note 
</code></pre>
<p>Runbooks can be either AWS-managed  (pre-built by AWS) or custom-created by
you.
AWS provides hundreds of pre-built runbooks for common tasks like patching
instances, creating AMIs, or stopping/starting EC2 instances.</p>
<pre><code>                     SSM Runbook Execution Options 
</code></pre>
<p>When you run an Automation, you have to select the appropriate execution
option.</p>
<pre><code>                    SSM Runbook Execution Options 
</code></pre>
<p>Option Description Use-Case
Simple execution Basic execution mode that runs the
automation document on specified targets Single account/region scenarios
Rate control Execute safely on multiple targets by
defining concurrency and error thresholds. Cross-account operations
Multi-region deployments
Enterprise-wide automation
Multi-account and
Region Execute in multiple accounts and
Regions. Large-scale operations
Production environments
Risk-sensitive automations
Manual execution Step-by-step runbook mode. Critical operations
Human oversight
Automation - Multi Region / Multi-A WS Account
You can run AWS Systems Manager automations across multiple AWS Regions
and AWS accounts or AWS Organizations organizational units (OUs) from a
central account.</p>
<pre><code>                      AWS Systems Manager - Patch Manager 
                            Revision on Patching 
</code></pre>
<p>Patching is the process of applying updates —called patches—to software,
operating systems, etc.
Unpatched systems are a leading cause of security breaches. Attackers often
exploit known vulnerabilities that have been fixed in patches, but not yet applied
by users.</p>
<pre><code>                     Introducing Patch Manager 
</code></pre>
<p>Patch Manager , a tool in AWS Systems Manager, automates the process of
patching managed nodes.
Patch Manager
Apply Patches Scan for Missing Patches Missing Patches
cron
curl
mysql
vim
Reference Screenshot - Missing Patches Reported</p>
<pre><code>                                   Patch Baseline 
</code></pre>
<p>A patch baseline controls what patches should or should not be installed on your
instances.
Patch Baseline Missing Patches
cron
curl
mysql
vimRejected
Reference Screenshot - Approval Rules in Patch Baseline</p>
<pre><code>                   Reference Screenshot - Patch Exceptions 

                            Maintenance Windows 
</code></pre>
<p>A maintenance window is a schedule that defines when your patching or other
administrative tasks should run.
Example:  Perform Patching activity at 2 AM in the morning on Sundays.</p>
<pre><code>                              Patch Operations 
</code></pre>
<p>You can choose for Patch Manager to show you:
1.Only a report of missing patches (a Scan operation )
2.Automatically install all patches it find are missing from a managed node (a
Scan and install operation ).</p>
<pre><code>                         Benefits of Patch Manager 
</code></pre>
<p>Benefits Description
Patch policies Configure patching operations across multiple AWS accounts and Regions using a
single policy through integration with AWS Organizations.
Multiple patching methods Choose from patch policies, maintenance windows, or on-demand &ldquo;Patch now&rdquo;
operations to meet your specific needs.
Compliance reporting Generate detailed reports on patch compliance status that can be sent to an Amazon
S3 bucket in CSV format.
Cross-platform support Patch both operating systems and applications across Windows Server, various
Linux distributions, and macOS.
Rate control Configure concurrency and error thresholds for patching operations to minimize
operational impact.
AWS Systems Manager - Inventory
Setting the Base
You can use Inventory to collect metadata from your managed nodes.
Metadata includes:  Files, Application Names, Services, Windows Registry etc.</p>
<pre><code>                          Storing Metadata Centrally 
</code></pre>
<p>You can store this metadata in a central S3 bucket, and then use built-in tools to
query the data  and quickly determine which nodes are running the necessary
software.
SSM Inventory
In which servers
anti-virus is not
installed?
Reference Screenshot - Centralized Architecture</p>
<p>A WS Batch
Running Batch Jobs
Getting Started
knowledge portal
A batch job is a collection, or list, of commands that are processed in sequence often
without requiring user input or intervention.
Generally batch jobs accumulate during working hours, and are then executed during the
evening or another time the computer is idle.
Batch jobs wait in a job queue for processing when the system has the available resources.</p>
<p>Overview of A WS Batch
knowledge portal
A WS Batch enables developers, scientists, and engineers to easily and efficiently run
hundreds of thousands of batch computing jobs on A WS.
A WS Batch dynamically provisions the optimal quantity and type of compute resources
(e.g., CPU or memory optimized instances) based on the volume and specific resource
requirements of the batch jobs submitted.</p>
<p>Simple W orkflow Service
W orkflow execution
What is a W orkflow?
knowledge portal
A W orkflow is a sequence of tasks that processes a set of data.
A workflow is a set of activities that carry out some objective</p>
<p>Overview of SWF
knowledge portal
The Amazon Simple W orkflow Service (Amazon SWF) makes it easy to build applications
that coordinate work across distributed components.</p>
<p>knowledge portal               Start
firstToUpper      restToLower
concatenate
Finish
“Hello World” “hello world”
Overview of Activities
knowledge portal
Activities are were the actual processing takes place.
function firstT oUpper (input: String) {
return input[0].toUpperCase();
}</p>
<p>Overview of Decider
knowledge portal
Defines execution order of the processes.
Flow of input/ output between multiple processes.
Conditionals and Concurrency .
One decider per workflow .</p>
<p>AppStream 2.0
Interesting Service
knowledge portal                                   Getting Started
AppStream 2.0 allows us to centrally manage our desktop application and securely deliver them
to any computer.
Sample Use-Case:
Software vendors can use AppStream 2.0 to deliver trials, demos, and training for their
applications with no downloads or installations.</p>
<p>1397                 AWS Transfer Family</p>
<pre><code>                         Understanding the Basics 
</code></pre>
<p>AWS Transfer Family securely scales your recurring business-to-business file
transfers to AWS Storage services using SFTP, FTPS, FTP, and AS2 protocols.</p>
<pre><code>                             Lambda Versioning 

                    Understanding the Basics 
</code></pre>
<p>Lambda allows developers to host multiple versions of their code.
Version 1 APP
Version 2 APP Lambda
Function V ersion
A function version includes the following information:
1.The function code and all associated dependencies.
2.The Lambda runtime identifier and runtime version used by the function.
3.All the function settings, including the environment variables.
4.A unique Amazon Resource Name (ARN) to identify the specific version of
the function.</p>
<pre><code>                        T esting Before Prod 
</code></pre>
<p>You can allow certain amount of traffic to a specific version of function to test
before rolling out changes.
Prod Version
Stage Version Lambda
Users 95%
5%
Lambda Alias</p>
<pre><code>                    Understanding the Basics 
</code></pre>
<p>A Lambda alias  is like a pointer to a specific function version.<br>
Users can access the function version using the alias Amazon Resource Name
(ARN).
Version 1 APP
Version 2 APP
Version 3 APP    Stable Code
Lambda Alias
Alias routing configuration
We can use routing configuration on an alias to send a portion of traffic to a
second function version
Version 1 APP
Version 2 APP
Version 3 APP    Stable Code
Lambda Alias 90% Traffic
10% Traffic
Lambda Deployment Package</p>
<pre><code>                     Understanding the Basics 
</code></pre>
<p>Your AWS Lambda function&rsquo;s code can consists of scripts or compiled programs
and their dependencies
A dependency can be any package, module or other assembly dependency that
is not included with the Lambda runtime environment for your function&rsquo;s code.
Dependencies</p>
<pre><code>             Overview of Deployment Package 
</code></pre>
<p>The deployment package acts as the source bundle to run your function&rsquo;s code
and dependencies (if applicable) on Lambda.</p>
<pre><code>                            Points to Note 
</code></pre>
<p>Lambda supports two types of deployment packages :
Container images and .zip file archives.
Containers   Zip Archives
Migrating Lambda Function</p>
<pre><code>                  Understanding the Use-Case 
</code></pre>
<p>You have a Lambda function that is running in AWS Account A.
You now want the exact same function in AWS Account B.
Copy Function
Account 1 Account 2
Step 1 -  Exporting Function
To migrate a Lambda function to another AWS account or AWS Region using the
Lambda console, do the following:
1.Download the Lambda function’s deployment package.
2.Use the Lambda function’s deployment package to create a new Lambda
function in another AWS account or Region.</p>
<pre><code>                      Step 2 -  Importing Function 
</code></pre>
<p>Use the “Upload From” option in the new account’s Lambda function and upload
the zip file.</p>
<pre><code>                          Points to Note 
</code></pre>
<p>The deployment package contains only the Lambda function’s code.
The rest of your function’s configurations, such as timeout and memory size,
must be entered manually in the console when you create the new function.
To migrate all your function’s code and configurations automatically, you can use
an AWS SAM file.</p>
<pre><code>                      Basics of Lambda Concurrency 

                  Understanding the Basics 
</code></pre>
<p>Concurrency  is the number of in-flight requests your AWS Lambda function is
handling at the same time
For each concurrent request, Lambda provisions a separate instance of your
execution environment.
Execution Env 01
Execution Env 02
Request 1
Request 2
Point to Note
As your functions receive more requests, Lambda  automatically handles scaling<br>
the number of execution environments until you reach your account&rsquo;s
concurrency limit.</p>
<pre><code>      Understanding and visualizing concurrency 
</code></pre>
<p>To handle a request, Lambda must first initialize  an execution environment (the
Init phase), before using it to invoke your function (the Invoke phase)
When Lambda finishes processing the first request, this execution environment
can then process additional requests for the same function.</p>
<pre><code>                              Point to Note 
</code></pre>
<p>Lambda can reuse the same execution environment to handle the second
request.
Single instance of your execution environment = Concurrency of 1</p>
<pre><code>                        Creating Base W orkflow 
</code></pre>
<p>In real world scenario, Lambda may need to provision multiple execution
environment instances  in parallel to handle all incoming requests.
When your function receives a new request, one of two things can happen:
1.If a pre-initialized execution environment instance is available, Lambda uses
it to process the request.
2.Otherwise, Lambda creates a new execution environment instance to
process the request.</p>
<pre><code>                 Sample W orkflow - 10 Requests 

            Reserved and Provisioned Concurrency 

                  Understanding the Basics 
</code></pre>
<p>The default concurrency limit per AWS Region is 1,000 invocations at any given
time
Your functions share this pool of 1,000 concurrency on an on-demand basis.
Your function experiences throttling  (i.e. it starts to drop requests) if you run out
of available concurrency.</p>
<pre><code>                       Practical Point of View 
</code></pre>
<p>Some of your functions might be more critical than others.
As a result, you might want to configure concurrency settings to ensure that
critical functions get the concurrency they need.
Dev Lambda Function
QA Lambda Function
Prod Lambda Function Concurrency = 200
Concurrency = 600
Oops, only 200 left!
Concurrency Controls
Concurrency Control Description
Reserved concurrency Reserve a portion of your account&rsquo;s concurrency for a function.
Useful if you don&rsquo;t want other functions taking up all the available
unreserved concurrency.
Provisioned concurrency Pre-initialize a number of environment instances for a function.
Useful for reducing cold start latencies.
Reserved concurrency
If you want to guarantee that a certain amount of concurrency is available for
your function at any time, use reserved concurrency.
When you dedicate reserved concurrency to a function, no other function can
use that concurrency.</p>
<pre><code>              Challenge with Reserved Concurrency 
</code></pre>
<p>You use reserved concurrency to define the maximum number of execution
environments reserved for a Lambda function.
However, none of these environments come pre-initialized
As a result, your function invocations may take longer because Lambda must
first initialize the new environment before being able to use it to invoke your
function
When initialization takes longer than expected, this is known as a cold start. To
mitigate cold starts, you can use provisioned concurrency.</p>
<pre><code>                             Provisioned concurrency 
</code></pre>
<p>Provisioned concurrency is the number of pre-initialized execution environments<br>
you want to allocate to your function
If you set provisioned concurrency on a function, Lambda initializes that number
of execution environments so that they are prepared to respond immediately to
function requests.</p>
<pre><code>                       Practical Point of View 
</code></pre>
<p>You could use provisioned concurrency to set a baseline amount of
environments to handle request during weekdays, and use reserved
concurrency to handle the weekend spikes.</p>
<p>Comparing Reserved and Provisioned concurrency</p>
<pre><code>                                Lambda Layers 

                    Understanding the Challenge 
</code></pre>
<p>Let us assume there are 50 Lambda functions created based on Python.
All 50 function uses same set of base libraries.
Challenge:  Large Size Deployment Package, Update Difficult, Deployment Time
base module
base module
base module
Function 1 Function 2 Function 50
Understanding the Basics
Lambda layers  provide a convenient way to package libraries and other
dependencies that you can use with your Lambda functions.
base module
Function 1 Function 2 Function 3 Lambda Layer
Layer Path for Lambda Runtime</p>
<p>Connectivity Features of Lambda
Networking Again!
knowledge portal                    Connectivity Features
There can be scenarios where Lambda function needs to connect to EC2 instances, RDS
databases which are running inside the VPC (private subnet)
Lambda can connect to both the resources inside the VPC and Public Resources.
Internet VPC
Lambda Function
knowledge portal                    Lambda and VPC
By default, when your Lambda function is not configured to connect to your own VPCs, the
function can access anything available on the public internet
However we can configure Lambda to connect to VPC by associate VPC and subnets with the
function.</p>
<p>knowledge portal                 Important Point to Note
When launching in a specific subnet in VPC, make sure that NA T gateway is attached in-case if
you need internet access to the Lambda function.
Lambda can also connect to A WS services like SQS via Private Link (VPC Endpoints)
If Lambda wants to connect to SQS to perform certain operations, appropriate IAM role will
be needed.
If launched in VPC, you need to assign appropriate IAM role so that Lambda can perform
certain operations like creating/ deleting network interfaces.
Content Delivery Networks (CDN)
Setting the Base
Let’s consider your website contains a very popular image of Mr Crow .
If 1,000 users visit a website containing a single image, the server must send
that image 1,000 times—one to each user.
Global Users Server
Disadvantage
1.The main server must handle every user request, which can cause
slowdowns or outages under heavy traffic.
2.Higher Bandwidth Cost.
3.Users far from the server (e.g., server in India, users in USA/Europe) might
experience slower load times.
4.Server vulnerable to attack.
Prepare for Attackers
Attackers love Internet.
A typical website and web-application face various type of attacks  ranging from
DDoS, Web-Application attacks and so on.
Global Users Server
denial of service attack
Possible Solution
A better architecture would be to introduce a hardened middle layer that has all
functionalities related to protecting against attacks, caching of commonly
requested objects for better performance.
Server Hardened Middle
Layer
Global Users
Cached
Content Delivery Networks
A CDN acts as an intelligent proxy that receives the request and then forwards it
to the backend systems.
Many CDN’s also comes with features like DDoS Protection, WAF, Caching, etc
Server
Global Users
CDN
Server
Global Users
Web Application Firewall
Caching
DDoS Protection
SSL/TLS Termination
Content Optimization CDN
Distributed Network
A Content Delivery Network (CDN) is a distributed network of servers  that cache
and deliver website content as close to your end-users as possible</p>
<pre><code>                             Benefits of CDNs 
</code></pre>
<p>Benefits Description
Improved Performance Static Assets like images can be cached at CDN level leading to
reduced latency and faster load times for users.
Enhanced Security Built-in security features protect against common web threats
and attacks.
Bandwidth Savings Offloading traffic to CDN edge servers reduces the load on origin
servers and saves bandwidth costs.
Amazon CloudFront
Setting the Base
Amazon CloudFront is a content delivery network  (CDN) offering in AWS.
Server
Global Users
CloudFront
Supported Origins
When you create a CloudFront distribution, you specify the origin  where
CloudFront sends requests for the files.
You can use several different kinds of origins with CloudFront.
CloudFront Origins
S3 Bucket
Load Balancers
Lambda Functions
API Gateway
Custom Origins
Mediastore/Mediapackage Supported
Origins
Integration with A WS Services
CloudFront supports wide range of integration with other AWS services.
CloudFront Integrations Integrations Use-Case
AWS WAF Protect against web exploits and bots.
AWS Shield DDoS protection by default
ACM Use AWS Certificate Manager for HTTPS.
Edge Locations
CloudFront Edge Location  is a data center where cached copies of your content
are stored and served to users.
Edge locations are strategically distributed around the world to ensure that
requests for your web content are handled as close as possible to the end-user</p>
<pre><code>                        CloudFront - Origin Access Control 

                  Understanding the Challenge 
</code></pre>
<p>Security controls applied at Cloudfront can easily be bypassed  if attacker sends
a request directly to the origin.
CloudFront S3 Bucket
Geo-Restriction Filter
Block From Country A
Block From Country B Bypass CloudFront
Ideal Approach
You want to restrict S3 bucket access to requests originating from a specific
CloudFront distribution only.</p>
<p>CloudFront S3 Bucket Policy
Only Allow Connections
from  CloudFront
distribution.
Origin Access [Control and Identity]
CloudFront provides two ways  to send authenticated requests to an Amazon S3
origin:</p>
<ol>
<li>
<p>Origin access control  (OAC) [Recommended]</p>
</li>
<li>
<p>Origin access identity  (OAI)
CloudFront S3 Bucket Policy
Only Allow Connections
from Cloudfront
distribution with ID ES234
Reference Screenshot - Origin Access Methods</p>
<pre><code> Reference Screenshot - S3 Bucket Policy 

                 Understanding the Difference 
</code></pre>
</li>
</ol>
<p>Features / Aspects Origin Access Identity Origin Access Control
Availability Legacy (introduced earlier), still supported
but not recommended for new distributions Modern and recommended for new
distributions.
HTTP Method No support for PUT, POST, or DELETE to
Amazon S3 OAC supports GET, PUT, POST, PATCH,
DELETE, OPTIONS, and HEAD.
Encryption Server-Side Encryption with Amazon
S3-Managed Keys (SSE-S3). SSE KMS not
supported. OAC supports downloading and uploading
S3 objects encrypted with SSE-KMS.
Region Support No support for new AWS Regions launched
after January 2023 OAC supports accessing S3 in all AWS
regions, including existing regions and all
future regions.
Security Provides basic access control through bucket
policies. While secure, it is now considered a
legacy method. Enhanced security practices like short term
credentials, frequent credential rotations, and
resource-based policies
Custom Error Pages - CloudFront</p>
<pre><code>                  Understanding the Challenge 
</code></pre>
<p>The status code and the error page that CloudFront receives from the origin is
also returned to the viewer.
This will not create a good experience for the user accessing the website.</p>
<pre><code>           Generating Custom Error Response 
</code></pre>
<p>You can configure CloudFront to return a custom error response to the viewer
that is different from the origin response.
GET /admin.php GET /admin.php
HTTP 403 Access Denied HTTP 404. Sorry Dude,
Page Not Found CloudFront
Multiple Origins Conﬁguration - CloudFront</p>
<pre><code>                  Understanding the Basics 
</code></pre>
<p>You can configure a single CloudFront web distribution to serve different types of
requests from multiple origins .
For example, your website might serve static content from an Amazon Simple
Storage Service (Amazon S3) bucket and dynamic content from EC2.
CloudFront EC2 Instance
S3 Bucket HTML Files
JPG Files</p>
<pre><code>               Practical Approach - Step 1 
</code></pre>
<p>1.You need to have two origins (EC2 and S3 Bucket)</p>
<pre><code>               Practical Approach - Step 2 
</code></pre>
<ol start="2">
<li>
<p>Create a behavior  that specifies a path pattern to route all static content
requests to the S3 bucket</p>
<pre><code>  High-Availability with CloudFront Origin FailOver 

            Understanding the Challenge 
</code></pre>
</li>
</ol>
<p>If the CloudFront origin is down, then it can impact the production environment.
CloudFront EC2 Instance</p>
<pre><code>                 Achieving High-A vailability 
</code></pre>
<p>You can set up CloudFront with origin failover  for scenarios that require high
availability.
CloudFront EC2 Instance
Backup EC2
Failover Region 1
Region 2
Points to Note
When there’s a cache hit, CloudFront returns the requested object.
When there’s a cache miss, CloudFront routes the request to the primary origin
in the origin group.
When the primary origin returns a status code that is not configured for failover,
such as an HTTP 5xx or CloudFront fails to connect to the origin, then
CloudFront routes the request to the secondary origin in the origin group.</p>
<pre><code>                                 CloudFront - Signed URLs 
                         Understanding a Use-Case 
</code></pre>
<p>A music company stores all its MP3 files  in an Amazon S3 bucket.
They want to allow customers to download specific music files only after
purchase via their website.
Music Files
01.mp3
02.mp3
03.mp3
Introducing Signed URLs
A CloudFront Signed URL is a special link  that provides secure, temporary
access to private content  distributed via Amazon CloudFront
Music Files
01.mp3
02.mp3
03.mp3
Access 01.mp3
Access 01.mp3
Special URL:
https://special-url.
.internal Subscriber Random Users
Cloudfront
Generating Signed URLs
Only trusted signers  can generate signed URLs.
These signers use their private keys  to sign URLs, ensuring authenticity and
security.</p>
<pre><code>                      Use-Case for Signed URLs 
</code></pre>
<p>Use-Case Description
Paywalled Content Serve premium videos, music, or articles only to paying customers.
Software Downloads Distribute installers or patches to authorized users.
Temporary File Sharing Allow a user to access a file for a limited period.
Signed URLs and Signed Cookies
You can either generate Signed URLs  or even Signed Cookies .
Signed URL
Best for granting access to individual files (e.g., one song download).
Signed Cookies
Ideal for scenarios where a user needs to access multiple protected
files (e.g., all videos in a course) without generating a separate
signed URL for each resource.</p>
<pre><code>                            Practical -  CloudFront Signed URLs 
                                    Practical Steps 
</code></pre>
<p>1.Generate Public / Private Key for Trusted Signer
2.Create CloudFront distribution with Origin Access Identity.
3.Generate signed URL using aws cloudfront sign &ndash;url  CLI command.
4.Download and enjoy your file.</p>
<p>Lambda@Edge
Running Serverless at the Edge
knowledge portal                          Getting started
Lambda@Edge lets you run Lambda functions to customize content that CloudFront
delivers.
Y ou can use Lambda functions to change CloudFront requests and responses at the following
points:</p>
<ol>
<li>
<p>After CloudFront receives a request from a viewer ( viewer request )</p>
</li>
<li>
<p>Before CloudFront forwards the request to the origin ( origin request )</p>
</li>
<li>
<p>After CloudFront receives the response from the origin ( origin response )</p>
</li>
<li>
<p>Before CloudFront forwards the response to the viewer ( viewer response )</p>
<p>knowledge portal                  Diagrammatic Representation
Viewer Request
Viewer Response Origin Request
Origin Response     User Agent CloudFront
Cache
knowledge portal                     Viewer Request
Viewer Request is executed on every request before CloudFront cache is checked.
There are various things that we can do at this stage, like:
● Modify URLs, cookies query strings etc.
● Perform Authentication and Authorization Checks.</p>
<p>knowledge portal                           Viewer Request
Viewer Request Event
HTTP 403 OK
Verify Token
knowledge portal                     Origin Request
Executed on cache miss, before a request is forwarded to the origin.
There are various things that we can do at this stage, like:
● Dynamically select origin based on the request headers</p>
<p>knowledge portal                           Origin Request
Viewer Request
Viewer Response  Origin Request
Origin Response     User Agent
CloudFront
Cache
knowledge portal                     Origin Response
Executed on a cache miss, after a response is received from the origin.
There are various things that we can do at this stage, like:
● Modify the response headers.
● Intercept and replace various 4XX and 5XX errors from the origin.</p>
<p>knowledge portal                           Origin Response
Viewer Request
Viewer Response  Origin Request
Origin Response     User Agent
CloudFront
Cache
knowledge portal                     Viewer Response
Executed on all the responses received either from the origin or the cache.
Modifies the response headers before caching the response.</p>
<p>knowledge portal
Viewer Request
Viewer Response  Origin Request
Origin Response     User Agent
CloudFront
Cache
CloudFront Functions</p>
<pre><code>            Understanding the Basics 
</code></pre>
</li>
</ol>
<p>CloudFront Functions allows users to write lightweight functions in JavaScript  for
high-scale, latency-sensitive CDN customizations.
Your functions can manipulate the requests and responses that flow through
CloudFront
CloudFront EC2 Instance
Redirect All Request to AWS Docs
Function Welcome! aws.amazon.com
Basics of API</p>
<pre><code>                       Understanding the Challenge 
</code></pre>
<p>Book Distributor maintains the list of available books in it’s backend systems.
Operator has access to Backend system to check the availability.
Clients they connect to Operator via Phone call / Chat option
BackEnd System + Operator
Clients Call / Chat
API Based Approach
The book distributor could provide an API to check stock availability.
APIs let you open up access to your resources  while maintaining security and
control.
BackEnd System   API
How many Security
books available?
25
Simple Use-Case
James wants to build a weather report application.
OpenWeatherMap is an online service that provides global weather data via API.
He decided to connect his application to OpenWeatherMap API to fetch the
latest reports and populate it in application.</p>
<pre><code>                                   API Gateway 

                      Introduction to T opic 
</code></pre>
<p>APIs act as the &quot; front door &quot; for applications to access data, business logic, or
functionality from your backend services.
Hence API should be able to be highly available and handle thousands of
requests.
BackEnd System
API
Understanding the Basics
Amazon API Gateway  is a fully managed service that makes it easy for
developers to create, publish, maintain, monitor, and secure APIs at any scale.
BackEnd System
API Gateway
REST APIs vs HTTP APIs</p>
<pre><code>                    Understanding the Basics 
</code></pre>
<p>REST APIs and HTTP APIs are both RESTful API products.
REST APIs support more features than HTTP APIs, while HTTP APIs are
designed with minimal features so that they can be offered at a lower price.</p>
<pre><code>                          Which to Choose? 
</code></pre>
<p>Choose REST APIs if you need features such as API keys, per-client throttling,
request validation, AWS WAF integration, or private API endpoints.
Choose HTTP APIs if you don&rsquo;t need the features included with REST APIs.</p>
<pre><code>                     Core Differences - Security 
</code></pre>
<p>API Gateway provides a number of ways to protect your API from certain
threats, like malicious actors or spikes in traffic.</p>
<pre><code>       Core Differences - API Management 
</code></pre>
<p>Choose REST APIs if you need API management capabilities such as API keys
and per-client rate limiting</p>
<pre><code>              Core Differences - Monitoring 
</code></pre>
<p>API Gateway supports several options to log API requests and monitor your
APIs</p>
<pre><code>              Core Differences - Endpoint T ype 
</code></pre>
<p>The endpoint type refers to the endpoint that API Gateway creates for your API</p>
<pre><code>              Core Differences - Development 
</code></pre>
<p>As you&rsquo;re developing your API Gateway API, you decide on a number of
characteristics of your API.
These characteristics depend on the use case of your API.</p>
<pre><code>                          API Gateway Practical 

         Overall Implementation Architecture 
</code></pre>
<p>1.Create HTTP API
2.API will invoke a backend Lambda function.
Global Users
Creating REST API</p>
<pre><code>         Overall Implementation Architecture 
</code></pre>
<p>1.Create REST API
2.API will invoke a backend Lambda function.
Global Users
API Keys and Usage Plans</p>
<pre><code>                            Basics of API Keys 
</code></pre>
<p>API keys  are alphanumeric string values that you distribute to application
developer customers to grant access to your API.
GET /product
Forbidden
Connecting Through API Key
You can use the X-API-KEY  header while connecting to the API Endpoint.</p>
<pre><code>                                    Usage Plan 
</code></pre>
<p>A usage plan  specifies who can access one or more deployed API stages and
methods—and optionally sets the target request rate to start throttling requests.
The plan uses API keys to identify API clients and who can access the
associated API stages for each key.</p>
<pre><code>                                 Points to Note 
</code></pre>
<p>After you create, test, and deploy your APIs, you can use API Gateway usage
plans to make them available as product offerings for your customers.
You can configure usage plans and API keys to allow customers to access
selected APIs, and begin throttling requests  to those APIs based on defined
limits and quotas.
These can be set at the API, or API method level.</p>
<pre><code>                               Points to Note 
</code></pre>
<p>API Gateway throttles requests to your API using the token bucket algorithm,
where a token counts for a request
When request submissions exceed the steady-state request rate and burst
limits, API Gateway begins to throttle requests. Clients may receive 429 Too
Many Requests
There is a default quota of 10,000 requests per second (RPS) applicable at per
account per region.</p>
<p>1519            API Gateway Endpoint Types</p>
<pre><code>                              API Endpoints 
</code></pre>
<p>Depending on where the majority of your API traffic originates from, you can
create a appropriate API Gateway endpoint type.
API Gateway      Regional Endpoints  Edge Optimized Endpoints
Private Endpoints
Edge-optimized API endpoints
An edge-optimized API endpoint is best for geographically distributed clients.
API requests are routed to the nearest CloudFront Point of Presence (POP).
This is the default endpoint type for API Gateway REST APIs.
Internet CloudFront API Gateway
Global Users Global Users
Regional API endpoints
A regional API endpoint is intended for clients in the same region.
When a client running on an EC2 instance calls an API in the same region, or
when an API is intended to serve a small number of clients with high demands,
a regional API reduces connection overhead.
Internet API Gateway
Regional Users
Regional Users
us-east-1
Private API endpoints
A private API endpoint is an API endpoint that can only be accessed from your
Amazon Virtual Private Cloud (VPC) using an interface VPC endpoint
API Gateway
us-east-1 VPC Resources
Endpoint ENI</p>
<p>API Gateway Logging
Back to Logging!
Logging at API Gateway Level
knowledge portal
Logging at API Gateway allows customers to log calls that are made to the API Gateway
along with detailed information as API Gateway goes through each step of processing the
request.
API Gateway     Execution Logs
Access Logs</p>
<ol>
<li>
<p>Execution Logs
knowledge portal
Records the API Gateway internal information as the request is processed.
These are fully managed by the API Gateway .
Contains information like:
● The request URL
● The request data received by API Gateway
● The request data sent to the Lambda function
● The response received from the Lambda function
● The response data sent by API Gateway
Useful when a specific request needs troubleshooting.</p>
<pre><code>                        2.      Access Logs 
</code></pre>
<p>knowledge portal
Logs related to who has accessed the API.
V ery similar to the Apache / Nginx Logs.
Contains information like:
● The caller’s IP address
● The request time
● The request HTTP method
● The request URL
● The response HTTP status code, etc.</p>
</li>
</ol>
<p>CloudW atch Metrics for API Gateway
knowledge portal
There are certain metrics that are made available in CloudW atch for the API Gateway
resource.
Some of these metrics include:
● 5XX Error
● Latency
● Count
● 4XX Error</p>
<p>Amazon Comprehend
ML to Analyze T ext
Simple Use-Case
There are 100 customer representatives working in a call center.
All the conversation is recorded into text (speech to text converter)
Management wants to know the overall sentiment of conversation (positive/ negative).</p>
<p>knowledge portal
Amazon Comprehend
Amazon Comprehend is a natural-language processing (NLP) service that uses machine learning
to uncover valuable insights and connections in text.</p>
<p>knowledge portal Text 1
Text 2
Text 3
Analysis
Positive Sentiment
PII Data
English Language Comprehend
Amazon Comprehend - Medical
Amazon Comprehend Medical is a HIP AA-eligible NLP service that uses machine learning to
understand and extract health data from medical text, such as prescriptions, procedures, or
diagnoses.</p>
<p>knowledge portal</p>
<p>Amazon T ranslate
T ranslate Languages
Understanding the Basics
Amazon T ranslate is a neural machine translation service that delivers fast, high-quality ,
affordable, and customizable language translation.</p>
<p>knowledge portal</p>
<p>Sample Use-Case - Chat Application
Y ou can translate messages in real-time based received on services like T witch.
knowledge portal</p>
<p>Amazon T extract
Handwriting to T ext!
Understanding the Basics
Amazon T extract  is a machine learning (ML) service that automatically extracts text,
handwriting, and data from scanned documents.</p>
<p>knowledge portal
Amazon Lex
Automate Conversations
Basic of Amazon Lex
Amazon Lex is a fully managed AI service with advanced natural language models to design,
build, test, and deploy conversational interfaces in applications.</p>
<p>knowledge portal
Integration with Lambda
Amazon Lex can also be integrated with Lambda Function to achieve a specific use-case.</p>
<p>knowledge portal
CPU Price on 10th Feb?
LexLambda Response Input
Output User
Amazon T ranscribe
Speech to T ext Converter
Understanding the Basics
Amazon T ranscribe is an automatic speech recognition service that uses machine learning
models to convert audio to text.</p>
<p>Hi Everyone
Welcome Back
This is Demo
TextSpeech
knowledge portal
Call Analytics
Amazon T ranscribe Call Analytics  allows organizations to gain insight into customer-agent
interactions. Call Analytics provides you with:</p>
<ol>
<li>
<p>Call characteristics, including talk time, non-talk time, speaker loudness, interruptions,
and talk speed</p>
</li>
<li>
<p>Speaker sentiment for each caller at various points in a call</p>
</li>
<li>
<p>Call summarization, which detects issues, action items, and outcomes</p>
<p>knowledge portal
Amazon Kendra
Enterprise Searching
Understanding the Basics
Amazon Kendra  is a highly accurate and intelligent search service that enables your users to
search unstructured and structured data using natural language processing and advanced search
algorithms.</p>
</li>
</ol>
<h2 id="it-allows-us-to-easily-integrate-powerful-visual-analysis-into-our-application">Where does DevOps
Team sit?
Building A - 3rd Floor User
knowledge portal
A WS Rekognition
Deep Learning
Overview of A WS Rekognition
knowledge portal
A WS A WS Rekognition  is a deep learning based virtual analysis service.
It allows us to easily integrate powerful visual analysis into our application</h2>
<p>Best of Luck for the Exams
knowledge portal</p>

  <footer class="footline">
  </footer>
</article>
        </div>
      </main>
    </div>
    <aside id="R-sidebar" class="default-animation">
      <div id="R-header-topbar" class="default-animation"></div>
      <div id="R-header-wrapper" class="default-animation">
        <div id="R-header" class="default-animation">
          <a id="R-logo" class="R-default" href="../index.html">
            <div class="logo-title">AWS Solution Architect</div>
          </a>
        </div>
        <search><form action="../search/index.html" method="get">
          <div class="searchbox default-animation">
            <button class="search-detail" type="submit" title="Search (CTRL+ALT+f)"><i class="fas fa-search"></i></button>
            <label class="a11y-only" for="R-search-by">Search</label>
            <input data-search-input id="R-search-by" name="search-by" class="search-by" type="search" placeholder="Search...">
            <button class="search-clear" type="button" data-search-clear="" title="Clear search"><i class="fas fa-times" title="Clear search"></i></button>
          </div>
        </form></search>
      </div>
      <div id="R-homelinks" class="default-animation homelinks">
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-homelinks">
          <ul class="space collapsible-menu">
            <li class="" data-nav-id="/index.html"><a class="padding" href="../index.html"><i class="fa-fw fas fa-home"></i> Home</a></li>
          </ul>
        </div>
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-headercontrols">
          <ul class="">
          </ul>
        </div>
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
      </div>
      <div id="R-content-wrapper" class="highlightable">
        <div class="R-sidebarmenu R-shortcutmenu-main">
          <ul class="enlarge morespace collapsible-menu">
            <li class="active " data-nav-id="/aws_solutions_architect_professional_cleaned/index.html"><a class="padding" href="../aws_solutions_architect_professional_cleaned/index.html">Getting Started with AWS</a></li>
            <li class="" data-nav-id="/getting-started-with-the-course/index.html"><a class="padding" href="../getting-started-with-the-course/index.html">Getting Started with AWS</a></li>
            <li class="" data-nav-id="/02/index.html"><a class="padding" href="../02/index.html">AWS Multi-Account Strategy</a></li>
          </ul>
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-shortcuts">
          <ul class="space collapsible-menu">
          </ul>
        </div>
        <div id="R-footer-margin"></div>
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-footercontrols">
          <ul class="">
          </ul>
        </div>
<div id="R-footer"><p>Built with <a href="https://github.com/McShelby/hugo-theme-relearn" title="love"><i class="fas fa-heart"></i></a> by <a href="https://gohugo.io/">Hugo</a></p></div>
      </div>
    </aside>
    <script src="../nirpendra83/aws-doc.git/js/clipboard/clipboard.min.js?1757405171" defer></script>
    <script src="../nirpendra83/aws-doc.git/js/perfect-scrollbar/perfect-scrollbar.min.js?1757405171" defer></script>
    <script src="../nirpendra83/aws-doc.git/js/theme.js?1757405171" defer></script>
  </body>
</html>
